{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "USPPPM-train-hf-customheads.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b21c525372334f7aa24872c13da1ca6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_daf24c96883d4055a83f1e7e1a5400d9",
              "IPY_MODEL_560e87e589454287ae0eadb763d9936b",
              "IPY_MODEL_3bf89be19d294ff0a8f01695885e8b96"
            ],
            "layout": "IPY_MODEL_fd28cecb70954ad6a629819e63ad7042"
          }
        },
        "daf24c96883d4055a83f1e7e1a5400d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f119d94a4167497a863198ab7ff6cc31",
            "placeholder": "​",
            "style": "IPY_MODEL_7a1985a481704df090e9fe1f742ab49c",
            "value": "100%"
          }
        },
        "560e87e589454287ae0eadb763d9936b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b35a25c80710473f9107808a95334ae5",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad6be44c4aa94b7aa6c660c4ba6dac4d",
            "value": 30
          }
        },
        "3bf89be19d294ff0a8f01695885e8b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae5566f4cbcf49d6a16b4b0a9a952f59",
            "placeholder": "​",
            "style": "IPY_MODEL_89afaabbe7f84e30b8e7b46b71d0ab71",
            "value": " 30/30 [00:13&lt;00:00,  3.79ba/s]"
          }
        },
        "fd28cecb70954ad6a629819e63ad7042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f119d94a4167497a863198ab7ff6cc31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a1985a481704df090e9fe1f742ab49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b35a25c80710473f9107808a95334ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad6be44c4aa94b7aa6c660c4ba6dac4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae5566f4cbcf49d6a16b4b0a9a952f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89afaabbe7f84e30b8e7b46b71d0ab71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9844e82ec81743888e7e98488e25e0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fed500bb59a496e915f45452462fee6",
              "IPY_MODEL_a224e83d9e27467f9cf8f7aa92aa8f98",
              "IPY_MODEL_14ec3106d4524cd792c3b008bff63e96"
            ],
            "layout": "IPY_MODEL_4ee8be9699ac4b17aec1d87fb5b378d9"
          }
        },
        "6fed500bb59a496e915f45452462fee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f8dc94a8910415d875babfa40b50245",
            "placeholder": "​",
            "style": "IPY_MODEL_7af5f098326d4c47aaebdb8c47792b5c",
            "value": "100%"
          }
        },
        "a224e83d9e27467f9cf8f7aa92aa8f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c89b85f4453d40e7803d6fdd4a16181e",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57691aab3f83453e88401b672740d249",
            "value": 8
          }
        },
        "14ec3106d4524cd792c3b008bff63e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a118cf9b9ce74e07b04bc36da6070fd6",
            "placeholder": "​",
            "style": "IPY_MODEL_9bd7aeee67354b278b043f8df19592a5",
            "value": " 8/8 [00:03&lt;00:00,  2.79ba/s]"
          }
        },
        "4ee8be9699ac4b17aec1d87fb5b378d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f8dc94a8910415d875babfa40b50245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7af5f098326d4c47aaebdb8c47792b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c89b85f4453d40e7803d6fdd4a16181e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57691aab3f83453e88401b672740d249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a118cf9b9ce74e07b04bc36da6070fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bd7aeee67354b278b043f8df19592a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h460sHoQYjST",
        "outputId": "0b29646b-fc6b-48cd-a159-37033329a503"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jun 28 12:32:55 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq3l2TU4Yjwg",
        "outputId": "6b5bb088-804c-4399-d287-f4f1ca5965cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q transformers[sentencepiece] datasets hydra-core wandb"
      ],
      "metadata": {
        "id": "RWjqiyXRrQjr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "COLAB_ROOT_PATH = \"/content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/\"\n",
        "sys.path.append(COLAB_ROOT_PATH + \"src/util_code\")\n",
        "os.chdir(COLAB_ROOT_PATH)"
      ],
      "metadata": {
        "id": "gsMLUCFwS_Co"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the config for training run\n",
        "import hydra\n",
        "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
        "from omegaconf import DictConfig, OmegaConf\n",
        "\n",
        "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
        "initialize(version_base=None, config_path=\"configs\")\n",
        "config = compose(config_name=\"config\")"
      ],
      "metadata": {
        "id": "4ByEXnliUeIU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "UvSgv0xcWgWu"
      },
      "outputs": [],
      "source": [
        "import colab_utils\n",
        "import utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from datasets import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import transformers\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import torch.multiprocessing as mp\n",
        "from transformers import logging\n",
        "import warnings\n",
        "import wandb\n",
        "\n",
        "logging.set_verbosity_error()\n",
        "logging.set_verbosity_warning()\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is where we configure the run parameters\n",
        "# Model to run\n",
        "EXP_NUM = \"00\"\n",
        "MODEL_NAME = \"deberta-v3-small\"\n",
        "TRAIN_RUN_NAME = \"baseline\"\n",
        "TRANSFORMER_CHECKPOINT = \"microsoft/deberta-v3-small\"\n",
        "EXPERIMENT_NAME = EXP_NUM + \"_\" + MODEL_NAME + \"_\" + TRAIN_RUN_NAME\n",
        "\n",
        "# update the config with run params\n",
        "# update the output_dir to model specific directory\n",
        "config.paths.out_dir += MODEL_NAME\n",
        "print(f\"config.paths.out_dir = {config.paths.out_dir}\")\n",
        "config.train_run.transformer_checkpoint = TRANSFORMER_CHECKPOINT\n",
        "print(f\"config.train_run.transformer_checkpoint = {config.train_run.transformer_checkpoint}\")\n",
        "config.train_run.num_workers = mp.cpu_count()\n",
        "print(f\"config.train_run.num_workers = {config.train_run.num_workers}\")\n",
        "config.train_run.experiment_name = EXPERIMENT_NAME\n",
        "print(f\"config.train_run.experiment_name = {config.train_run.experiment_name}\")\n",
        "if config.wandb.enabled:\n",
        "    # enable reporting to wandb via huggingface training arguments\n",
        "    config.training_args.report_to = \"wandb\"\n",
        "    config.wandb.key = \"c5e2877bf080e6b62fcc57231c91e3a1455f97d0\"    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4ejkw2GZCDC",
        "outputId": "a5ba93ed-5330-4440-fae9-40e9c95a24a3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.paths.out_dir = /content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/model/deberta-v3-small\n",
            "config.train_run.transformer_checkpoint = microsoft/deberta-v3-small\n",
            "config.train_run.num_workers = 2\n",
            "config.train_run.experiment_name = 00_deberta-v3-small_baseline\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(OmegaConf.to_yaml(config))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0vaq7KLt0u_",
        "outputId": "005596f5-d961-4cd5-8b9e-eb531c61009a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_run:\n",
            "  random_state: 42\n",
            "  num_labels: 1\n",
            "  label_col: score\n",
            "  num_folds: 5\n",
            "  run_all_folds: false\n",
            "  num_epochs: 2\n",
            "  num_workers: 2\n",
            "  device: cuda\n",
            "  subset_rows_frac: 0.05\n",
            "  train_on_subset: false\n",
            "  transformer_checkpoint: microsoft/deberta-v3-small\n",
            "  experiment_name: 00_deberta-v3-small_baseline\n",
            "  save_artifacts: true\n",
            "wandb:\n",
            "  key: c5e2877bf080e6b62fcc57231c91e3a1455f97d0\n",
            "  project: USPPPM\n",
            "  enabled: true\n",
            "training_args:\n",
            "  output_dir: None\n",
            "  evaluation_strategy: epoch\n",
            "  save_strategy: epoch\n",
            "  save_total_limit: 1\n",
            "  load_best_model_at_end: true\n",
            "  metric_for_best_model: pearson\n",
            "  greater_is_better: true\n",
            "  log_level: warning\n",
            "  group_by_length: true\n",
            "  report_to: wandb\n",
            "  num_train_epochs: 2\n",
            "  per_device_train_batch_size: 40\n",
            "  per_device_eval_batch_size: 80\n",
            "  weight_decay: 0.01\n",
            "  learning_rate: 4.0e-05\n",
            "  warmup_ratio: 0.1\n",
            "  gradient_accumulation_steps: 3\n",
            "  fp16: true\n",
            "  lr_scheduler_type: linear\n",
            "  adam_epsilon: 1.0e-06\n",
            "paths:\n",
            "  data_path: /content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/data/\n",
            "  val_preds_path: /content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/preds/\n",
            "  out_dir: /content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/model/deberta-v3-small\n",
            "  run_artifacts_dir: /content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/model/deberta-v3-small/run_artifacts\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colab_utils.empty_gdrive_trash()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaIGLPZnaH3_",
        "outputId": "4e4ae197-4add-41a3-a59d-61c453dc0a1f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The below files were cleared from trash\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_wandb(fold):    \n",
        "    wandb.login(key=config.wandb.key)\n",
        "    wandb.init(\n",
        "        config=config,\n",
        "        project=config.wandb.project,\n",
        "        group=config.train_run.experiment_name,\n",
        "        name=f\"fold_{fold}\"\n",
        "    )        "
      ],
      "metadata": {
        "id": "fZaQBGmpvYyY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(config.paths.data_path + \"train.csv\")\n",
        "df_train[\"section\"] = df_train.context.str[0]\n",
        "df_test = pd.read_csv(config.paths.data_path + \"test.csv\")\n",
        "df_titles = pd.read_csv(config.paths.data_path + \"titles.csv\")"
      ],
      "metadata": {
        "id": "vJxWPSZuY5vC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "anchor_encoder = LabelEncoder()\n",
        "df_train[\"anchor_map\"] = anchor_encoder.fit_transform(df_train[\"anchor\"])\n",
        "df_train[\"context_map\"] = anchor_encoder.fit_transform(df_train[\"context\"])\n",
        "df_train[\"anchor_context_map\"] = df_train[\"anchor_map\"].astype(str).str.cat(df_train[\"context_map\"].astype(str), sep=\"_\")\n",
        "# Score is not really a continuous value here as there are just five distinct values. But since it is float it needs to be converted\n",
        "# to categorical value before we can perform stratified split on score\n",
        "df_train[\"score_map\"] = df_train[\"score\"].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})"
      ],
      "metadata": {
        "id": "9UhTGFDT2i_O"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if config.train_run.train_on_subset:\n",
        "    print(f\"Selecting {config.train_run.subset_rows_frac * 100}% training data\")\n",
        "    df_train = df_train.sample(\n",
        "        frac=config.train_run.subset_rows_frac, \n",
        "        random_state=config.train_run.random_state\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "# Since the target column (score) is continuous, we need to create bins out of the target column\n",
        "# df_train.loc[:, \"bins\"] = pd.cut(df_train.score, bins=5, labels=[0,1,2,3,4])\n",
        "# df_train = utils.strat_kfold_dataframe(df_train, target_col_name=\"bins\", random_state=config.train_run.random_state, num_folds=Config.NUM_FOLDS)\n",
        "\n",
        "# Now do a stratified group k fold on the bins column (which is a categorical column) and anchor as groups\n",
        "df_train = utils.strat_group_kfold_dataframe(\n",
        "    df_train, \n",
        "    target_col_name=\"score_map\", \n",
        "    group_col_name=\"anchor_context_map\",\n",
        "    random_state=config.train_run.random_state, \n",
        "    num_folds=config.train_run.num_folds\n",
        ")            \n",
        "# drop the bin column\n",
        "# df_train = df_train.drop([\"bins\"], axis=1)\n",
        "# df_train = df_train.drop([\"anchor_map\", \"score_map\"], axis=1)"
      ],
      "metadata": {
        "id": "e5dwA39eQET9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us check if the stratification has been done correctly\n",
        "# The mean of score column should be similar across folds \n",
        "fold_score_mean = []\n",
        "fold_anchor_context_maps = []\n",
        "for fold in range(config.train_run.num_folds):\n",
        "    df_train_fold = df_train[df_train.kfold == fold]\n",
        "    fold_score_mean.append(np.mean(df_train_fold.score.values))\n",
        "    fold_anchor_context_maps.append(set(df_train_fold.anchor_context_map.unique()))\n",
        "fold_score_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aAbRqQKha7u",
        "outputId": "f6a2ad43-8fcd-4309-ab0b-e7a62baa62fa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3557356434260165,\n",
              " 0.35813229056203605,\n",
              " 0.36268028846153844,\n",
              " 0.36315899290582837,\n",
              " 0.37085976039464413]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check each of the folds has no common anchor value\n",
        "def check_disjoint(start, fold_anchor_context_maps):\n",
        "    for i in range(start, 4):\n",
        "        for j in range(i+1, 5):\n",
        "            if fold_anchor_context_maps[i].isdisjoint(fold_anchor_context_maps[j]):\n",
        "                print(f\"anchor context map for fold {i} and {j} are disjoint\")\n",
        "\n",
        "check_disjoint(0, fold_anchor_context_maps)                "
      ],
      "metadata": {
        "id": "2X_BRoQaZH4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351e868e-1c70-46f9-df05-a69707db0184"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anchor context map for fold 0 and 1 are disjoint\n",
            "anchor context map for fold 0 and 2 are disjoint\n",
            "anchor context map for fold 0 and 3 are disjoint\n",
            "anchor context map for fold 0 and 4 are disjoint\n",
            "anchor context map for fold 1 and 2 are disjoint\n",
            "anchor context map for fold 1 and 3 are disjoint\n",
            "anchor context map for fold 1 and 4 are disjoint\n",
            "anchor context map for fold 2 and 3 are disjoint\n",
            "anchor context map for fold 2 and 4 are disjoint\n",
            "anchor context map for fold 3 and 4 are disjoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_titles.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nu9yrrW33CGl",
        "outputId": "ec3151cc-6a82-4507-950a-eb10d22238cf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       code                                              title section  class  \\\n",
              "0         A                                  HUMAN NECESSITIES       A    NaN   \n",
              "1       A01  AGRICULTURE; FORESTRY; ANIMAL HUSBANDRY; HUNTI...       A    1.0   \n",
              "2      A01B  SOIL WORKING IN AGRICULTURE OR FORESTRY; PARTS...       A    1.0   \n",
              "3  A01B1/00  Hand tools (edge trimmers for lawns A01G3/06  ...       A    1.0   \n",
              "4  A01B1/02  Spades; Shovels {(hand-operated dredgers E02F3...       A    1.0   \n",
              "\n",
              "  subclass  group  main_group  \n",
              "0      NaN    NaN         NaN  \n",
              "1      NaN    NaN         NaN  \n",
              "2        B    NaN         NaN  \n",
              "3        B    1.0         0.0  \n",
              "4        B    1.0         2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-940424a6-cc3f-404a-888e-8aecc21541ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>title</th>\n",
              "      <th>section</th>\n",
              "      <th>class</th>\n",
              "      <th>subclass</th>\n",
              "      <th>group</th>\n",
              "      <th>main_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>HUMAN NECESSITIES</td>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A01</td>\n",
              "      <td>AGRICULTURE; FORESTRY; ANIMAL HUSBANDRY; HUNTI...</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A01B</td>\n",
              "      <td>SOIL WORKING IN AGRICULTURE OR FORESTRY; PARTS...</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A01B1/00</td>\n",
              "      <td>Hand tools (edge trimmers for lawns A01G3/06  ...</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A01B1/02</td>\n",
              "      <td>Spades; Shovels {(hand-operated dredgers E02F3...</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-940424a6-cc3f-404a-888e-8aecc21541ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-940424a6-cc3f-404a-888e-8aecc21541ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-940424a6-cc3f-404a-888e-8aecc21541ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.merge(\n",
        "    left = df_train,\n",
        "    right = df_titles[[\"code\", \"title\"]],\n",
        "    how = \"inner\",\n",
        "    left_on = \"context\",\n",
        "    right_on = \"code\"\n",
        ")"
      ],
      "metadata": {
        "id": "7cnxD7nK6TAt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.anchor_context_map.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXTlR6uY5Df5",
        "outputId": "5b1dc236-2bd2-4d77-be5f-1384d65abf12"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "555_89     84\n",
              "129_47     79\n",
              "324_49     79\n",
              "430_104    74\n",
              "129_48     73\n",
              "           ..\n",
              "525_62      1\n",
              "649_62      1\n",
              "480_11      1\n",
              "485_11      1\n",
              "727_101     1\n",
              "Name: anchor_context_map, Length: 1699, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For each anchor, context group (i.e. set of records having same anchor and context values), concatenate the target phrases\n",
        "# key is unique anchor_context_map , value is concatenation of target phrases of all records for that unique anchor_context_map\n",
        "anc_ctx_targets = {}\n",
        "for anchor_context_map in df_train.anchor_context_map.unique():\n",
        "    df_train_sub = df_train[df_train.anchor_context_map == anchor_context_map]\n",
        "    anchor_context_target_text = \",\".join(df_train_sub.target)    \n",
        "    anc_ctx_targets[anchor_context_map] = anchor_context_target_text\n",
        "\n",
        "df_train[\"anchor_context_targets\"] = df_train.anchor_context_map.map(anc_ctx_targets)\n",
        "df_train[\"anc_ctx_tgt_len\"] = df_train[\"anchor_context_targets\"].apply(lambda text: len(text.split()))\n",
        "df_train = df_train.sort_values(by=[\"anc_ctx_tgt_len\"], ascending=False)\n",
        "# df_train = df_train.head(500)\n",
        "# df_train = df_train[df_train.anchor_context_map == \"555_89\"]"
      ],
      "metadata": {
        "id": "PlVFnydo5ltK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.train_run.transformer_checkpoint)\n",
        "# DataCollatorWithPadding pads each batch to the longest sequence length\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ki9Z4VTqzvr",
        "outputId": "a986dbb9-b284-4439-effb-d99bfd23cf7f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['sectok'] = '[' + df_train.section + ']'\n",
        "sectoks = list(df_train.sectok.unique())\n",
        "print(f\"Additional special tokens: {sectoks}\")\n",
        "tokenizer.add_special_tokens({'additional_special_tokens': sectoks})"
      ],
      "metadata": {
        "id": "QdNCCLVNMi2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c627b836-6255-4084-d5a6-d5ee9a90cc0e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Additional special tokens: ['[G]', '[C]', '[H]', '[B]', '[A]', '[E]', '[F]', '[D]']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sep = \" \" + tokenizer.sep_token + \" \"\n",
        "df_train[\"inputs\"] = df_train.sectok + sep + df_train.anchor + sep + df_train.target + sep + df_train.title + sep + df_train.anchor_context_targets\n",
        "df_train[\"inputs\"] = df_train[\"inputs\"].apply(lambda x: x.lower())\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "vcEDi4QjUEto",
        "outputId": "7747263b-cdae-4da6-ea39-b6fd803308c2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     id                                  anchor  \\\n",
              "18583  426b5d4ee52dfbba  reflection type liquid crystal display   \n",
              "19157  d583a6c02fed7b2a  reflection type liquid crystal display   \n",
              "19227  668eb746e5b96f9e  reflection type liquid crystal display   \n",
              "19221  b0e707f934a27619  reflection type liquid crystal display   \n",
              "19217  722fbf83a2054afa  reflection type liquid crystal display   \n",
              "\n",
              "                                target context  score section  anchor_map  \\\n",
              "18583   reflective mode liquid display     G02   0.50       G         555   \n",
              "19157      reflection mode lcd crystal     G02   0.50       G         555   \n",
              "19227                           mobile     G02   0.25       G         555   \n",
              "19221  reflection type crystal display     G02   0.50       G         555   \n",
              "19217            liquid crystal device     G02   0.50       G         555   \n",
              "\n",
              "       context_map anchor_context_map  score_map  kfold code   title  \\\n",
              "18583           89             555_89          2      4  G02  OPTICS   \n",
              "19157           89             555_89          2      4  G02  OPTICS   \n",
              "19227           89             555_89          1      4  G02  OPTICS   \n",
              "19221           89             555_89          2      4  G02  OPTICS   \n",
              "19217           89             555_89          2      4  G02  OPTICS   \n",
              "\n",
              "                                  anchor_context_targets  anc_ctx_tgt_len  \\\n",
              "18583  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "19157  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "19227  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "19221  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "19217  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "\n",
              "      sectok                                             inputs  \n",
              "18583    [G]  [g] [sep] reflection type liquid crystal displ...  \n",
              "19157    [G]  [g] [sep] reflection type liquid crystal displ...  \n",
              "19227    [G]  [g] [sep] reflection type liquid crystal displ...  \n",
              "19221    [G]  [g] [sep] reflection type liquid crystal displ...  \n",
              "19217    [G]  [g] [sep] reflection type liquid crystal displ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f32e23c6-3473-4585-8be4-55acd405ef5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>section</th>\n",
              "      <th>anchor_map</th>\n",
              "      <th>context_map</th>\n",
              "      <th>anchor_context_map</th>\n",
              "      <th>score_map</th>\n",
              "      <th>kfold</th>\n",
              "      <th>code</th>\n",
              "      <th>title</th>\n",
              "      <th>anchor_context_targets</th>\n",
              "      <th>anc_ctx_tgt_len</th>\n",
              "      <th>sectok</th>\n",
              "      <th>inputs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18583</th>\n",
              "      <td>426b5d4ee52dfbba</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>reflective mode liquid display</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19157</th>\n",
              "      <td>d583a6c02fed7b2a</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>reflection mode lcd crystal</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19227</th>\n",
              "      <td>668eb746e5b96f9e</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>mobile</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.25</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19221</th>\n",
              "      <td>b0e707f934a27619</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>reflection type crystal display</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19217</th>\n",
              "      <td>722fbf83a2054afa</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>liquid crystal device</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f32e23c6-3473-4585-8be4-55acd405ef5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f32e23c6-3473-4585-8be4-55acd405ef5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f32e23c6-3473-4585-8be4-55acd405ef5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(tokenizer, with_labels, row):\n",
        "    encoding = tokenizer(\n",
        "        text = row[\"inputs\"],\n",
        "        padding = False,\n",
        "        truncation = True,\n",
        "        # maximum possible sequence length (for inputs column). Sequences exceeding this length will be truncated\n",
        "        max_length = 512\n",
        "    )\n",
        "    if with_labels:\n",
        "        encoding[\"labels\"] = row[config.train_run.label_col]\n",
        "    return encoding"
      ],
      "metadata": {
        "id": "bfp4vMSLVUnv"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "preprocess_train_data = partial(tokenize_text, tokenizer, True)  \n",
        "preprocess_test_data = partial(tokenize_text, tokenizer, False)  "
      ],
      "metadata": {
        "id": "40q3FL0nWa2e"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = predictions.reshape(len(predictions))\n",
        "    return {\n",
        "        'pearson': np.corrcoef(predictions, labels)[0][1]\n",
        "    }"
      ],
      "metadata": {
        "id": "1AcHcSdKdwMb"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_oof_preds(trainer, ds_val, df_val_fold):\n",
        "    oof_outputs = trainer.predict(ds_val)\n",
        "    oof_predictions = oof_outputs.predictions.reshape(-1)\n",
        "    df_val_fold[\"val_preds\"] = oof_predictions\n",
        "    return df_val_fold"
      ],
      "metadata": {
        "id": "geU35SINdzXe"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_up():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    utils.delete_checkpoints(config.training_args[\"output_dir\"])\n",
        "    print(f\"deleted checkpoints as best model for {fold_str} saved already\")\n",
        "    # Empty the trash to clear gdrive disk space\n",
        "    colab_utils.empty_gdrive_trash()"
      ],
      "metadata": {
        "id": "l2m2Y_8H9Jh_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import custom_transformer_heads\n",
        "import time\n",
        "\n",
        "df_val_preds = pd.DataFrame()\n",
        "tok_vocab = tokenizer.get_vocab()\n",
        "exp_start_time = time.time()\n",
        "for fold in range(config.train_run.num_folds):\n",
        "    fold_str = f\"fold{fold}\"\n",
        "    print(f\"Running training for {fold_str}\")\n",
        "    if config.wandb.enabled:\n",
        "        initialize_wandb(fold)\n",
        "    df_train_fold, df_val_fold, ds_train, ds_val = utils.get_fold_ds(fold, df_train, preprocess_train_data)\n",
        "    config.training_args[\"output_dir\"] = config.paths.out_dir + fold_str\n",
        "    training_args = TrainingArguments(**config.training_args)\n",
        "    model = custom_transformer_heads.DebertaV2ForSeqClfMeanPooling.from_pretrained(\n",
        "        config.train_run.transformer_checkpoint, \n",
        "        num_labels=config.train_run.num_labels\n",
        "    )\n",
        "    print(f\"len(tokenizer_vocab) = {len(tok_vocab)}\")\n",
        "    model.resize_token_embeddings(len(tok_vocab))    \n",
        "    trainer = Trainer(\n",
        "        model=model,                         # the instantiated Transformers model to be trained\n",
        "        args=training_args,                  # training arguments, defined above\n",
        "        train_dataset=ds_train,              # training dataset\n",
        "        eval_dataset=ds_val,                 # evaluation dataset\n",
        "        compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "    trainer.train()\n",
        "    trainer.save_model(config.training_args[\"output_dir\"])\n",
        "    df_val_fold = get_oof_preds(trainer, ds_val, df_val_fold) \n",
        "    # display(df_val_fold.head())\n",
        "    df_val_preds = pd.concat([df_val_preds, df_val_fold], axis=0)\n",
        "    # export the oof predictions to csv for later use in stacking    \n",
        "    df_val_fold.to_csv(config.paths.val_preds_path + f\"df_train_oof_preds_{MODEL_NAME}_{fold_str}.csv\")\n",
        "    print(f\"Saved OOF predictions for fold {fold}\")    \n",
        "    del model, trainer\n",
        "    clean_up()\n",
        "    if not config.train_run.run_all_folds:\n",
        "        break\n",
        "\n",
        "exp_end_time = time.time()        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572,
          "referenced_widgets": [
            "b21c525372334f7aa24872c13da1ca6f",
            "daf24c96883d4055a83f1e7e1a5400d9",
            "560e87e589454287ae0eadb763d9936b",
            "3bf89be19d294ff0a8f01695885e8b96",
            "fd28cecb70954ad6a629819e63ad7042",
            "f119d94a4167497a863198ab7ff6cc31",
            "7a1985a481704df090e9fe1f742ab49c",
            "b35a25c80710473f9107808a95334ae5",
            "ad6be44c4aa94b7aa6c660c4ba6dac4d",
            "ae5566f4cbcf49d6a16b4b0a9a952f59",
            "89afaabbe7f84e30b8e7b46b71d0ab71",
            "9844e82ec81743888e7e98488e25e0cb",
            "6fed500bb59a496e915f45452462fee6",
            "a224e83d9e27467f9cf8f7aa92aa8f98",
            "14ec3106d4524cd792c3b008bff63e96",
            "4ee8be9699ac4b17aec1d87fb5b378d9",
            "6f8dc94a8910415d875babfa40b50245",
            "7af5f098326d4c47aaebdb8c47792b5c",
            "c89b85f4453d40e7803d6fdd4a16181e",
            "57691aab3f83453e88401b672740d249",
            "a118cf9b9ce74e07b04bc36da6070fd6",
            "9bd7aeee67354b278b043f8df19592a5"
          ]
        },
        "id": "e7Dzi9bM_9E1",
        "outputId": "09b0e91f-b2e0-4dcc-9b5e-d7537207588f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running training for fold0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbkanupam\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.19"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/wandb/run-20220628_123452-1rjhww9j</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bkanupam/USPPPM/runs/1rjhww9j\" target=\"_blank\">fold_0</a></strong> to <a href=\"https://wandb.ai/bkanupam/USPPPM\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parameter 'function'=<function Dataset.map.<locals>.decorate.<locals>.decorated at 0x7f4da7d31b90> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b21c525372334f7aa24872c13da1ca6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9844e82ec81743888e7e98488e25e0cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSeqClfMeanPooling: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight']\n",
            "- This IS expected if you are initializing DebertaV2ForSeqClfMeanPooling from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSeqClfMeanPooling from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSeqClfMeanPooling were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(tokenizer_vocab) = 128009\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='488' max='488' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [488/488 09:34, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pearson</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.048141</td>\n",
              "      <td>0.737365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.027970</td>\n",
              "      <td>0.779183</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='90' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [90/90 00:22]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved OOF predictions for fold 0\n",
            "deleted checkpoints as best model for fold0 saved already\n",
            "The below files were cleared from trash\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the CV score\n",
        "def calculate_cv_score(df_oof):\n",
        "    predictions = df_oof['val_preds'].values\n",
        "    labels = df_oof['score'].values\n",
        "    eval_preds = predictions, labels\n",
        "    cv_metric_dict = compute_metrics(eval_preds)\n",
        "    return cv_metric_dict[\"pearson\"]"
      ],
      "metadata": {
        "id": "kW8Ts1u8Ib4q"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# save config file, log file, oof file etc. related to training run\n",
        "exp_run_time = utils.asHours(exp_end_time - exp_start_time)\n",
        "if config.train_run.run_all_folds:\n",
        "        df_val_preds.to_csv(config.paths.val_preds_path + f\"df_train_oof_preds_{MODEL_NAME}.csv\")\n",
        "\n",
        "cv_score = calculate_cv_score(df_val_preds)\n",
        "print(f\"cv_score = {cv_score}\")\n",
        "run_summary_dict = {\n",
        "    \"experiment\": config.train_run.experiment_name,\n",
        "    \"cv\": cv_score,\n",
        "    \"experiment_time\": exp_run_time,\n",
        "    \"wandb_run\": wandb.run.get_url() if config.wandb.enabled else None,\n",
        "}\n",
        "print(run_summary_dict)\n",
        "if config.train_run.save_artifacts:\n",
        "    run_summary_file = config.paths.out_dir + \"/run_summary.json\"\n",
        "    with open(run_summary_file, \"w\") as f:\n",
        "        json.dump(run_summary_dict, f, indent=4)\n",
        "\n",
        "    # save run config yaml file (hydra config)\n",
        "    exp_config_file = config.paths.out_dir + \"/exp_config.yaml\"\n",
        "    with open(exp_config_file, \"w\") as fp:\n",
        "        OmegaConf.save(config, fp)\n",
        "\n",
        "    # upload artifacts and log final metrics to wandb\n",
        "    if config.wandb.enabled:\n",
        "        # Log config, cv score, run time to wandb\n",
        "        wandb.log({\"cv_score\": cv_score, \"exp_run_time\": exp_run_time})    \n",
        "        wandb.save(exp_config_file)        \n",
        "        wandb.save(run_summary_file)\n"
      ],
      "metadata": {
        "id": "RHmW1Ef7TNaM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "52c46fd9-7e0d-48fb-9101-af8730a0b2f7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv_score = 0.7791831694320728\n",
            "{'experiment': '00_deberta-v3-small_baseline', 'cv': 0.7791831694320728, 'experiment_time': '0h:10m:50s', 'wandb_run': 'https://wandb.ai/bkanupam/USPPPM/runs/1rjhww9j'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-f0021bf8c3ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Log config, cv score, run time to wandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"cv_score\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcv_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exp_run_time\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mexp_run_time\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_summary_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_attaching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, glob_str, base_path, policy)\u001b[0m\n\u001b[1;32m   1577\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m     def _save(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self, glob_str, base_path, policy)\u001b[0m\n\u001b[1;32m   1631\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwandb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m             \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwandb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 95] Operation not supported: '/content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/model/deberta-v3-small/exp_config.yaml' -> '/content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/wandb/run-20220628_123452-1rjhww9j/files/exp_config.yaml'"
          ]
        }
      ]
    }
  ]
}