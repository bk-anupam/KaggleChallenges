{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "USPPPM-train-hf-customheads.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b28e65edbd284541899ef352ea15b8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73086a274b3f4fbcbf0edf0632489d1a",
              "IPY_MODEL_1e18c408304046d882c978b06d3bafff",
              "IPY_MODEL_7d9df01f26ef4e86aecda72c50886bb4"
            ],
            "layout": "IPY_MODEL_26dd9989421e487bbbc58c1d4e3c7956"
          }
        },
        "73086a274b3f4fbcbf0edf0632489d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e1c20fb445e4a0d865871cfaec3da1e",
            "placeholder": "​",
            "style": "IPY_MODEL_1f5c93bf01e3456ab11c164c489bd93b",
            "value": "100%"
          }
        },
        "1e18c408304046d882c978b06d3bafff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f78402779a24957a8dfe42217dae938",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e895d44f13948e1a4dfca219583d191",
            "value": 30
          }
        },
        "7d9df01f26ef4e86aecda72c50886bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_839c830166f5480d9cdef8df4519fc7c",
            "placeholder": "​",
            "style": "IPY_MODEL_db05c398fa514c1e8415af3544e65937",
            "value": " 30/30 [00:11&lt;00:00,  3.91ba/s]"
          }
        },
        "26dd9989421e487bbbc58c1d4e3c7956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1c20fb445e4a0d865871cfaec3da1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f5c93bf01e3456ab11c164c489bd93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f78402779a24957a8dfe42217dae938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e895d44f13948e1a4dfca219583d191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "839c830166f5480d9cdef8df4519fc7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db05c398fa514c1e8415af3544e65937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f72fc2767e594a9bbd67e26b9f91f849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad4e066082064be3af3c5b16a5e9c05c",
              "IPY_MODEL_a2752b589f314f47a055685e0dbffbd7",
              "IPY_MODEL_fff889b3b7cb41038e7bdefbea2422d5"
            ],
            "layout": "IPY_MODEL_c24208d1f5af47338324b9fc72304f87"
          }
        },
        "ad4e066082064be3af3c5b16a5e9c05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c33c112f6b45bc95592deeb5aadce5",
            "placeholder": "​",
            "style": "IPY_MODEL_7219325d28254055a505ff85d069ef3a",
            "value": "100%"
          }
        },
        "a2752b589f314f47a055685e0dbffbd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aa4dfb68e474cf5ad74b735d25f9436",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28033064b49f427fa923c174e987df26",
            "value": 8
          }
        },
        "fff889b3b7cb41038e7bdefbea2422d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0e05983c85d4cc788a666e01cbe3243",
            "placeholder": "​",
            "style": "IPY_MODEL_2c3819fec6bb448f8cccdf7e44440f06",
            "value": " 8/8 [00:02&lt;00:00,  2.96ba/s]"
          }
        },
        "c24208d1f5af47338324b9fc72304f87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73c33c112f6b45bc95592deeb5aadce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7219325d28254055a505ff85d069ef3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3aa4dfb68e474cf5ad74b735d25f9436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28033064b49f427fa923c174e987df26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0e05983c85d4cc788a666e01cbe3243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c3819fec6bb448f8cccdf7e44440f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h460sHoQYjST",
        "outputId": "fb3d790a-2c8c-4c8a-8f48-2b85bca4f219"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 24 06:00:35 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq3l2TU4Yjwg",
        "outputId": "cfa1b0b6-1954-41b4-a08d-91215e4b8024"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q transformers[sentencepiece] datasets"
      ],
      "metadata": {
        "id": "RWjqiyXRrQjr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/src\")"
      ],
      "metadata": {
        "id": "gsMLUCFwS_Co"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In this notebook we experiment by finetuning a bert-for-patents model on competition data by adding patent section as special token to the tokenizer vocab."
      ],
      "metadata": {
        "id": "smOwYeJq980J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UvSgv0xcWgWu"
      },
      "outputs": [],
      "source": [
        "import colab_utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from datasets import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import transformers\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import torch.multiprocessing as mp\n",
        "from transformers import logging\n",
        "import warnings\n",
        "\n",
        "logging.set_verbosity_error()\n",
        "logging.set_verbosity_warning()\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    MODEL_NAME = \"deberta-v3-small\"\n",
        "    DATA_PATH = \"/content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/data/\"\n",
        "    VAL_PREDS_PATH = \"/content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/preds/\"\n",
        "    # location where trained model weights are saved\n",
        "    OUT_DIR = \"/content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/model/deberta-v3-small/\"\n",
        "    RUNTIME = \"COLAB\"\n",
        "    RANDOM_STATE = 42\n",
        "    BATCH_SIZE = 32\n",
        "    EVAL_BATCH_SIZE = 64\n",
        "    NUM_LABELS = 1\n",
        "    LABEL_COL = \"score\"\n",
        "    NUM_FOLDS = 5\n",
        "    RUN_ALL_FOLDS = False\n",
        "    NUM_EPOCHS = 2\n",
        "    NUM_WORKERS = mp.cpu_count()\n",
        "    TRANSFORMER_CHECKPOINT = \"microsoft/deberta-v3-small\"\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    SUBSET_ROWS_FRAC = 0.05\n",
        "    TRAIN_ON_SUBSET = False\n",
        "    RANDOM_SEED = 42\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "id": "ZUFOAd9PnMeC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args_dict = dict(\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy='epoch',        \n",
        "    num_train_epochs=Config.NUM_EPOCHS,\n",
        "    per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "    per_device_eval_batch_size=Config.EVAL_BATCH_SIZE,\n",
        "    weight_decay = 0.01,\n",
        "    learning_rate = 4e-5,\n",
        "    warmup_ratio = 0.1,\n",
        "    gradient_accumulation_steps = 4,\n",
        "    fp16 = True,\n",
        "    lr_scheduler_type = \"linear\",\n",
        "    # Number of checkpoints to save for each model\n",
        "    save_total_limit = 1,\n",
        "    #  Whether or not to load the best model found during training at the end of training.\n",
        "    load_best_model_at_end=True,\n",
        "    # Use in conjunction with `load_best_model_at_end` to specify the metric to use to compare two different\n",
        "    # models. Must be the name of a metric returned by the evaluation with or without the prefix `\"eval_\"`. Will\n",
        "    # default to `\"loss\"` if unspecified and `load_best_model_at_end=True` (to use the evaluation loss).\n",
        "    # If you set this value, `greater_is_better` will default to `True`. Don't forget to set it to `False` if\n",
        "    # your metric is better when lower.\n",
        "    metric_for_best_model=\"pearson\",\n",
        "    greater_is_better=True,\n",
        "    adam_epsilon=1e-6,\n",
        "    #warmup_steps=1000\n",
        "    log_level=\"warning\",\n",
        "    group_by_length=True    \n",
        ")    "
      ],
      "metadata": {
        "id": "MBUukiPdaqeK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colab_utils.empty_gdrive_trash()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaIGLPZnaH3_",
        "outputId": "4d760a71-65ef-465e-b86b-f1fbef815af6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The below files were cleared from trash\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(Config.DATA_PATH + \"train.csv\")\n",
        "df_train[\"section\"] = df_train.context.str[0]\n",
        "df_test = pd.read_csv(Config.DATA_PATH + \"test.csv\")\n",
        "df_titles = pd.read_csv(Config.DATA_PATH + \"titles.csv\")"
      ],
      "metadata": {
        "id": "vJxWPSZuY5vC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "anchor_encoder = LabelEncoder()\n",
        "df_train[\"anchor_map\"] = anchor_encoder.fit_transform(df_train[\"anchor\"])\n",
        "df_train[\"context_map\"] = anchor_encoder.fit_transform(df_train[\"context\"])\n",
        "df_train[\"anchor_context_map\"] = df_train[\"anchor_map\"].astype(str).str.cat(df_train[\"context_map\"].astype(str), sep=\"_\")\n",
        "# Score is not really a continuous value here as there are just five distinct values. But since it is float it needs to be converted\n",
        "# to categorical value before we can perform stratified split on score\n",
        "df_train[\"score_map\"] = df_train[\"score\"].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})"
      ],
      "metadata": {
        "id": "9UhTGFDT2i_O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "def strat_group_kfold_dataframe(df, target_col_name, group_col_name, num_folds=Config.NUM_FOLDS):\n",
        "    # we create a new column called kfold and fill it with -1\n",
        "    df[\"kfold\"] = -1\n",
        "    # randomize of shuffle the rows of dataframe before splitting is done\n",
        "    df = df.sample(frac=1, random_state=Config.RANDOM_SEED).reset_index(drop=True)\n",
        "    # get the target data\n",
        "    y = df[target_col_name].values    \n",
        "    groups = df[group_col_name].values\n",
        "    # stratify data using anchor as group and score as target\n",
        "    skf = model_selection.StratifiedGroupKFold(n_splits=num_folds, shuffle=True, random_state=Config.RANDOM_SEED)\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(X=df, y=y, groups=groups)):\n",
        "        df.loc[val_index, \"kfold\"] = fold        \n",
        "    return df     "
      ],
      "metadata": {
        "id": "oyJk2Q0gmwo4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strat_kfold_dataframe(df, target_col_name, num_folds=5):\n",
        "    # we create a new column called kfold and fill it with -1\n",
        "    df[\"kfold\"] = -1\n",
        "    # randomize of shuffle the rows of dataframe before splitting is done\n",
        "    df.sample(frac=1, random_state=Config.RANDOM_STATE).reset_index(drop=True)\n",
        "    y = df[target_col_name].values\n",
        "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=Config.RANDOM_STATE)\n",
        "    # stratification is done on the basis of y labels, a placeholder for X is sufficient\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X=df, y=y)):\n",
        "        df.loc[val_idx, \"kfold\"] = fold\n",
        "    return df"
      ],
      "metadata": {
        "id": "laP1LyLsoxe_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if Config.TRAIN_ON_SUBSET:\n",
        "    print(f\"Selecting {Config.SUBSET_ROWS_FRAC * 100}% training data\")\n",
        "    df_train = df_train.sample(frac=Config.SUBSET_ROWS_FRAC, random_state=Config.RANDOM_SEED).reset_index(drop=True)\n",
        "\n",
        "# Since the target column (score) is continuous, we need to create bins out of the target column\n",
        "# df_train.loc[:, \"bins\"] = pd.cut(df_train.score, bins=5, labels=[0,1,2,3,4])\n",
        "# df_train = strat_kfold_dataframe(df_train, target_col_name=\"bins\", num_folds=Config.NUM_FOLDS)\n",
        "\n",
        "# Now do a stratified group k fold on the bins column (which is a categorical column) and anchor as groups\n",
        "df_train = strat_group_kfold_dataframe(df_train, target_col_name=\"score_map\", group_col_name=\"anchor_context_map\", num_folds=Config.NUM_FOLDS)            \n",
        "# drop the bin column\n",
        "# df_train = df_train.drop([\"bins\"], axis=1)\n",
        "# df_train = df_train.drop([\"anchor_map\", \"score_map\"], axis=1)"
      ],
      "metadata": {
        "id": "e5dwA39eQET9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us check if the stratification has been done correctly\n",
        "# The mean of score column should be similar across folds \n",
        "fold_score_mean = []\n",
        "fold_anchor_context_maps = []\n",
        "for fold in range(Config.NUM_FOLDS):\n",
        "    df_train_fold = df_train[df_train.kfold == fold]\n",
        "    fold_score_mean.append(np.mean(df_train_fold.score.values))\n",
        "    fold_anchor_context_maps.append(set(df_train_fold.anchor_context_map.unique()))\n",
        "fold_score_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aAbRqQKha7u",
        "outputId": "75f6ccf8-09cd-45bf-ca9a-0a738529943f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3557356434260165,\n",
              " 0.35813229056203605,\n",
              " 0.36268028846153844,\n",
              " 0.36315899290582837,\n",
              " 0.37085976039464413]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check each of the folds has no common anchor value\n",
        "def check_disjoint(start, fold_anchor_context_maps):\n",
        "    for i in range(start, 4):\n",
        "        for j in range(i+1, 5):\n",
        "            if fold_anchor_context_maps[i].isdisjoint(fold_anchor_context_maps[j]):\n",
        "                print(f\"anchor context map for fold {i} and {j} are disjoint\")\n",
        "\n",
        "check_disjoint(0, fold_anchor_context_maps)                "
      ],
      "metadata": {
        "id": "2X_BRoQaZH4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69076e33-84f9-452c-9084-09cfe3565b5f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anchor context map for fold 0 and 1 are disjoint\n",
            "anchor context map for fold 0 and 2 are disjoint\n",
            "anchor context map for fold 0 and 3 are disjoint\n",
            "anchor context map for fold 0 and 4 are disjoint\n",
            "anchor context map for fold 1 and 2 are disjoint\n",
            "anchor context map for fold 1 and 3 are disjoint\n",
            "anchor context map for fold 1 and 4 are disjoint\n",
            "anchor context map for fold 2 and 3 are disjoint\n",
            "anchor context map for fold 2 and 4 are disjoint\n",
            "anchor context map for fold 3 and 4 are disjoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_titles.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nu9yrrW33CGl",
        "outputId": "fe7aa8ce-9ce6-43cc-9589-611ee88728d4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       code                                              title section  class  \\\n",
              "0         A                                  HUMAN NECESSITIES       A    NaN   \n",
              "1       A01  AGRICULTURE; FORESTRY; ANIMAL HUSBANDRY; HUNTI...       A    1.0   \n",
              "2      A01B  SOIL WORKING IN AGRICULTURE OR FORESTRY; PARTS...       A    1.0   \n",
              "3  A01B1/00  Hand tools (edge trimmers for lawns A01G3/06  ...       A    1.0   \n",
              "4  A01B1/02  Spades; Shovels {(hand-operated dredgers E02F3...       A    1.0   \n",
              "\n",
              "  subclass  group  main_group  \n",
              "0      NaN    NaN         NaN  \n",
              "1      NaN    NaN         NaN  \n",
              "2        B    NaN         NaN  \n",
              "3        B    1.0         0.0  \n",
              "4        B    1.0         2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f79996b-718f-4ba0-8d06-70c3ef691b8c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>title</th>\n",
              "      <th>section</th>\n",
              "      <th>class</th>\n",
              "      <th>subclass</th>\n",
              "      <th>group</th>\n",
              "      <th>main_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>HUMAN NECESSITIES</td>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A01</td>\n",
              "      <td>AGRICULTURE; FORESTRY; ANIMAL HUSBANDRY; HUNTI...</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A01B</td>\n",
              "      <td>SOIL WORKING IN AGRICULTURE OR FORESTRY; PARTS...</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A01B1/00</td>\n",
              "      <td>Hand tools (edge trimmers for lawns A01G3/06  ...</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A01B1/02</td>\n",
              "      <td>Spades; Shovels {(hand-operated dredgers E02F3...</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f79996b-718f-4ba0-8d06-70c3ef691b8c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3f79996b-718f-4ba0-8d06-70c3ef691b8c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3f79996b-718f-4ba0-8d06-70c3ef691b8c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.merge(\n",
        "    left = df_train,\n",
        "    right = df_titles[[\"code\", \"title\"]],\n",
        "    how = \"inner\",\n",
        "    left_on = \"context\",\n",
        "    right_on = \"code\"\n",
        ")"
      ],
      "metadata": {
        "id": "7cnxD7nK6TAt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.anchor_context_map.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXTlR6uY5Df5",
        "outputId": "ac7f526b-971a-4e82-b571-540e6622b484"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "555_89     84\n",
              "129_47     79\n",
              "324_49     79\n",
              "430_104    74\n",
              "129_48     73\n",
              "           ..\n",
              "525_62      1\n",
              "649_62      1\n",
              "480_11      1\n",
              "485_11      1\n",
              "727_101     1\n",
              "Name: anchor_context_map, Length: 1699, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For each anchor, context group (i.e. set of records having same anchor and context values), concatenate the target phrases\n",
        "# key is unique anchor_context_map , value is concatenation of target phrases of all records for that unique anchor_context_map\n",
        "anc_ctx_targets = {}\n",
        "for anchor_context_map in df_train.anchor_context_map.unique():\n",
        "    df_train_sub = df_train[df_train.anchor_context_map == anchor_context_map]\n",
        "    anchor_context_target_text = \",\".join(df_train_sub.target)    \n",
        "    anc_ctx_targets[anchor_context_map] = anchor_context_target_text\n",
        "\n",
        "df_train[\"anchor_context_targets\"] = df_train.anchor_context_map.map(anc_ctx_targets)\n",
        "df_train[\"anc_ctx_tgt_len\"] = df_train[\"anchor_context_targets\"].apply(lambda text: len(text.split()))\n",
        "df_train = df_train.sort_values(by=[\"anc_ctx_tgt_len\"], ascending=False)\n",
        "# df_train = df_train.head(500)\n",
        "# df_train = df_train[df_train.anchor_context_map == \"555_89\"]"
      ],
      "metadata": {
        "id": "PlVFnydo5ltK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(Config.TRANSFORMER_CHECKPOINT)\n",
        "# DataCollatorWithPadding pads each batch to the longest sequence length\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ki9Z4VTqzvr",
        "outputId": "760eb3fb-dced-4047-908d-b1019fc5709b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['sectok'] = '[' + df_train.section + ']'\n",
        "sectoks = list(df_train.sectok.unique())\n",
        "print(f\"Additional special tokens: {sectoks}\")\n",
        "tokenizer.add_special_tokens({'additional_special_tokens': sectoks})"
      ],
      "metadata": {
        "id": "QdNCCLVNMi2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07dce816-3bbb-4268-9772-fce4da4550d0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Additional special tokens: ['[G]', '[C]', '[H]', '[B]', '[A]', '[E]', '[F]', '[D]']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sep = \" \" + tokenizer.sep_token + \" \"\n",
        "df_train[\"inputs\"] = df_train.sectok + sep + df_train.anchor + sep + df_train.target + sep + df_train.title + sep + df_train.anchor_context_targets\n",
        "df_train[\"inputs\"] = df_train[\"inputs\"].apply(lambda x: x.lower())\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "vcEDi4QjUEto",
        "outputId": "70854e1d-ce5b-411b-eed6-7084c96c5c68"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     id                                  anchor  \\\n",
              "18583  426b5d4ee52dfbba  reflection type liquid crystal display   \n",
              "19157  d583a6c02fed7b2a  reflection type liquid crystal display   \n",
              "19227  668eb746e5b96f9e  reflection type liquid crystal display   \n",
              "19221  b0e707f934a27619  reflection type liquid crystal display   \n",
              "19217  722fbf83a2054afa  reflection type liquid crystal display   \n",
              "\n",
              "                                target context  score section  anchor_map  \\\n",
              "18583   reflective mode liquid display     G02   0.50       G         555   \n",
              "19157      reflection mode lcd crystal     G02   0.50       G         555   \n",
              "19227                           mobile     G02   0.25       G         555   \n",
              "19221  reflection type crystal display     G02   0.50       G         555   \n",
              "19217            liquid crystal device     G02   0.50       G         555   \n",
              "\n",
              "       context_map anchor_context_map  score_map  kfold code   title  \\\n",
              "18583           89             555_89          2      4  G02  OPTICS   \n",
              "19157           89             555_89          2      4  G02  OPTICS   \n",
              "19227           89             555_89          1      4  G02  OPTICS   \n",
              "19221           89             555_89          2      4  G02  OPTICS   \n",
              "19217           89             555_89          2      4  G02  OPTICS   \n",
              "\n",
              "                                  anchor_context_targets  anc_ctx_tgt_len  \\\n",
              "18583  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "19157  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "19227  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "19221  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "19217  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "\n",
              "      sectok                                             inputs  \n",
              "18583    [G]  [g] [sep] reflection type liquid crystal displ...  \n",
              "19157    [G]  [g] [sep] reflection type liquid crystal displ...  \n",
              "19227    [G]  [g] [sep] reflection type liquid crystal displ...  \n",
              "19221    [G]  [g] [sep] reflection type liquid crystal displ...  \n",
              "19217    [G]  [g] [sep] reflection type liquid crystal displ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18816fea-9949-4408-b05b-ae49c4cdabcd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>section</th>\n",
              "      <th>anchor_map</th>\n",
              "      <th>context_map</th>\n",
              "      <th>anchor_context_map</th>\n",
              "      <th>score_map</th>\n",
              "      <th>kfold</th>\n",
              "      <th>code</th>\n",
              "      <th>title</th>\n",
              "      <th>anchor_context_targets</th>\n",
              "      <th>anc_ctx_tgt_len</th>\n",
              "      <th>sectok</th>\n",
              "      <th>inputs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18583</th>\n",
              "      <td>426b5d4ee52dfbba</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>reflective mode liquid display</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19157</th>\n",
              "      <td>d583a6c02fed7b2a</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>reflection mode lcd crystal</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19227</th>\n",
              "      <td>668eb746e5b96f9e</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>mobile</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.25</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19221</th>\n",
              "      <td>b0e707f934a27619</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>reflection type crystal display</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19217</th>\n",
              "      <td>722fbf83a2054afa</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>liquid crystal device</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18816fea-9949-4408-b05b-ae49c4cdabcd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18816fea-9949-4408-b05b-ae49c4cdabcd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18816fea-9949-4408-b05b-ae49c4cdabcd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(tokenizer, with_labels, row):\n",
        "    encoding = tokenizer(\n",
        "        text = row[\"inputs\"],\n",
        "        padding = False,\n",
        "        truncation = True,\n",
        "        # maximum possible sequence length (for inputs column). Sequences exceeding this length will be truncated\n",
        "        max_length = 512\n",
        "    )\n",
        "    if with_labels:\n",
        "        encoding[\"labels\"] = row[Config.LABEL_COL]\n",
        "    return encoding"
      ],
      "metadata": {
        "id": "bfp4vMSLVUnv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "preprocess_train_data = partial(tokenize_text, tokenizer, True)  \n",
        "preprocess_test_data = partial(tokenize_text, tokenizer, False)  "
      ],
      "metadata": {
        "id": "40q3FL0nWa2e"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fold_dls(fold, df):\n",
        "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
        "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
        "    ds_train_raw = Dataset.from_pandas(train_df)\n",
        "    ds_valid_raw = Dataset.from_pandas(valid_df)\n",
        "    raw_ds_col_names = ds_train_raw.column_names    \n",
        "    ds_train = ds_train_raw.map(preprocess_train_data, batched=True, batch_size=1000, remove_columns=raw_ds_col_names)\n",
        "    ds_valid = ds_valid_raw.map(preprocess_train_data, batched=True, batch_size=1000, remove_columns=raw_ds_col_names)    \n",
        "    return train_df, valid_df, ds_train, ds_valid"
      ],
      "metadata": {
        "id": "uwGKDR0vWlKC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def compute_metrics(eval_pred):\n",
        "#     predictions, labels = eval_pred        \n",
        "#     if Config.NUM_LABELS == 1:\n",
        "#         y_preds = predictions.reshape(len(predictions))\n",
        "#     else:\n",
        "#         y_preds = np.argmax(predictions, axis=1)\n",
        "#     return {\n",
        "#         'eval_pearson': np.corrcoef(y_preds, labels)[0][1]\n",
        "#     }"
      ],
      "metadata": {
        "id": "0U2HCksdbDzh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = predictions.reshape(len(predictions))\n",
        "    return {\n",
        "        'pearson': np.corrcoef(predictions, labels)[0][1]\n",
        "    }"
      ],
      "metadata": {
        "id": "1AcHcSdKdwMb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_oof_preds(trainer, ds_val, df_val_fold):\n",
        "#     oof_outputs = trainer.predict(ds_val)\n",
        "#     if Config.NUM_LABELS == 1:\n",
        "#         y_preds_proba = oof_outputs.predictions\n",
        "#         oof_predictions = np.argmax(y_preds_proba, axis=1)\n",
        "#     else:\n",
        "#         oof_predictions = oof_outputs.predictions.reshape(-1)\n",
        "#     df_val_fold[\"val_preds\"] = oof_predictions\n",
        "#     return df_val_fold"
      ],
      "metadata": {
        "id": "9kuA_THHJiFx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_oof_preds(trainer, ds_val, df_val_fold):\n",
        "    oof_outputs = trainer.predict(ds_val)\n",
        "    oof_predictions = oof_outputs.predictions.reshape(-1)\n",
        "    df_val_fold[\"val_preds\"] = oof_predictions\n",
        "    return df_val_fold"
      ],
      "metadata": {
        "id": "geU35SINdzXe"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import custom_transformer_heads\n",
        "import utils\n",
        "\n",
        "df_val_preds = pd.DataFrame()\n",
        "tok_vocab = tokenizer.get_vocab()\n",
        "for fold in range(Config.NUM_FOLDS):\n",
        "    fold_str = f\"fold{fold}\"\n",
        "    print(f\"Running training for {fold_str}\")\n",
        "    df_train_fold, df_val_fold, ds_train, ds_val = get_fold_dls(fold, df_train)\n",
        "    training_args_dict[\"output_dir\"] = Config.OUT_DIR + fold_str\n",
        "    training_args = TrainingArguments(**training_args_dict, report_to=None)\n",
        "    model = custom_transformer_heads.DebertaV2ForSeqClfMeanPooling.from_pretrained(Config.TRANSFORMER_CHECKPOINT, num_labels=Config.NUM_LABELS)\n",
        "    print(f\"len(tokenizer_vocab) = {len(tok_vocab)}\")\n",
        "    model.resize_token_embeddings(len(tok_vocab))    \n",
        "    trainer = Trainer(\n",
        "        model=model,                         # the instantiated Transformers model to be trained\n",
        "        args=training_args,                  # training arguments, defined above\n",
        "        train_dataset=ds_train,              # training dataset\n",
        "        eval_dataset=ds_val,                 # evaluation dataset\n",
        "        compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "    trainer.train()\n",
        "    trainer.save_model(Config.OUT_DIR + fold_str)\n",
        "    df_val_fold = get_oof_preds(trainer, ds_val, df_val_fold) \n",
        "    # display(df_val_fold.head())\n",
        "    df_val_preds = pd.concat([df_val_preds, df_val_fold], axis=0)\n",
        "    # export the oof predictions to csv for later use in stacking\n",
        "    if Config.RUNTIME != \"KAGGLE\":\n",
        "        df_val_fold.to_csv(Config.VAL_PREDS_PATH + f\"df_train_oof_preds_{Config.MODEL_NAME}_{fold_str}.csv\")\n",
        "    else:\n",
        "        df_val_preds.to_csv(\"/kaggle/working/df_train_oof_preds.csv\")\n",
        "    print(f\"Saved OOF predictions for fold {fold}\")    \n",
        "    del model, trainer\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    utils.delete_checkpoints(Config.OUT_DIR + fold_str)\n",
        "    print(f\"deleted checkpoints as best model for {fold_str} saved already\")\n",
        "    # Empty the trash to clear gdrive disk space\n",
        "    colab_utils.empty_gdrive_trash()\n",
        "    if not Config.RUN_ALL_FOLDS:\n",
        "        break\n",
        "\n",
        "if Config.RUN_ALL_FOLDS:\n",
        "    df_val_preds.to_csv(Config.VAL_PREDS_PATH + f\"df_train_oof_preds_{Config.MODEL_NAME}.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "b28e65edbd284541899ef352ea15b8c2",
            "73086a274b3f4fbcbf0edf0632489d1a",
            "1e18c408304046d882c978b06d3bafff",
            "7d9df01f26ef4e86aecda72c50886bb4",
            "26dd9989421e487bbbc58c1d4e3c7956",
            "7e1c20fb445e4a0d865871cfaec3da1e",
            "1f5c93bf01e3456ab11c164c489bd93b",
            "0f78402779a24957a8dfe42217dae938",
            "6e895d44f13948e1a4dfca219583d191",
            "839c830166f5480d9cdef8df4519fc7c",
            "db05c398fa514c1e8415af3544e65937",
            "f72fc2767e594a9bbd67e26b9f91f849",
            "ad4e066082064be3af3c5b16a5e9c05c",
            "a2752b589f314f47a055685e0dbffbd7",
            "fff889b3b7cb41038e7bdefbea2422d5",
            "c24208d1f5af47338324b9fc72304f87",
            "73c33c112f6b45bc95592deeb5aadce5",
            "7219325d28254055a505ff85d069ef3a",
            "3aa4dfb68e474cf5ad74b735d25f9436",
            "28033064b49f427fa923c174e987df26",
            "a0e05983c85d4cc788a666e01cbe3243",
            "2c3819fec6bb448f8cccdf7e44440f06"
          ]
        },
        "id": "e7Dzi9bM_9E1",
        "outputId": "2858daac-d780-483d-e34b-3e9ee7ec8cb3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parameter 'function'=<function Dataset.map.<locals>.decorate.<locals>.decorated at 0x7ff48c7103b0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running training for fold0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b28e65edbd284541899ef352ea15b8c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f72fc2767e594a9bbd67e26b9f91f849"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSeqClfMeanPooling: ['mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight']\n",
            "- This IS expected if you are initializing DebertaV2ForSeqClfMeanPooling from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSeqClfMeanPooling from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSeqClfMeanPooling were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(tokenizer_vocab) = 128009\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='458' max='458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [458/458 09:32, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pearson</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.045101</td>\n",
              "      <td>0.688217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.031042</td>\n",
              "      <td>0.754331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='112' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [112/112 00:25]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved OOF predictions for fold 0\n",
            "The below files were cleared from trash\n",
            "['rng_state.pth', 'trainer_state.json', 'scaler.pt', 'scheduler.pt', 'optimizer.pt', 'training_args.bin', 'tokenizer.json', 'spm.model', 'added_tokens.json', 'special_tokens_map.json', 'tokenizer_config.json', 'pytorch_model.bin', 'config.json', 'checkpoint-229']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the CV score\n",
        "predictions = df_val_preds['val_preds'].values\n",
        "labels = df_val_preds['score'].values\n",
        "eval_preds = predictions, labels\n",
        "cv_metric_dict = compute_metrics(eval_preds)\n",
        "print(f\"CV score = {cv_metric_dict}\")"
      ],
      "metadata": {
        "id": "RHmW1Ef7TNaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45ec942-54b7-4a5d-db34-d82c2eb25e16"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score = {'pearson': 0.7543307773172057}\n"
          ]
        }
      ]
    }
  ]
}