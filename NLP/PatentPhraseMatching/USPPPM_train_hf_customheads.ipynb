{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "USPPPM-train-hf-customheads.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "611c82c49d4b43f3ace00c9a10b5de74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad98a6e0b3714d2086a42397cd65c95f",
              "IPY_MODEL_cd18496d192d45f795b379447d78f9e3",
              "IPY_MODEL_09a5adbce2ed437b91000544565d315a"
            ],
            "layout": "IPY_MODEL_76df071232e047cf828628a4f9fcf2e7"
          }
        },
        "ad98a6e0b3714d2086a42397cd65c95f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_222e4220856548c39fe930f28e7e7c6b",
            "placeholder": "​",
            "style": "IPY_MODEL_f1fd0a254fca4a68ba411ec739a7427f",
            "value": "100%"
          }
        },
        "cd18496d192d45f795b379447d78f9e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_956c7b2a48024481a4c86b23d202f204",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6e03d14273e40ca8f31dda498a69bcb",
            "value": 30
          }
        },
        "09a5adbce2ed437b91000544565d315a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcbaf45bb8f2405791de8df6e47738af",
            "placeholder": "​",
            "style": "IPY_MODEL_228ff00efc9d44a2beeccdf3a0c8ba5a",
            "value": " 30/30 [00:10&lt;00:00,  3.75ba/s]"
          }
        },
        "76df071232e047cf828628a4f9fcf2e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "222e4220856548c39fe930f28e7e7c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1fd0a254fca4a68ba411ec739a7427f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "956c7b2a48024481a4c86b23d202f204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6e03d14273e40ca8f31dda498a69bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcbaf45bb8f2405791de8df6e47738af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228ff00efc9d44a2beeccdf3a0c8ba5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a5f8d4caeb449a4a37d8f8c18be9d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ee31ae4991645afb1ed7cd897826c52",
              "IPY_MODEL_a06a1a47450d468f9855115ec1d7c795",
              "IPY_MODEL_ca7ec52d07a64b6d9155452b2efff27c"
            ],
            "layout": "IPY_MODEL_7cdbda70cf644675b9b6ff503429f657"
          }
        },
        "4ee31ae4991645afb1ed7cd897826c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a34b2c8c691481885ed8858fc379a2b",
            "placeholder": "​",
            "style": "IPY_MODEL_b0cb4a6a23af4f02a9c41403146efb59",
            "value": "100%"
          }
        },
        "a06a1a47450d468f9855115ec1d7c795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb23a6c088f9496ea8f18ca2e883266b",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dba8f957b0e462382e5fbc60af3f9d6",
            "value": 8
          }
        },
        "ca7ec52d07a64b6d9155452b2efff27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c03d238891c4ff3accebad53daef492",
            "placeholder": "​",
            "style": "IPY_MODEL_536eda52e0bb442486e0605c68322058",
            "value": " 8/8 [00:02&lt;00:00,  2.93ba/s]"
          }
        },
        "7cdbda70cf644675b9b6ff503429f657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a34b2c8c691481885ed8858fc379a2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0cb4a6a23af4f02a9c41403146efb59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb23a6c088f9496ea8f18ca2e883266b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dba8f957b0e462382e5fbc60af3f9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c03d238891c4ff3accebad53daef492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "536eda52e0bb442486e0605c68322058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h460sHoQYjST",
        "outputId": "0a63c6ae-57e6-4d78-ba18-24d67282f298"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun 22 11:40:11 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq3l2TU4Yjwg",
        "outputId": "1749c92a-7943-455a-c74f-6159e08762c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q transformers[sentencepiece] datasets"
      ],
      "metadata": {
        "id": "RWjqiyXRrQjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a59892b-1958-44ca-897d-832a3c8f4fa4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.4 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 362 kB 57.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 59.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 75.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 60.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 73.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 53.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 74.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 78.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 50.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 65.3 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### In this notebook we experiment by finetuning a bert-for-patents model on competition data by adding patent section as special token to the tokenizer vocab."
      ],
      "metadata": {
        "id": "smOwYeJq980J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# my_drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "P-ieFj8jnb3Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "UvSgv0xcWgWu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from datasets import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import transformers\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import torch.multiprocessing as mp\n",
        "from transformers import logging\n",
        "import warnings\n",
        "\n",
        "logging.set_verbosity_error()\n",
        "logging.set_verbosity_warning()\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainingArgs:\n",
        "    weight_decay = 0.01\n",
        "    learning_rate = 1e-5\n",
        "    warmup_ratio = 0.1\n",
        "    gradient_accumulation_steps = 8\n",
        "    fp16 = True\n",
        "    lr_scheduler_type = \"linear\"\n",
        "    # Number of checkpoints to save for each model\n",
        "    save_total_limit = 1\n",
        "    #  Whether or not to load the best model found during training at the end of training.\n",
        "    load_best_model_at_end=True\n",
        "    # Use in conjunction with `load_best_model_at_end` to specify the metric to use to compare two different\n",
        "    # models. Must be the name of a metric returned by the evaluation with or without the prefix `\"eval_\"`. Will\n",
        "    # default to `\"loss\"` if unspecified and `load_best_model_at_end=True` (to use the evaluation loss).\n",
        "    # If you set this value, `greater_is_better` will default to `True`. Don't forget to set it to `False` if\n",
        "    # your metric is better when lower.\n",
        "    metric_for_best_model=\"pearson\"\n",
        "    greater_is_better=True\n",
        "    adam_epsilon=1e-6\n",
        "    #warmup_steps=1000\n",
        "    log_level=\"warning\"\n",
        "    group_by_length=True\n",
        "\n",
        "class Config:\n",
        "    MODEL_NAME = \"deberta-v3-large\"\n",
        "    DATA_PATH = \"/content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/data/\"\n",
        "    VAL_PREDS_PATH = \"/content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/preds/\"\n",
        "    # location where trained model weights are saved\n",
        "    OUT_DIR = \"/content/gdrive/MyDrive/Kaggle/NLP/PatentPhraseMatching/model/deberta-v3-large/\"\n",
        "    RUNTIME = \"COLAB\"\n",
        "    RANDOM_STATE = 42\n",
        "    BATCH_SIZE = 4\n",
        "    EVAL_BATCH_SIZE = 8\n",
        "    NUM_LABELS = 1\n",
        "    LABEL_COL = \"score\"\n",
        "    NUM_FOLDS = 5\n",
        "    RUN_ALL_FOLDS = False\n",
        "    NUM_EPOCHS = 1\n",
        "    NUM_WORKERS = mp.cpu_count()\n",
        "    TRANSFORMER_CHECKPOINT = \"microsoft/deberta-v3-large\"\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    SUBSET_ROWS_FRAC = 0.05\n",
        "    TRAIN_ON_SUBSET = False\n",
        "    RANDOM_SEED = 42\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "id": "ZUFOAd9PnMeC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def empty_gdrive_trash():\n",
        "    deleted_file_name = []\n",
        "    for a_file in my_drive.ListFile({'q': \"trashed = true\"}).GetList():\n",
        "        file_name = a_file['title']\n",
        "        deleted_file_name.append(file_name)\n",
        "        # delete the file permanently.\n",
        "        a_file.Delete()\n",
        "    print(\"The below files were cleared from trash\")\n",
        "    print(deleted_file_name)"
      ],
      "metadata": {
        "id": "qDqO9vZjfNWw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# empty_gdrive_trash()"
      ],
      "metadata": {
        "id": "nWus5Rs1m7UI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(Config.DATA_PATH + \"train.csv\")\n",
        "df_test = pd.read_csv(Config.DATA_PATH + \"test.csv\")\n",
        "df_titles = pd.read_csv(Config.DATA_PATH + \"titles.csv\")"
      ],
      "metadata": {
        "id": "vJxWPSZuY5vC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"section\"] = df_train.context.str[0]"
      ],
      "metadata": {
        "id": "QOkNxZGEyvyv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "anchor_encoder = LabelEncoder()\n",
        "df_train[\"anchor_map\"] = anchor_encoder.fit_transform(df_train[\"anchor\"])\n",
        "df_train[\"context_map\"] = anchor_encoder.fit_transform(df_train[\"context\"])\n",
        "df_train[\"anchor_context_map\"] = df_train[\"anchor_map\"].astype(str).str.cat(df_train[\"context_map\"].astype(str), sep=\"_\")\n",
        "# Score is not really a continuous value here as there are just five distinct values. But since it is float it needs to be converted\n",
        "# to categorical value before we can perform stratified split on score\n",
        "df_train[\"score_map\"] = df_train[\"score\"].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})"
      ],
      "metadata": {
        "id": "9UhTGFDT2i_O"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "def strat_group_kfold_dataframe(df, target_col_name, group_col_name, num_folds=Config.NUM_FOLDS):\n",
        "    # we create a new column called kfold and fill it with -1\n",
        "    df[\"kfold\"] = -1\n",
        "    # randomize of shuffle the rows of dataframe before splitting is done\n",
        "    df = df.sample(frac=1, random_state=Config.RANDOM_SEED).reset_index(drop=True)\n",
        "    # get the target data\n",
        "    y = df[target_col_name].values    \n",
        "    groups = df[group_col_name].values\n",
        "    # stratify data using anchor as group and score as target\n",
        "    skf = model_selection.StratifiedGroupKFold(n_splits=num_folds, shuffle=True, random_state=Config.RANDOM_SEED)\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(X=df, y=y, groups=groups)):\n",
        "        df.loc[val_index, \"kfold\"] = fold        \n",
        "    return df     "
      ],
      "metadata": {
        "id": "oyJk2Q0gmwo4"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strat_kfold_dataframe(df, target_col_name, num_folds=5):\n",
        "    # we create a new column called kfold and fill it with -1\n",
        "    df[\"kfold\"] = -1\n",
        "    # randomize of shuffle the rows of dataframe before splitting is done\n",
        "    df.sample(frac=1, random_state=Config.RANDOM_STATE).reset_index(drop=True)\n",
        "    y = df[target_col_name].values\n",
        "    skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=Config.RANDOM_STATE)\n",
        "    # stratification is done on the basis of y labels, a placeholder for X is sufficient\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X=df, y=y)):\n",
        "        df.loc[val_idx, \"kfold\"] = fold\n",
        "    return df"
      ],
      "metadata": {
        "id": "laP1LyLsoxe_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if Config.TRAIN_ON_SUBSET:\n",
        "    print(f\"Selecting {Config.SUBSET_ROWS_FRAC * 100}% training data\")\n",
        "    df_train = df_train.sample(frac=Config.SUBSET_ROWS_FRAC, random_state=Config.RANDOM_SEED).reset_index(drop=True)\n",
        "\n",
        "# Since the target column (score) is continuous, we need to create bins out of the target column\n",
        "# df_train.loc[:, \"bins\"] = pd.cut(df_train.score, bins=5, labels=[0,1,2,3,4])\n",
        "# df_train = strat_kfold_dataframe(df_train, target_col_name=\"bins\", num_folds=Config.NUM_FOLDS)\n",
        "\n",
        "# Now do a stratified group k fold on the bins column (which is a categorical column) and anchor as groups\n",
        "df_train = strat_group_kfold_dataframe(df_train, target_col_name=\"score_map\", group_col_name=\"anchor_context_map\", num_folds=Config.NUM_FOLDS)            \n",
        "# drop the bin column\n",
        "# df_train = df_train.drop([\"bins\"], axis=1)\n",
        "# df_train = df_train.drop([\"anchor_map\", \"score_map\"], axis=1)"
      ],
      "metadata": {
        "id": "e5dwA39eQET9"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us check if the stratification has been done correctly\n",
        "# The mean of score column should be similar across folds \n",
        "fold_score_mean = []\n",
        "fold_anchor_context_maps = []\n",
        "for fold in range(Config.NUM_FOLDS):\n",
        "    df_train_fold = df_train[df_train.kfold == fold]\n",
        "    fold_score_mean.append(np.mean(df_train_fold.score.values))\n",
        "    fold_anchor_context_maps.append(set(df_train_fold.anchor_context_map.unique()))\n",
        "fold_score_mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aAbRqQKha7u",
        "outputId": "bc944c4a-0123-44f7-9ea4-3738a18ea0d6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3557356434260165,\n",
              " 0.35813229056203605,\n",
              " 0.36268028846153844,\n",
              " 0.36315899290582837,\n",
              " 0.37085976039464413]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check each of the folds has no common anchor value\n",
        "def check_disjoint(start, fold_anchor_context_maps):\n",
        "    for i in range(start, 4):\n",
        "        for j in range(i+1, 5):\n",
        "            if fold_anchor_context_maps[i].isdisjoint(fold_anchor_context_maps[j]):\n",
        "                print(f\"anchor context map for fold {i} and {j} are disjoint\")\n",
        "\n",
        "check_disjoint(0, fold_anchor_context_maps)                "
      ],
      "metadata": {
        "id": "2X_BRoQaZH4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a17e9cdb-53b3-410e-c44c-7c7a742b9431"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anchor context map for fold 0 and 1 are disjoint\n",
            "anchor context map for fold 0 and 2 are disjoint\n",
            "anchor context map for fold 0 and 3 are disjoint\n",
            "anchor context map for fold 0 and 4 are disjoint\n",
            "anchor context map for fold 1 and 2 are disjoint\n",
            "anchor context map for fold 1 and 3 are disjoint\n",
            "anchor context map for fold 1 and 4 are disjoint\n",
            "anchor context map for fold 2 and 3 are disjoint\n",
            "anchor context map for fold 2 and 4 are disjoint\n",
            "anchor context map for fold 3 and 4 are disjoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_titles.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Nu9yrrW33CGl",
        "outputId": "297fecf4-bd9f-4420-fb8c-0bb4bc948aaf"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       code                                              title section  class  \\\n",
              "0         A                                  HUMAN NECESSITIES       A    NaN   \n",
              "1       A01  AGRICULTURE; FORESTRY; ANIMAL HUSBANDRY; HUNTI...       A    1.0   \n",
              "2      A01B  SOIL WORKING IN AGRICULTURE OR FORESTRY; PARTS...       A    1.0   \n",
              "3  A01B1/00  Hand tools (edge trimmers for lawns A01G3/06  ...       A    1.0   \n",
              "4  A01B1/02  Spades; Shovels {(hand-operated dredgers E02F3...       A    1.0   \n",
              "\n",
              "  subclass  group  main_group  \n",
              "0      NaN    NaN         NaN  \n",
              "1      NaN    NaN         NaN  \n",
              "2        B    NaN         NaN  \n",
              "3        B    1.0         0.0  \n",
              "4        B    1.0         2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8df2a445-923a-4d9a-a16c-f548d89af122\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>title</th>\n",
              "      <th>section</th>\n",
              "      <th>class</th>\n",
              "      <th>subclass</th>\n",
              "      <th>group</th>\n",
              "      <th>main_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>HUMAN NECESSITIES</td>\n",
              "      <td>A</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A01</td>\n",
              "      <td>AGRICULTURE; FORESTRY; ANIMAL HUSBANDRY; HUNTI...</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A01B</td>\n",
              "      <td>SOIL WORKING IN AGRICULTURE OR FORESTRY; PARTS...</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A01B1/00</td>\n",
              "      <td>Hand tools (edge trimmers for lawns A01G3/06  ...</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A01B1/02</td>\n",
              "      <td>Spades; Shovels {(hand-operated dredgers E02F3...</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>B</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8df2a445-923a-4d9a-a16c-f548d89af122')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8df2a445-923a-4d9a-a16c-f548d89af122 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8df2a445-923a-4d9a-a16c-f548d89af122');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.merge(\n",
        "    left = df_train,\n",
        "    right = df_titles[[\"code\", \"title\"]],\n",
        "    how = \"inner\",\n",
        "    left_on = \"context\",\n",
        "    right_on = \"code\"\n",
        ")"
      ],
      "metadata": {
        "id": "7cnxD7nK6TAt"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.anchor_context_map.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXTlR6uY5Df5",
        "outputId": "f38a4e6a-5b98-4670-de8b-36d0fd62e0dc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "555_89     84\n",
              "129_47     79\n",
              "324_49     79\n",
              "430_104    74\n",
              "129_48     73\n",
              "           ..\n",
              "525_62      1\n",
              "649_62      1\n",
              "480_11      1\n",
              "485_11      1\n",
              "727_101     1\n",
              "Name: anchor_context_map, Length: 1699, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For each anchor, context group (i.e. set of records having same anchor and context values), concatenate the target phrases\n",
        "# key is unique anchor_context_map , value is concatenation of target phrases of all records for that unique anchor_context_map\n",
        "anc_ctx_targets = {}\n",
        "for anchor_context_map in df_train.anchor_context_map.unique():\n",
        "    df_train_sub = df_train[df_train.anchor_context_map == anchor_context_map]\n",
        "    anchor_context_target_text = \",\".join(df_train_sub.target)    \n",
        "    anc_ctx_targets[anchor_context_map] = anchor_context_target_text\n",
        "\n",
        "df_train[\"anchor_context_targets\"] = df_train.anchor_context_map.map(anc_ctx_targets)\n",
        "df_train[\"anc_ctx_tgt_len\"] = df_train[\"anchor_context_targets\"].apply(lambda text: len(text.split()))\n",
        "df_train = df_train.sort_values(by=[\"anc_ctx_tgt_len\"], ascending=False)\n",
        "# df_train = df_train.head(500)\n",
        "# df_train = df_train[df_train.anchor_context_map == \"555_89\"]"
      ],
      "metadata": {
        "id": "PlVFnydo5ltK"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from typing import Optional, Union, Tuple\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "from transformers import DebertaV2Model, DebertaV2PreTrainedModel\n",
        "from transformers.models.deberta.modeling_deberta import ContextPooler, StableDropout"
      ],
      "metadata": {
        "id": "k2MVTFlOIC_l"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base class for implementing custom heads on top of deberta-v2 backbone\n",
        "class DebertaV2ForSeqClfBase(DebertaV2PreTrainedModel):    \n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        num_labels = getattr(config, \"num_labels\", 2)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.deberta = DebertaV2Model(config)\n",
        "        self.pooler = ContextPooler(config)\n",
        "        output_dim = self.pooler.output_dim\n",
        "\n",
        "        self.classifier = nn.Linear(output_dim, num_labels)\n",
        "        drop_out = getattr(config, \"cls_dropout\", None)\n",
        "        drop_out = self.config.hidden_dropout_prob if drop_out is None else drop_out\n",
        "        self.dropout = StableDropout(drop_out)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.deberta.get_input_embeddings()\n",
        "\n",
        "    def set_input_embeddings(self, new_embeddings):\n",
        "        self.deberta.set_input_embeddings(new_embeddings)\n",
        "    \n",
        "    def get_loss(self, labels, logits):\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.config.problem_type is None:\n",
        "                if self.num_labels == 1:\n",
        "                    # regression task\n",
        "                    loss_fn = nn.MSELoss()\n",
        "                    logits = logits.view(-1).to(labels.dtype)\n",
        "                    loss = loss_fn(logits, labels.view(-1))\n",
        "                elif labels.dim() == 1 or labels.size(-1) == 1:\n",
        "                    label_index = (labels >= 0).nonzero()\n",
        "                    labels = labels.long()\n",
        "                    if label_index.size(0) > 0:\n",
        "                        labeled_logits = torch.gather(\n",
        "                            logits, 0, label_index.expand(label_index.size(0), logits.size(1))\n",
        "                        )\n",
        "                        labels = torch.gather(labels, 0, label_index.view(-1))\n",
        "                        loss_fct = nn.CrossEntropyLoss()\n",
        "                        loss = loss_fct(labeled_logits.view(-1, self.num_labels).float(), labels.view(-1))\n",
        "                    else:\n",
        "                        loss = torch.tensor(0).to(logits)\n",
        "                else:\n",
        "                    log_softmax = nn.LogSoftmax(-1)\n",
        "                    loss = -((log_softmax(logits) * labels).sum(-1)).mean()\n",
        "            elif self.config.problem_type == \"regression\":\n",
        "                loss_fct = nn.MSELoss()\n",
        "                if self.num_labels == 1:\n",
        "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
        "                else:\n",
        "                    loss = loss_fct(logits, labels)\n",
        "            elif self.config.problem_type == \"single_label_classification\":\n",
        "                loss_fct = nn.CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            elif self.config.problem_type == \"multi_label_classification\":\n",
        "                loss_fct = nn.BCEWithLogitsLoss()\n",
        "                loss = loss_fct(logits, labels)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "Y93YExCxM2O9"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DebertaV2ForSeqClfMeanPooling(DebertaV2ForSeqClfBase):    \n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "    \n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        labels: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
        "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
        "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.deberta(\n",
        "            input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            position_ids=position_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        # hidden state from the last layer [batch_size, seq_len, hidden_size]\n",
        "        last_hidden_state = outputs[0]\n",
        "        # copy the 2d attention mask [batch_size, seq_len] hidden_size times in the third dimension (hidden state)\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "        # [batch_size, seq_len, hidden_size ]\n",
        "        # Each hidden state is a tensor of dimension [batch_size, seq_len] and we have hidden_size number of such hidden state\n",
        "        # Of these seq_len columns in each hidden state only those need to be taken into account for which attention_mask = 1.  \n",
        "        # Doing an element wise multiplication of the 2d attention mask [batch_size, seq_len] with the corresponding 2d hidden state \n",
        "        # [batch_size, seq_len] gives hidden state with only the non-padded columns. Sum this hidden state along dimension 1 \n",
        "        # ( the dimension of sequence length) to get the sum_embeddings [batch_size, hidden_size] \n",
        "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
        "        # The sum mask is a value between 0 to 256 signifying the number of unpadded columns for that hidden state\n",
        "        sum_mask = input_mask_expanded.sum(1)\n",
        "        # [batch_size, hidden_size]\n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "        # element wise division \n",
        "        mean_embeddings = sum_embeddings / sum_mask\n",
        "        # [batch_size, hidden_size]\n",
        "        logits = self.classifier(mean_embeddings)\n",
        "        loss = self.get_loss(labels, logits)\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[1:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions\n",
        "        )\n"
      ],
      "metadata": {
        "id": "mSAO73j50MML"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DebertaV2ForSeqClfMaxPooling(DebertaV2ForSeqClfBase):    \n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "    \n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        labels: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
        "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
        "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.deberta(\n",
        "            input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            position_ids=position_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        # hidden state from the last layer [batch_size, seq_len, hidden_size]\n",
        "        last_hidden_state = outputs[0]\n",
        "        # copy the 2d attention mask [batch_size, seq_len] hidden_size times in the third dimension (hidden state)\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "        # [batch_size, seq_len, hidden_size ]        \n",
        "        # Set padding tokens to large negative value\n",
        "        last_hidden_state[input_mask_expanded == 0] = -1e9  \n",
        "        # Get the max value along dimension 1 (seq_len dimension) of last_hidden_state. The result will be [batch_size, hidden_size] tensor\n",
        "        # The first output torch.max returns the max values along a dimension, the second output is the index of max value\n",
        "        max_embeddings = torch.max(last_hidden_state, 1)[0]        \n",
        "        # [batch_size, hidden_size]\n",
        "        logits = self.classifier(max_embeddings)\n",
        "        loss = self.get_loss(labels, logits)\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[1:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions\n",
        "        )\n"
      ],
      "metadata": {
        "id": "xsHDn9VkMaYN"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DebertaV2ForSeqClfMeanMaxPooling(DebertaV2ForSeqClfBase):    \n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "    \n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        labels: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
        "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
        "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.deberta(\n",
        "            input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            position_ids=position_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        \n",
        "        last_hidden_state = outputs[0]        \n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "\n",
        "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)        \n",
        "        sum_mask = input_mask_expanded.sum(1)        \n",
        "        sum_mask = torch.clamp(sum_mask, min=1e-9)        \n",
        "        mean_pooling_embeddings = sum_embeddings / sum_mask        \n",
        "\n",
        "        last_hidden_state[input_mask_expanded == 0] = -1e9          \n",
        "        max_pooling_embeddings = torch.max(last_hidden_state, 1)[0]\n",
        "\n",
        "        mean_max_embeddings = torch.cat((mean_pooling_embeddings, max_pooling_embeddings), 1)\n",
        "        # [batch_size, 2*hidden_size]\n",
        "        logits = self.classifier(mean_max_embeddings)\n",
        "        loss = self.get_loss(labels, logits)\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[1:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions\n",
        "        )\n"
      ],
      "metadata": {
        "id": "dDrR-uTGmd9G"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(Config.TRANSFORMER_CHECKPOINT)\n",
        "# DataCollatorWithPadding pads each batch to the longest sequence length\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ki9Z4VTqzvr",
        "outputId": "b1e28c17-edf8-408e-a5e6-e897efdcb06c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['sectok'] = '[' + df_train.section + ']'\n",
        "sectoks = list(df_train.sectok.unique())\n",
        "print(f\"Additional special tokens: {sectoks}\")\n",
        "tokenizer.add_special_tokens({'additional_special_tokens': sectoks})"
      ],
      "metadata": {
        "id": "QdNCCLVNMi2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5009a11f-7a5d-4fbc-fa5a-dd49106c97ac"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Additional special tokens: ['[G]', '[C]', '[H]', '[B]', '[A]', '[E]', '[F]', '[D]']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sep = \" \" + tokenizer.sep_token + \" \"\n",
        "# sep = tokenizer.sep_token\n",
        "df_train[\"inputs\"] = df_train.sectok + sep + df_train.anchor + sep + df_train.target + sep + df_train.title + sep + df_train.anchor_context_targets\n",
        "df_train[\"inputs\"] = df_train[\"inputs\"].apply(lambda x: x.lower())\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "vcEDi4QjUEto",
        "outputId": "257da7e4-f1bc-4840-88fa-b306803d7de2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     id                                  anchor  \\\n",
              "18583  426b5d4ee52dfbba  reflection type liquid crystal display   \n",
              "19157  d583a6c02fed7b2a  reflection type liquid crystal display   \n",
              "19227  668eb746e5b96f9e  reflection type liquid crystal display   \n",
              "19221  b0e707f934a27619  reflection type liquid crystal display   \n",
              "19217  722fbf83a2054afa  reflection type liquid crystal display   \n",
              "\n",
              "                                target context  score section  anchor_map  \\\n",
              "18583   reflective mode liquid display     G02   0.50       G         555   \n",
              "19157      reflection mode lcd crystal     G02   0.50       G         555   \n",
              "19227                           mobile     G02   0.25       G         555   \n",
              "19221  reflection type crystal display     G02   0.50       G         555   \n",
              "19217            liquid crystal device     G02   0.50       G         555   \n",
              "\n",
              "       context_map anchor_context_map  score_map  kfold code   title  \\\n",
              "18583           89             555_89          2      4  G02  OPTICS   \n",
              "19157           89             555_89          2      4  G02  OPTICS   \n",
              "19227           89             555_89          1      4  G02  OPTICS   \n",
              "19221           89             555_89          2      4  G02  OPTICS   \n",
              "19217           89             555_89          2      4  G02  OPTICS   \n",
              "\n",
              "                                  anchor_context_targets  anc_ctx_tgt_len  \\\n",
              "18583  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "19157  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "19227  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "19221  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "19217  liquid matrix type crystal,lcd displays reflec...              213   \n",
              "\n",
              "      sectok                                             inputs  \n",
              "18583    [G]  [g] [sep] reflection type liquid crystal displ...  \n",
              "19157    [G]  [g] [sep] reflection type liquid crystal displ...  \n",
              "19227    [G]  [g] [sep] reflection type liquid crystal displ...  \n",
              "19221    [G]  [g] [sep] reflection type liquid crystal displ...  \n",
              "19217    [G]  [g] [sep] reflection type liquid crystal displ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b92206eb-6c61-4019-84af-b7368e899bd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anchor</th>\n",
              "      <th>target</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>section</th>\n",
              "      <th>anchor_map</th>\n",
              "      <th>context_map</th>\n",
              "      <th>anchor_context_map</th>\n",
              "      <th>score_map</th>\n",
              "      <th>kfold</th>\n",
              "      <th>code</th>\n",
              "      <th>title</th>\n",
              "      <th>anchor_context_targets</th>\n",
              "      <th>anc_ctx_tgt_len</th>\n",
              "      <th>sectok</th>\n",
              "      <th>inputs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18583</th>\n",
              "      <td>426b5d4ee52dfbba</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>reflective mode liquid display</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19157</th>\n",
              "      <td>d583a6c02fed7b2a</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>reflection mode lcd crystal</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19227</th>\n",
              "      <td>668eb746e5b96f9e</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>mobile</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.25</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19221</th>\n",
              "      <td>b0e707f934a27619</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>reflection type crystal display</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19217</th>\n",
              "      <td>722fbf83a2054afa</td>\n",
              "      <td>reflection type liquid crystal display</td>\n",
              "      <td>liquid crystal device</td>\n",
              "      <td>G02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>G</td>\n",
              "      <td>555</td>\n",
              "      <td>89</td>\n",
              "      <td>555_89</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>G02</td>\n",
              "      <td>OPTICS</td>\n",
              "      <td>liquid matrix type crystal,lcd displays reflec...</td>\n",
              "      <td>213</td>\n",
              "      <td>[G]</td>\n",
              "      <td>[g] [sep] reflection type liquid crystal displ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b92206eb-6c61-4019-84af-b7368e899bd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b92206eb-6c61-4019-84af-b7368e899bd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b92206eb-6c61-4019-84af-b7368e899bd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(tokenizer, with_labels, row):\n",
        "    encoding = tokenizer(\n",
        "        text = row[\"inputs\"],\n",
        "        padding = False,\n",
        "        truncation = True,\n",
        "        # maximum possible sequence length (for inputs column). Sequences exceeding this\n",
        "        # length will be truncated\n",
        "        max_length = 512\n",
        "    )\n",
        "    if with_labels:\n",
        "        encoding[\"labels\"] = row[Config.LABEL_COL]\n",
        "    return encoding"
      ],
      "metadata": {
        "id": "bfp4vMSLVUnv"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "preprocess_train_data = partial(tokenize_text, tokenizer, True)  \n",
        "preprocess_test_data = partial(tokenize_text, tokenizer, False)  "
      ],
      "metadata": {
        "id": "40q3FL0nWa2e"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fold_dls(fold, df):\n",
        "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
        "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
        "    ds_train_raw = Dataset.from_pandas(train_df)\n",
        "    ds_valid_raw = Dataset.from_pandas(valid_df)\n",
        "    raw_ds_col_names = ds_train_raw.column_names    \n",
        "    ds_train = ds_train_raw.map(preprocess_train_data, batched=True, batch_size=1000, remove_columns=raw_ds_col_names)\n",
        "    ds_valid = ds_valid_raw.map(preprocess_train_data, batched=True, batch_size=1000, remove_columns=raw_ds_col_names)    \n",
        "    return train_df, valid_df, ds_train, ds_valid"
      ],
      "metadata": {
        "id": "uwGKDR0vWlKC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def compute_metrics(eval_pred):\n",
        "#     predictions, labels = eval_pred        \n",
        "#     if Config.NUM_LABELS == 1:\n",
        "#         y_preds = predictions.reshape(len(predictions))\n",
        "#     else:\n",
        "#         y_preds = np.argmax(predictions, axis=1)\n",
        "#     return {\n",
        "#         'eval_pearson': np.corrcoef(y_preds, labels)[0][1]\n",
        "#     }"
      ],
      "metadata": {
        "id": "0U2HCksdbDzh"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = predictions.reshape(len(predictions))\n",
        "    return {\n",
        "        'pearson': np.corrcoef(predictions, labels)[0][1]\n",
        "    }"
      ],
      "metadata": {
        "id": "1AcHcSdKdwMb"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_oof_preds(trainer, ds_val, df_val_fold):\n",
        "#     oof_outputs = trainer.predict(ds_val)\n",
        "#     if Config.NUM_LABELS == 1:\n",
        "#         y_preds_proba = oof_outputs.predictions\n",
        "#         oof_predictions = np.argmax(y_preds_proba, axis=1)\n",
        "#     else:\n",
        "#         oof_predictions = oof_outputs.predictions.reshape(-1)\n",
        "#     df_val_fold[\"val_preds\"] = oof_predictions\n",
        "#     return df_val_fold"
      ],
      "metadata": {
        "id": "9kuA_THHJiFx"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_oof_preds(trainer, ds_val, df_val_fold):\n",
        "    oof_outputs = trainer.predict(ds_val)\n",
        "    oof_predictions = oof_outputs.predictions.reshape(-1)\n",
        "    df_val_fold[\"val_preds\"] = oof_predictions\n",
        "    return df_val_fold"
      ],
      "metadata": {
        "id": "geU35SINdzXe"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_args(fold_str):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=Config.OUT_DIR + fold_str,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy='epoch',        \n",
        "        num_train_epochs=Config.NUM_EPOCHS,\n",
        "        per_device_train_batch_size=Config.BATCH_SIZE,\n",
        "        per_device_eval_batch_size=Config.EVAL_BATCH_SIZE,\n",
        "        warmup_ratio=TrainingArgs.warmup_ratio,\n",
        "        weight_decay=TrainingArgs.weight_decay,\n",
        "        learning_rate=TrainingArgs.learning_rate,    \n",
        "        gradient_accumulation_steps=TrainingArgs.gradient_accumulation_steps,\n",
        "        fp16=TrainingArgs.fp16,\n",
        "        lr_scheduler_type=TrainingArgs.lr_scheduler_type,\n",
        "        save_total_limit=TrainingArgs.save_total_limit,\n",
        "        load_best_model_at_end=TrainingArgs.load_best_model_at_end,\n",
        "        metric_for_best_model=TrainingArgs.metric_for_best_model,\n",
        "        greater_is_better=TrainingArgs.greater_is_better,\n",
        "        adam_epsilon=TrainingArgs.adam_epsilon,\n",
        "        #warmup_steps=TrainingArgs.warmup_steps,\n",
        "        log_level=TrainingArgs.log_level,\n",
        "        group_by_length=TrainingArgs.group_by_length\n",
        "    )\n",
        "    return training_args"
      ],
      "metadata": {
        "id": "4qfol82CjNqx"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "df_val_preds = pd.DataFrame()\n",
        "tok_vocab = tokenizer.get_vocab()\n",
        "for fold in range(Config.NUM_FOLDS):\n",
        "    fold_str = f\"fold{fold}\"\n",
        "    print(f\"Running training for {fold_str}\")\n",
        "    df_train_fold, df_val_fold, ds_train, ds_val = get_fold_dls(fold, df_train)\n",
        "    training_args = get_training_args(fold_str)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(Config.TRANSFORMER_CHECKPOINT, num_labels=Config.NUM_LABELS)\n",
        "    print(f\"len(tokenizer_vocab) = {len(tok_vocab)}\")\n",
        "    model.resize_token_embeddings(len(tok_vocab))    \n",
        "    trainer = Trainer(\n",
        "        model=model,                         # the instantiated Transformers model to be trained\n",
        "        args=training_args,                  # training arguments, defined above\n",
        "        train_dataset=ds_train,              # training dataset\n",
        "        eval_dataset=ds_val,                 # evaluation dataset\n",
        "        compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer\n",
        "    )\n",
        "    trainer.train()\n",
        "    trainer.save_model(Config.OUT_DIR + fold_str)\n",
        "    df_val_fold = get_oof_preds(trainer, ds_val, df_val_fold) \n",
        "    # display(df_val_fold.head())\n",
        "    df_val_preds = pd.concat([df_val_preds, df_val_fold], axis=0)\n",
        "    # export the oof predictions to csv for later use in stacking\n",
        "    if Config.RUNTIME != \"KAGGLE\":\n",
        "        df_val_fold.to_csv(Config.VAL_PREDS_PATH + f\"df_train_oof_preds_{Config.MODEL_NAME}_{fold_str}.csv\")\n",
        "    else:\n",
        "        df_val_preds.to_csv(\"/kaggle/working/df_train_oof_preds.csv\")\n",
        "    print(f\"Saved OOF predictions for fold {fold}\")    \n",
        "    del model, trainer\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    # Empty the trash to clear gdrive disk space\n",
        "    # empty_gdrive_trash()\n",
        "    if not Config.RUN_ALL_FOLDS:\n",
        "        break\n",
        "\n",
        "if Config.RUN_ALL_FOLDS:\n",
        "    df_val_preds.to_csv(Config.VAL_PREDS_PATH + f\"df_train_oof_preds_{Config.MODEL_NAME}.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298,
          "referenced_widgets": [
            "611c82c49d4b43f3ace00c9a10b5de74",
            "ad98a6e0b3714d2086a42397cd65c95f",
            "cd18496d192d45f795b379447d78f9e3",
            "09a5adbce2ed437b91000544565d315a",
            "76df071232e047cf828628a4f9fcf2e7",
            "222e4220856548c39fe930f28e7e7c6b",
            "f1fd0a254fca4a68ba411ec739a7427f",
            "956c7b2a48024481a4c86b23d202f204",
            "b6e03d14273e40ca8f31dda498a69bcb",
            "dcbaf45bb8f2405791de8df6e47738af",
            "228ff00efc9d44a2beeccdf3a0c8ba5a",
            "6a5f8d4caeb449a4a37d8f8c18be9d9d",
            "4ee31ae4991645afb1ed7cd897826c52",
            "a06a1a47450d468f9855115ec1d7c795",
            "ca7ec52d07a64b6d9155452b2efff27c",
            "7cdbda70cf644675b9b6ff503429f657",
            "4a34b2c8c691481885ed8858fc379a2b",
            "b0cb4a6a23af4f02a9c41403146efb59",
            "cb23a6c088f9496ea8f18ca2e883266b",
            "7dba8f957b0e462382e5fbc60af3f9d6",
            "5c03d238891c4ff3accebad53daef492",
            "536eda52e0bb442486e0605c68322058"
          ]
        },
        "id": "e7Dzi9bM_9E1",
        "outputId": "c2bed2dc-a811-43d1-8585-1491658f5628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running training for fold0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "611c82c49d4b43f3ace00c9a10b5de74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a5f8d4caeb449a4a37d8f8c18be9d9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(tokenizer_vocab) = 128009\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='156' max='916' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [156/916 06:22 < 31:25, 0.40 it/s, Epoch 0.17/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the CV score\n",
        "predictions = df_val_preds['val_preds'].values\n",
        "labels = df_val_preds['score'].values\n",
        "eval_preds = predictions, labels\n",
        "cv_metric_dict = compute_metrics(eval_preds)\n",
        "print(f\"CV score = {cv_metric_dict}\")"
      ],
      "metadata": {
        "id": "RHmW1Ef7TNaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}