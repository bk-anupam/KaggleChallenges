{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42bd0559",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-10T13:36:58.692669Z",
     "iopub.status.busy": "2022-06-10T13:36:58.692154Z",
     "iopub.status.idle": "2022-06-10T13:37:06.471552Z",
     "shell.execute_reply": "2022-06-10T13:37:06.470731Z"
    },
    "papermill": {
     "duration": 7.790576,
     "end_time": "2022-06-10T13:37:06.473756",
     "exception": false,
     "start_time": "2022-06-10T13:36:58.683180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "from functools import partial\n",
    "import torch.multiprocessing as mp\n",
    "import warnings\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "logging.set_verbosity_warning()\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084dffb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:37:06.487880Z",
     "iopub.status.busy": "2022-06-10T13:37:06.487395Z",
     "iopub.status.idle": "2022-06-10T13:37:06.547247Z",
     "shell.execute_reply": "2022-06-10T13:37:06.546461Z"
    },
    "papermill": {
     "duration": 0.068904,
     "end_time": "2022-06-10T13:37:06.549104",
     "exception": false,
     "start_time": "2022-06-10T13:37:06.480200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Models:\n",
    "    DEBERTA_V3_LARGE = \"deberta-v3-large\"\n",
    "    BERT_FOR_PATENTS = \"bert-for-patents\"\n",
    "    DEBERTA_V2_XLARGE = \"deberta-v2-xlarge\"\n",
    "\n",
    "class TrainingArgs:\n",
    "    weight_decay = 0.01\n",
    "    learning_rate = 2e-5  \n",
    "    warmup_ratio = 0.1\n",
    "    gradient_accumulation_steps = 8\n",
    "    fp16 = True\n",
    "    lr_scheduler_type = \"cosine\"\n",
    "\n",
    "class Config:\n",
    "    DATA_PATH = \"/kaggle/input/us-patent-phrase-to-phrase-matching/\"\n",
    "    RANDOM_STATE = 42\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_LABELS = 1\n",
    "    NUM_FOLDS = 5\n",
    "    NUM_EPOCHS = 4\n",
    "    NUM_WORKERS = mp.cpu_count()\n",
    "    TRANSFORMER_CHECKPOINT = \"microsoft/deberta-v3-large\"\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5e283f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:37:06.563007Z",
     "iopub.status.busy": "2022-06-10T13:37:06.562259Z",
     "iopub.status.idle": "2022-06-10T13:37:06.568795Z",
     "shell.execute_reply": "2022-06-10T13:37:06.568046Z"
    },
    "papermill": {
     "duration": 0.015032,
     "end_time": "2022-06-10T13:37:06.570405",
     "exception": false,
     "start_time": "2022-06-10T13:37:06.555373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_paths = {\n",
    "    Models.DEBERTA_V3_LARGE: f\"/kaggle/input/anu-dbv3l/deberta-v3-large/\",\n",
    "    Models.BERT_FOR_PATENTS: f\"/kaggle/input/anu-bfp/bert-for-patents/\",\n",
    "    Models.DEBERTA_V2_XLARGE: f\"/kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/\"\n",
    "}\n",
    "\n",
    "tokenizer_paths = {\n",
    "    Models.DEBERTA_V3_LARGE: f\"/kaggle/input/anu-dbv3l/deberta-v3-large/fold0/checkpoint-2280/\",\n",
    "    Models.BERT_FOR_PATENTS: f\"/kaggle/input/anu-bfp/bert-for-patents/fold0/checkpoint-2280/\",\n",
    "    Models.DEBERTA_V2_XLARGE: f\"/kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold0/\"\n",
    "}\n",
    "\n",
    "oof_preds_paths = {\n",
    "    Models.DEBERTA_V3_LARGE: \"/kaggle/input/uspppmmodeloofpreds/uspppm-models-oof-preds2/df_train_oof_preds_deberta-v3-large.csv\",\n",
    "    Models.BERT_FOR_PATENTS: \"/kaggle/input/uspppmmodeloofpreds/uspppm-models-oof-preds2/df_bfp_train_oof_preds.csv\",\n",
    "    Models.DEBERTA_V2_XLARGE: \"/kaggle/input/uspppmmodeloofpreds/uspppm-models-oof-preds2/df_train_oof_preds_deberta-v2-xlarge.csv\"\n",
    "}\n",
    "\n",
    "# columns to select from model OOF predictions dataframe\n",
    "oof_cols_to_use = [\n",
    "    \"id\",\n",
    "    \"anchor\",\n",
    "    \"target\",\n",
    "    \"context\",\n",
    "    \"section\",\n",
    "    \"kfold\",\n",
    "    \"score\",\n",
    "    \"val_preds\"\n",
    "]\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f623fa3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:37:06.583570Z",
     "iopub.status.busy": "2022-06-10T13:37:06.583326Z",
     "iopub.status.idle": "2022-06-10T13:37:07.402771Z",
     "shell.execute_reply": "2022-06-10T13:37:07.401828Z"
    },
    "papermill": {
     "duration": 0.829211,
     "end_time": "2022-06-10T13:37:07.405652",
     "exception": false,
     "start_time": "2022-06-10T13:37:06.576441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(Config.DATA_PATH + \"train.csv\")\n",
    "df_test = pd.read_csv(Config.DATA_PATH + \"test.csv\")\n",
    "df_titles = pd.read_csv(\"/kaggle/input/cpc-codes/titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80d0e7d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:37:07.426825Z",
     "iopub.status.busy": "2022-06-10T13:37:07.426374Z",
     "iopub.status.idle": "2022-06-10T13:37:07.585589Z",
     "shell.execute_reply": "2022-06-10T13:37:07.584758Z"
    },
    "papermill": {
     "duration": 0.172683,
     "end_time": "2022-06-10T13:37:07.588440",
     "exception": false,
     "start_time": "2022-06-10T13:37:07.415757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.merge(\n",
    "    left = df_test,\n",
    "    right = df_titles[[\"code\", \"title\"]],\n",
    "    how = \"inner\",\n",
    "    left_on = \"context\",\n",
    "    right_on = \"code\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49670347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:37:07.610230Z",
     "iopub.status.busy": "2022-06-10T13:37:07.609849Z",
     "iopub.status.idle": "2022-06-10T13:37:07.688744Z",
     "shell.execute_reply": "2022-06-10T13:37:07.687654Z"
    },
    "papermill": {
     "duration": 0.092014,
     "end_time": "2022-06-10T13:37:07.690923",
     "exception": false,
     "start_time": "2022-06-10T13:37:07.598909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addn_special_tokens = ['[F]', '[B]', '[E]', '[G]', '[D]', '[C]', '[H]', '[A]', '[s]']\n"
     ]
    }
   ],
   "source": [
    "df_train[\"section\"] = df_train.context.str[0]\n",
    "df_test[\"section\"] = df_test.context.str[0]\n",
    "df_train['sectok'] = '[' + df_train.section + ']'\n",
    "df_test['sectok'] = '[' + df_test.section + ']'\n",
    "train_sectoks = set(df_train.sectok.unique())\n",
    "test_sectoks = set(df_test.sectok.unique())\n",
    "sep = '[s]'\n",
    "addn_special_tokens = list(train_sectoks.union(test_sectoks))\n",
    "addn_special_tokens.append(sep)\n",
    "print(f\"addn_special_tokens = {addn_special_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417bfa12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:37:07.719684Z",
     "iopub.status.busy": "2022-06-10T13:37:07.719194Z",
     "iopub.status.idle": "2022-06-10T13:37:07.726421Z",
     "shell.execute_reply": "2022-06-10T13:37:07.725683Z"
    },
    "papermill": {
     "duration": 0.023528,
     "end_time": "2022-06-10T13:37:07.729265",
     "exception": false,
     "start_time": "2022-06-10T13:37:07.705737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_text(tokenizer, with_labels, row):\n",
    "    encoding = tokenizer(\n",
    "        text = row[\"inputs\"],\n",
    "        padding = False,\n",
    "        truncation = True\n",
    "    )\n",
    "    if with_labels:\n",
    "        encoding[\"labels\"] = row[\"score\"]\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55309cc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:37:07.749340Z",
     "iopub.status.busy": "2022-06-10T13:37:07.748914Z",
     "iopub.status.idle": "2022-06-10T13:37:07.758977Z",
     "shell.execute_reply": "2022-06-10T13:37:07.758329Z"
    },
    "papermill": {
     "duration": 0.023013,
     "end_time": "2022-06-10T13:37:07.761183",
     "exception": false,
     "start_time": "2022-06-10T13:37:07.738170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_dataset_for_model(model_name, df):\n",
    "    tokenizer_path = tokenizer_paths[model_name]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, local_files_only=True)\n",
    "    # add section special token to the tokenizer\n",
    "    tokenizer.add_special_tokens({'additional_special_tokens': addn_special_tokens})\n",
    "    # DataCollatorWithPadding pads each batch to the longest sequence length\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)        \n",
    "    # create input column that we will tokenize\n",
    "    df[\"inputs\"] = df.sectok + sep + df.anchor + sep + df.target + sep + df.title \n",
    "    preprocess_test_data = partial(tokenize_text, tokenizer, False)  \n",
    "    ds_test_raw = Dataset.from_pandas(df)\n",
    "    raw_ds_col_names = ds_test_raw.column_names  \n",
    "    ds_test = ds_test_raw.map(preprocess_test_data, batched=True, batch_size=1000, remove_columns=raw_ds_col_names)\n",
    "    return ds_test, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38af20cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:37:07.781901Z",
     "iopub.status.busy": "2022-06-10T13:37:07.781512Z",
     "iopub.status.idle": "2022-06-10T13:37:07.787074Z",
     "shell.execute_reply": "2022-06-10T13:37:07.786195Z"
    },
    "papermill": {
     "duration": 0.02013,
     "end_time": "2022-06-10T13:37:07.791091",
     "exception": false,
     "start_time": "2022-06-10T13:37:07.770961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fold_model(model_path, tokenizer):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path, local_files_only=True)\n",
    "    tok_vocab = tokenizer.get_vocab()\n",
    "    print(f\"len(tokenizer_vocab) = {len(tok_vocab)}\")\n",
    "    model.resize_token_embeddings(len(tok_vocab))    \n",
    "    model.to(Config.DEVICE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7047a1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:37:07.812231Z",
     "iopub.status.busy": "2022-06-10T13:37:07.811838Z",
     "iopub.status.idle": "2022-06-10T13:43:23.702947Z",
     "shell.execute_reply": "2022-06-10T13:43:23.701781Z"
    },
    "papermill": {
     "duration": 375.905504,
     "end_time": "2022-06-10T13:43:23.706449",
     "exception": false,
     "start_time": "2022-06-10T13:37:07.800945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d799d2c78747f08996da289848b7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test predictions using deberta-v3-large fold 0\n",
      "model_path = /kaggle/input/anu-dbv3l/deberta-v3-large/fold0/checkpoint-2280/\n",
      "len(tokenizer_vocab) = 128010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-dbv3l/deberta-v3-large/fold1/checkpoint-2280/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-dbv3l/deberta-v3-large/fold1/checkpoint-2280/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128009\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-dbv3l/deberta-v3-large/fold1/checkpoint-2280/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 0\n",
      "Running test predictions using deberta-v3-large fold 1\n",
      "model_path = /kaggle/input/anu-dbv3l/deberta-v3-large/fold1/checkpoint-2280/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-dbv3l/deberta-v3-large/fold1/checkpoint-2280/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 128010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-dbv3l/deberta-v3-large/fold2/checkpoint-2280/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-dbv3l/deberta-v3-large/fold2/checkpoint-2280/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128009\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-dbv3l/deberta-v3-large/fold2/checkpoint-2280/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 1\n",
      "Running test predictions using deberta-v3-large fold 2\n",
      "model_path = /kaggle/input/anu-dbv3l/deberta-v3-large/fold2/checkpoint-2280/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-dbv3l/deberta-v3-large/fold2/checkpoint-2280/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 128010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-dbv3l/deberta-v3-large/fold3/checkpoint-2280/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-dbv3l/deberta-v3-large/fold3/checkpoint-2280/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128009\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-dbv3l/deberta-v3-large/fold3/checkpoint-2280/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 2\n",
      "Running test predictions using deberta-v3-large fold 3\n",
      "model_path = /kaggle/input/anu-dbv3l/deberta-v3-large/fold3/checkpoint-2280/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-dbv3l/deberta-v3-large/fold3/checkpoint-2280/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 128010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-dbv3l/deberta-v3-large/fold4/checkpoint-2280/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-dbv3l/deberta-v3-large/fold4/checkpoint-2280/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128009\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-dbv3l/deberta-v3-large/fold4/checkpoint-2280/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 3\n",
      "Running test predictions using deberta-v3-large fold 4\n",
      "model_path = /kaggle/input/anu-dbv3l/deberta-v3-large/fold4/checkpoint-2280/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-dbv3l/deberta-v3-large/fold4/checkpoint-2280/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 128010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file /kaggle/input/anu-bfp/bert-for-patents/fold0/checkpoint-2280/vocab.txt\n",
      "loading file /kaggle/input/anu-bfp/bert-for-patents/fold0/checkpoint-2280/tokenizer.json\n",
      "loading file /kaggle/input/anu-bfp/bert-for-patents/fold0/checkpoint-2280/added_tokens.json\n",
      "loading file /kaggle/input/anu-bfp/bert-for-patents/fold0/checkpoint-2280/special_tokens_map.json\n",
      "loading file /kaggle/input/anu-bfp/bert-for-patents/fold0/checkpoint-2280/tokenizer_config.json\n",
      "Assigning ['[F]', '[B]', '[E]', '[G]', '[D]', '[C]', '[H]', '[A]', '[s]'] to the additional_special_tokens key of the tokenizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe70ca607c243e681084e816aee2ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "loading configuration file /kaggle/input/anu-bfp/bert-for-patents/fold0/checkpoint-2280/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-bfp/bert-for-patents/fold0/checkpoint-2280/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39867\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-bfp/bert-for-patents/fold0/checkpoint-2280/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test predictions using bert-for-patents fold 0\n",
      "model_path = /kaggle/input/anu-bfp/bert-for-patents/fold0/checkpoint-2280/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-bfp/bert-for-patents/fold0/checkpoint-2280/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 39868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-bfp/bert-for-patents/fold1/checkpoint-2280/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-bfp/bert-for-patents/fold1/checkpoint-2280/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39867\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-bfp/bert-for-patents/fold1/checkpoint-2280/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 0\n",
      "Running test predictions using bert-for-patents fold 1\n",
      "model_path = /kaggle/input/anu-bfp/bert-for-patents/fold1/checkpoint-2280/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-bfp/bert-for-patents/fold1/checkpoint-2280/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 39868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-bfp/bert-for-patents/fold2/checkpoint-2280/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-bfp/bert-for-patents/fold2/checkpoint-2280/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39867\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-bfp/bert-for-patents/fold2/checkpoint-2280/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test predictions using bert-for-patents fold 2\n",
      "model_path = /kaggle/input/anu-bfp/bert-for-patents/fold2/checkpoint-2280/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-bfp/bert-for-patents/fold2/checkpoint-2280/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 39868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-bfp/bert-for-patents/fold3/checkpoint-2280/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-bfp/bert-for-patents/fold3/checkpoint-2280/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39867\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-bfp/bert-for-patents/fold3/checkpoint-2280/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test predictions using bert-for-patents fold 3\n",
      "model_path = /kaggle/input/anu-bfp/bert-for-patents/fold3/checkpoint-2280/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-bfp/bert-for-patents/fold3/checkpoint-2280/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 39868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-bfp/bert-for-patents/fold4/checkpoint-2280/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-bfp/bert-for-patents/fold4/checkpoint-2280/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"regression\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39867\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-bfp/bert-for-patents/fold4/checkpoint-2280/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test predictions using bert-for-patents fold 4\n",
      "model_path = /kaggle/input/anu-bfp/bert-for-patents/fold4/checkpoint-2280/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-bfp/bert-for-patents/fold4/checkpoint-2280/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 39868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold0/spm.model\n",
      "loading file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold0/added_tokens.json\n",
      "loading file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold0/special_tokens_map.json\n",
      "loading file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold0/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding [MASK] to the vocabulary\n",
      "Adding [A] to the vocabulary\n",
      "Adding [C] to the vocabulary\n",
      "Adding [F] to the vocabulary\n",
      "Adding [H] to the vocabulary\n",
      "Adding [B] to the vocabulary\n",
      "Adding [D] to the vocabulary\n",
      "Adding [E] to the vocabulary\n",
      "Adding [G] to the vocabulary\n",
      "Adding [s] to the vocabulary\n",
      "Assigning ['[F]', '[B]', '[E]', '[G]', '[D]', '[C]', '[H]', '[A]', '[s]'] to the additional_special_tokens key of the tokenizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b1d5a2668c4f9bb841551d21ff82ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold0/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold0/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_head_size\": 64,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"conv_act\": \"gelu\",\n",
      "  \"conv_kernel_size\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1536,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 6144,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1536,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128010\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold0/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test predictions using deberta-v2-xlarge fold 0\n",
      "model_path = /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold0/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 128010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold1/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold1/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_head_size\": 64,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"conv_act\": \"gelu\",\n",
      "  \"conv_kernel_size\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1536,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 6144,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1536,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128010\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold1/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test predictions using deberta-v2-xlarge fold 1\n",
      "model_path = /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold1/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 128010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold2/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold2/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_head_size\": 64,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"conv_act\": \"gelu\",\n",
      "  \"conv_kernel_size\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1536,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 6144,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1536,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128010\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold2/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 1\n",
      "Running test predictions using deberta-v2-xlarge fold 2\n",
      "model_path = /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold2/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold2/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 128010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold3/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold3/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_head_size\": 64,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"conv_act\": \"gelu\",\n",
      "  \"conv_kernel_size\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1536,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 6144,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1536,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128010\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold3/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 2\n",
      "Running test predictions using deberta-v2-xlarge fold 3\n",
      "model_path = /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold3/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold3/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 128010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold4/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold4/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_head_size\": 64,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"conv_act\": \"gelu\",\n",
      "  \"conv_kernel_size\": 3,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1536,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 6144,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1536,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128010\n",
      "}\n",
      "\n",
      "loading weights file /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold4/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test predictions using deberta-v2-xlarge fold 4\n",
      "model_path = /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /kaggle/input/anu-uspppm-deberta-v2-xlarge2/deberta-v2-xlarge/fold4/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer_vocab) = 128010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed predictions for fold 4\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "model_fold_preds = {}\n",
    "for model_name in model_paths.keys():    \n",
    "    fold_preds = []\n",
    "    ds_test, tokenizer = get_test_dataset_for_model(model_name, df_test)    \n",
    "    for fold in range(Config.NUM_FOLDS):\n",
    "        print(f\"Running test predictions using {model_name} fold {fold}\")\n",
    "        model_path = model_paths[model_name] + f\"fold{fold}/\"\n",
    "        if model_name in [Models.DEBERTA_V3_LARGE, Models.BERT_FOR_PATENTS]:\n",
    "            model_path = model_path + \"checkpoint-2280/\"\n",
    "        print(f\"model_path = {model_path}\")\n",
    "        model = get_fold_model(model_path, tokenizer)\n",
    "        trainer_args = TrainingArguments(\n",
    "            output_dir=\"/kaggle/working/model/\",\n",
    "            per_device_eval_batch_size=Config.BATCH_SIZE\n",
    "        )\n",
    "        trainer = Trainer(model=model, tokenizer=tokenizer, args=trainer_args)\n",
    "        outputs = trainer.predict(ds_test)\n",
    "        fold_preds.append(outputs.predictions.reshape(-1))\n",
    "        print(f\"Completed predictions for fold {fold}\")\n",
    "        del model, trainer\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    model_fold_preds[model_name] = fold_preds    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c47e4c",
   "metadata": {
    "papermill": {
     "duration": 0.019699,
     "end_time": "2022-06-10T13:43:23.747131",
     "exception": false,
     "start_time": "2022-06-10T13:43:23.727432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### On test dataset generate predictions using level 1 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d088105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:23.788631Z",
     "iopub.status.busy": "2022-06-10T13:43:23.788225Z",
     "iopub.status.idle": "2022-06-10T13:43:23.800564Z",
     "shell.execute_reply": "2022-06-10T13:43:23.799868Z"
    },
    "papermill": {
     "duration": 0.034884,
     "end_time": "2022-06-10T13:43:23.802260",
     "exception": false,
     "start_time": "2022-06-10T13:43:23.767376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame({\"id\": df_test.id})\n",
    "for model_name in model_paths.keys():\n",
    "    test_preds_arr = np.array(model_fold_preds[model_name])\n",
    "    test_preds_avg = np.mean(test_preds_arr, axis=0)\n",
    "    df_submission.loc[:, f\"{model_name}-preds\"] = test_preds_avg    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5c6d9ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:23.843732Z",
     "iopub.status.busy": "2022-06-10T13:43:23.843176Z",
     "iopub.status.idle": "2022-06-10T13:43:23.848585Z",
     "shell.execute_reply": "2022-06-10T13:43:23.847919Z"
    },
    "papermill": {
     "duration": 0.028279,
     "end_time": "2022-06-10T13:43:23.850336",
     "exception": false,
     "start_time": "2022-06-10T13:43:23.822057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deberta-v3-large-preds', 'bert-for-patents-preds', 'deberta-v2-xlarge-preds']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_cols = df_submission.columns.tolist()\n",
    "test_pred_cols.remove(\"id\")\n",
    "test_pred_cols\n",
    "# df_submission[\"score\"] = df_submission[pred_cols].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263cfacd",
   "metadata": {
    "papermill": {
     "duration": 0.019698,
     "end_time": "2022-06-10T13:43:23.890010",
     "exception": false,
     "start_time": "2022-06-10T13:43:23.870312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Now we will first train a level 2 linear regression model using OOF predictions of different level 1 models on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0125e069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:23.932117Z",
     "iopub.status.busy": "2022-06-10T13:43:23.931453Z",
     "iopub.status.idle": "2022-06-10T13:43:24.464357Z",
     "shell.execute_reply": "2022-06-10T13:43:24.463471Z"
    },
    "papermill": {
     "duration": 0.556367,
     "end_time": "2022-06-10T13:43:24.467023",
     "exception": false,
     "start_time": "2022-06-10T13:43:23.910656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the level1 models OOF predictions on train dataset\n",
    "df_train_oof_bfp = pd.read_csv(oof_preds_paths[Models.BERT_FOR_PATENTS])\n",
    "# df_train_oof_bfp = df_train_oof_bfp[oof_cols_to_use]\n",
    "df_train_oof_dbv3l = pd.read_csv(oof_preds_paths[Models.DEBERTA_V3_LARGE])\n",
    "df_train_oof_dbl = pd.read_csv(oof_preds_paths[Models.DEBERTA_V2_XLARGE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11260b5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:24.509861Z",
     "iopub.status.busy": "2022-06-10T13:43:24.509104Z",
     "iopub.status.idle": "2022-06-10T13:43:24.514917Z",
     "shell.execute_reply": "2022-06-10T13:43:24.514245Z"
    },
    "papermill": {
     "duration": 0.028801,
     "end_time": "2022-06-10T13:43:24.516618",
     "exception": false,
     "start_time": "2022-06-10T13:43:24.487817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rename_val_preds(df, cols_to_use, suffix):\n",
    "    df = df[cols_to_use]\n",
    "    df.rename(columns = {\"val_preds\": \"val_preds_\"+suffix}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f225c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:24.560169Z",
     "iopub.status.busy": "2022-06-10T13:43:24.559403Z",
     "iopub.status.idle": "2022-06-10T13:43:24.622646Z",
     "shell.execute_reply": "2022-06-10T13:43:24.621829Z"
    },
    "papermill": {
     "duration": 0.085896,
     "end_time": "2022-06-10T13:43:24.624410",
     "exception": false,
     "start_time": "2022-06-10T13:43:24.538514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>val_preds_dbv3l</th>\n",
       "      <th>score</th>\n",
       "      <th>kfold</th>\n",
       "      <th>val_preds_bfp</th>\n",
       "      <th>val_preds_dbv2xl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>0.085144</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.00927</td>\n",
       "      <td>0.076599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ef2d4c2e6bbb208d</td>\n",
       "      <td>0.235596</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16370</td>\n",
       "      <td>0.223633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cc96541d4987b399</td>\n",
       "      <td>0.297607</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16700</td>\n",
       "      <td>0.308838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a8c9e9f37d4d836a</td>\n",
       "      <td>0.161621</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11896</td>\n",
       "      <td>0.246094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>604210b7c7ce2f6a</td>\n",
       "      <td>0.525391</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48070</td>\n",
       "      <td>0.515625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  val_preds_dbv3l  score  kfold  val_preds_bfp  \\\n",
       "0  54c1e3b9184cb5b6         0.085144   0.00      0       -0.00927   \n",
       "1  ef2d4c2e6bbb208d         0.235596   0.25      0        0.16370   \n",
       "2  cc96541d4987b399         0.297607   0.00      0        0.16700   \n",
       "3  a8c9e9f37d4d836a         0.161621   0.00      0        0.11896   \n",
       "4  604210b7c7ce2f6a         0.525391   0.50      0        0.48070   \n",
       "\n",
       "   val_preds_dbv2xl  \n",
       "0          0.076599  \n",
       "1          0.223633  \n",
       "2          0.308838  \n",
       "3          0.246094  \n",
       "4          0.515625  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "df_list = [(df_train_oof_dbv3l, \"dbv3l\"), (df_train_oof_bfp, \"bfp\"), (df_train_oof_dbl, \"dbv2xl\")]\n",
    "df_list_renamed = []\n",
    "for idx, (df, suffix) in enumerate(df_list):\n",
    "    cols = [\"id\", \"val_preds\"]\n",
    "    if idx == 0:\n",
    "        cols.append(\"score\")\n",
    "        cols.append(\"kfold\")\n",
    "    df_list_renamed.append(rename_val_preds(df, cols, suffix))\n",
    "df_train_all = functools.reduce(lambda df1, df2: pd.merge(left=df1, right=df2, on=[\"id\"], how=\"inner\"), df_list_renamed)\n",
    "df_train_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c675f6c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:24.667255Z",
     "iopub.status.busy": "2022-06-10T13:43:24.666950Z",
     "iopub.status.idle": "2022-06-10T13:43:24.670668Z",
     "shell.execute_reply": "2022-06-10T13:43:24.669823Z"
    },
    "papermill": {
     "duration": 0.027299,
     "end_time": "2022-06-10T13:43:24.672792",
     "exception": false,
     "start_time": "2022-06-10T13:43:24.645493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Merge different model OOF predictions to create a single dataframe\n",
    "# df_train_all = pd.merge(\n",
    "#     left = df_train_oof_bfp,\n",
    "#     right = df_train_oof_dbv3l[[\"id\", \"val_preds\"]],\n",
    "#     how = \"inner\",\n",
    "#     left_on = \"id\",\n",
    "#     right_on = \"id\",\n",
    "#     suffixes = (\"_bfp\", \"_dbv3l\")\n",
    "# )\n",
    "\n",
    "# df_train_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e66b2c7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:24.714629Z",
     "iopub.status.busy": "2022-06-10T13:43:24.714366Z",
     "iopub.status.idle": "2022-06-10T13:43:24.719587Z",
     "shell.execute_reply": "2022-06-10T13:43:24.718832Z"
    },
    "papermill": {
     "duration": 0.028143,
     "end_time": "2022-06-10T13:43:24.721238",
     "exception": false,
     "start_time": "2022-06-10T13:43:24.693095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_fold_data(fold, df, X_cols, y_col):\n",
    "    df_train = df[df.kfold != fold]\n",
    "    df_val = df[df.kfold == fold]\n",
    "    X_train = df_train[X_cols].to_numpy()\n",
    "    y_train = df_train[y_col].to_numpy()\n",
    "    X_val = df_val[X_cols].to_numpy()\n",
    "    y_val = df_val[y_col].to_numpy()\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "655c661e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:24.762549Z",
     "iopub.status.busy": "2022-06-10T13:43:24.762305Z",
     "iopub.status.idle": "2022-06-10T13:43:24.766177Z",
     "shell.execute_reply": "2022-06-10T13:43:24.765347Z"
    },
    "papermill": {
     "duration": 0.026492,
     "end_time": "2022-06-10T13:43:24.767886",
     "exception": false,
     "start_time": "2022-06-10T13:43:24.741394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Target column (continuous valued)\n",
    "y_col = \"score\"\n",
    "# Input features (OOF predictions) to be used by L2 regression model\n",
    "X_cols_train = [\"val_preds_dbv3l\",\"val_preds_bfp\", \"val_preds_dbv2xl\"]\n",
    "X_cols_test = test_pred_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9c2d242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:24.808952Z",
     "iopub.status.busy": "2022-06-10T13:43:24.808713Z",
     "iopub.status.idle": "2022-06-10T13:43:24.901457Z",
     "shell.execute_reply": "2022-06-10T13:43:24.900771Z"
    },
    "papermill": {
     "duration": 0.115279,
     "end_time": "2022-06-10T13:43:24.903255",
     "exception": false,
     "start_time": "2022-06-10T13:43:24.787976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def run_training(train_X, train_y, val_X, val_y, params=None):    \n",
    "    model = Ridge(alpha=params[\"alpha\"])    \n",
    "    model.fit(train_X, train_y.ravel())\n",
    "    val_y_pred = model.predict(val_X)\n",
    "    #print(f\"val_y_pred.shape = {val_y_pred.shape}\")\n",
    "    #print(f\"val_y.shape = {val_y.shape}\")\n",
    "    p_corr_coeff = np.corrcoef(val_y_pred, val_y)[0][1]    \n",
    "    return p_corr_coeff, model, val_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef098f07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:24.944591Z",
     "iopub.status.busy": "2022-06-10T13:43:24.944344Z",
     "iopub.status.idle": "2022-06-10T13:43:25.131500Z",
     "shell.execute_reply": "2022-06-10T13:43:25.130665Z"
    },
    "papermill": {
     "duration": 0.210497,
     "end_time": "2022-06-10T13:43:25.134068",
     "exception": false,
     "start_time": "2022-06-10T13:43:24.923571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 pearson corr. coeff = 0.8813455538507928\n",
      "fold 1 pearson corr. coeff = 0.8714793770030376\n",
      "fold 2 pearson corr. coeff = 0.8723145829405757\n",
      "fold 3 pearson corr. coeff = 0.8720874415180684\n",
      "fold 4 pearson corr. coeff = 0.858539480612362\n"
     ]
    }
   ],
   "source": [
    "fold_metrics_model = []\n",
    "l2_test_preds = []\n",
    "model_params = {'alpha': 2.0}\n",
    "# test data level 1 predictions to be used as input features by L2 model\n",
    "X_test = df_submission[X_cols_test].to_numpy()\n",
    "\n",
    "for fold in range(Config.NUM_FOLDS):\n",
    "    X_train, y_train, X_val, y_val = get_fold_data(fold, df_train_all, X_cols_train, y_col)\n",
    "    fold_pcc, model, fold_val_preds = run_training(X_train, y_train, X_val, y_val, params=model_params)\n",
    "    print(f\"fold {fold } pearson corr. coeff = {fold_pcc}\")\n",
    "    # add the level 2 validation predictions for the fold to a new column in train data\n",
    "    df_train_all.loc[df_train_all.kfold == fold, \"meta_val_preds\"] = fold_val_preds        \n",
    "    fold_metrics_model.append((round(fold_pcc, 4), model))\n",
    "    fold_test_preds = model.predict(X_test)\n",
    "    l2_test_preds.append(fold_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58d3d3a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:25.211215Z",
     "iopub.status.busy": "2022-06-10T13:43:25.210804Z",
     "iopub.status.idle": "2022-06-10T13:43:25.218219Z",
     "shell.execute_reply": "2022-06-10T13:43:25.217352Z"
    },
    "papermill": {
     "duration": 0.049072,
     "end_time": "2022-06-10T13:43:25.221234",
     "exception": false,
     "start_time": "2022-06-10T13:43:25.172162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 model CV score = 0.8709813043182332\n"
     ]
    }
   ],
   "source": [
    "# Calculate the CV score\n",
    "meta_val_preds = df_train_all['meta_val_preds'].values\n",
    "labels = df_train_all['score'].values\n",
    "p_corr_coeff_cv = np.corrcoef(meta_val_preds, labels)[0][1]    \n",
    "print(f\"L2 model CV score = {p_corr_coeff_cv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6369214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:25.282537Z",
     "iopub.status.busy": "2022-06-10T13:43:25.282289Z",
     "iopub.status.idle": "2022-06-10T13:43:25.287277Z",
     "shell.execute_reply": "2022-06-10T13:43:25.286463Z"
    },
    "papermill": {
     "duration": 0.029042,
     "end_time": "2022-06-10T13:43:25.288901",
     "exception": false,
     "start_time": "2022-06-10T13:43:25.259859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "l2_test_preds_arr = np.array(l2_test_preds)\n",
    "l2_test_preds_avg = np.mean(l2_test_preds_arr, axis=0)\n",
    "df_submission[\"score\"] = l2_test_preds_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f58a5b13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:25.331062Z",
     "iopub.status.busy": "2022-06-10T13:43:25.330796Z",
     "iopub.status.idle": "2022-06-10T13:43:25.339823Z",
     "shell.execute_reply": "2022-06-10T13:43:25.339044Z"
    },
    "papermill": {
     "duration": 0.031813,
     "end_time": "2022-06-10T13:43:25.341541",
     "exception": false,
     "start_time": "2022-06-10T13:43:25.309728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>0.518275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5203a36c501f1b7c</td>\n",
       "      <td>0.737798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7aa5908a77a7ec24</td>\n",
       "      <td>0.341652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09e418c93a776564</td>\n",
       "      <td>0.695098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36baf228038e314b</td>\n",
       "      <td>0.508804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     score\n",
       "0  4112d61851461f60  0.518275\n",
       "1  5203a36c501f1b7c  0.737798\n",
       "2  7aa5908a77a7ec24  0.341652\n",
       "3  09e418c93a776564  0.695098\n",
       "4  36baf228038e314b  0.508804"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission[[\"id\", \"score\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf74d73d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T13:43:25.384864Z",
     "iopub.status.busy": "2022-06-10T13:43:25.384316Z",
     "iopub.status.idle": "2022-06-10T13:43:25.393193Z",
     "shell.execute_reply": "2022-06-10T13:43:25.392498Z"
    },
    "papermill": {
     "duration": 0.031889,
     "end_time": "2022-06-10T13:43:25.394826",
     "exception": false,
     "start_time": "2022-06-10T13:43:25.362937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_submission[[\"id\", \"score\"]].to_csv(\"/kaggle/working/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 397.375108,
   "end_time": "2022-06-10T13:43:28.310531",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-10T13:36:50.935423",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "026428e333aa4e83822f487ed9bd64cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "02f2b95f16b248e7999c0dc29354c209": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "11957cf838ab41f4813db8a7df337d25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "17eed9384db34c35973a07eacd51b6c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_19a8dea70e5d4c1887ce366f269eeae6",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_02f2b95f16b248e7999c0dc29354c209",
       "value": 1.0
      }
     },
     "19a8dea70e5d4c1887ce366f269eeae6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2db6a405f69d4ecaad17bdca9088d347": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f67703dd54c45b292add420d188c6f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b38619899b0c4878a6af13af537ed0b5",
       "placeholder": "",
       "style": "IPY_MODEL_dc5b6993d8eb4285adc335b0220401dc",
       "value": "100%"
      }
     },
     "30b1d5a2668c4f9bb841551d21ff82ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8a0a9995b51d47bcbd2e9ab20ec178ee",
        "IPY_MODEL_17eed9384db34c35973a07eacd51b6c5",
        "IPY_MODEL_651e79525db9495a977a580d5ffa8678"
       ],
       "layout": "IPY_MODEL_a2bcd0084c7b4f40857bc9eb3677aec7"
      }
     },
     "4611771e849c4449bec49cded71a03c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49fd0bba3385467ca6f60b4a40ffacb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5696e2d2ca3243a6a75d2724ee3a4ddd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "60612d8f3e564dfe93db4f6ecfa9af9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7dd920d2e60548e2ae8e68a966d81b01",
       "placeholder": "",
       "style": "IPY_MODEL_c3fe65ca49a74a9bb5786e50b7de3d63",
       "value": " 1/1 [00:00&lt;00:00, 23.47ba/s]"
      }
     },
     "651e79525db9495a977a580d5ffa8678": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e6f8b9773fc0478a9feafb97818c0744",
       "placeholder": "",
       "style": "IPY_MODEL_bd7589ecfb4e4759aebbd10951f22e4c",
       "value": " 1/1 [00:00&lt;00:00, 25.29ba/s]"
      }
     },
     "6c4558ae08874c019467176c6fc636bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "71d799d2c78747f08996da289848b7a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8f26137129ab4a5297712ba34009c100",
        "IPY_MODEL_fed7fce005d248ceaa25de4f295bd6f6",
        "IPY_MODEL_9b5c0f1bfbdc4567a464d73806afd46e"
       ],
       "layout": "IPY_MODEL_4611771e849c4449bec49cded71a03c2"
      }
     },
     "7dd920d2e60548e2ae8e68a966d81b01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e1e242aed0f4132ac97eff50d89a434": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5696e2d2ca3243a6a75d2724ee3a4ddd",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b9ccade89a3e4e58a811e873a83793b0",
       "value": 1.0
      }
     },
     "8a0a9995b51d47bcbd2e9ab20ec178ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2db6a405f69d4ecaad17bdca9088d347",
       "placeholder": "",
       "style": "IPY_MODEL_b104c9d6c102448d9c98197fbc32337f",
       "value": "100%"
      }
     },
     "8f26137129ab4a5297712ba34009c100": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6c4558ae08874c019467176c6fc636bf",
       "placeholder": "",
       "style": "IPY_MODEL_11957cf838ab41f4813db8a7df337d25",
       "value": "100%"
      }
     },
     "9b5c0f1bfbdc4567a464d73806afd46e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_026428e333aa4e83822f487ed9bd64cb",
       "placeholder": "",
       "style": "IPY_MODEL_b7f383b78de94128bb00b7ebcda2a8f4",
       "value": " 1/1 [00:00&lt;00:00, 18.44ba/s]"
      }
     },
     "a2bcd0084c7b4f40857bc9eb3677aec7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b104c9d6c102448d9c98197fbc32337f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b38619899b0c4878a6af13af537ed0b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7f383b78de94128bb00b7ebcda2a8f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b9ccade89a3e4e58a811e873a83793b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bd7589ecfb4e4759aebbd10951f22e4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c3fe65ca49a74a9bb5786e50b7de3d63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "dc5b6993d8eb4285adc335b0220401dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e6f8b9773fc0478a9feafb97818c0744": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebe70ca607c243e681084e816aee2ce2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2f67703dd54c45b292add420d188c6f1",
        "IPY_MODEL_7e1e242aed0f4132ac97eff50d89a434",
        "IPY_MODEL_60612d8f3e564dfe93db4f6ecfa9af9b"
       ],
       "layout": "IPY_MODEL_f706aa11143246bca4ccda454dee3f98"
      }
     },
     "f706aa11143246bca4ccda454dee3f98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa923b7ece6543df949a7727e1d0910f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fed7fce005d248ceaa25de4f295bd6f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_49fd0bba3385467ca6f60b4a40ffacb9",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fa923b7ece6543df949a7727e1d0910f",
       "value": 1.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
