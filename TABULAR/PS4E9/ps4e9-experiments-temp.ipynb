{"cells":[{"cell_type":"code","execution_count":232,"metadata":{"trusted":true},"outputs":[],"source":["# !pip install -U scikit-learn --quiet"]},{"cell_type":"code","execution_count":233,"metadata":{"trusted":true},"outputs":[],"source":["import sys\n","import os\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import optuna\n","import statistics\n","import re\n","from sklearn.preprocessing import StandardScaler, OrdinalEncoder, TargetEncoder\n","from sklearn.impute import SimpleImputer, KNNImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector\n","from functools import partial\n","import lightgbm as lgb\n","from catboost import CatBoostRegressor, Pool\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score\n","from sklearn.model_selection import KFold\n","from lightgbm import log_evaluation, early_stopping\n","import warnings\n","\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"code","execution_count":234,"metadata":{"trusted":true},"outputs":[],"source":["sys.path.append(os.path.abspath(\"/home/bk_anupam/code/ML/ML_UTILS/\"))"]},{"cell_type":"code","execution_count":235,"metadata":{"trusted":true},"outputs":[],"source":["import train_tabular_utils as tt\n","import cv_split_utils\n","import enums\n","from enums import ModelName\n","import data_utils\n","import param_tuning_utils as ptu"]},{"cell_type":"code","execution_count":236,"metadata":{"trusted":true},"outputs":[],"source":["class Config:\n","    RUN_MODE = \"LOCAL\"\n","    RANDOM_SEED = 42\n","    NUM_FOLDS = 5\n","    TARGET_COL_NAME = \"price\"        \n","    SCALER = enums.Scaler.StandardScaler\n","    METRIC = enums.Metrics.RMSE\n","    # These values are more dynamic   \n","    MODEL_TYPE = enums.ModelName.CatBoost\n","    NUM_TUNING_TRIALS = 2\n","    TUNE_ON_SINGLE_FOLD = True\n","    TUNE_STEPWISE = False\n","    TRAIN_SINGLE_FOLD = False    \n","    PERSIST_MODEL = True    \n","    USE_MANUAL_FEATURES = False\n","    USE_ORIGINAL_DATA = True    \n","    FEATURE_SELECTION_METHOD = None\n","    NUM_CLASSES = None\n","\n","COLS_TO_LEAVE = [\"id\", \"price\", \"kfold\", \"target_grp\", \"transmission_speed\", \"is_price_outlier\"]\n","CPU_COUNT = os.cpu_count()\n","\n","DATA_READPATH = \"./data/\"\n","DATA_WRITEPATH = \"./output/\"\n","SUBMISSION_FILEPATH = DATA_READPATH\n","if Config.RUN_MODE == \"KAGGLE\":    \n","    DATA_READPATH = \"/kaggle/input/playground-series-s4e9/\"\n","    if Config.USE_MANUAL_FEATURES:\n","        DATA_READPATH = \"/kaggle/input/ps4e9-fe/\"        \n","    SUBMISSION_FILEPATH = \"/kaggle/input/playground-series-s4e9/\"\n","    DATA_WRITEPATH = \"/kaggle/working/\""]},{"cell_type":"code","execution_count":237,"metadata":{"trusted":true},"outputs":[],"source":["model_static_params = {\n","    enums.ModelName.XGBoost: {\n","        \"objective\": \"reg:squarederror\",\n","        \"eval_metric\": \"rmse\",\n","        \"seed\": Config.RANDOM_SEED,\n","        \"verbosity\": 0,\n","        \"device\": \"cuda\",\n","        \"tree_method\": \"hist\"\n","    },\n","    enums.ModelName.LGBM: {\n","        \"objective\": \"root_mean_squared_error\",\n","        \"metric\": 'rmse',\n","        \"verbosity\": -1,    # <0: fatal, =0: error (warn), =1: info, >1: debug\n","        \"boosting_type\": \"gbdt\",\n","        \"device\":  \"gpu\",\n","        \"gpu_platform_id\": 0,\n","        \"gpu_device_id\": 0\n","    },\n","    enums.ModelName.CatBoost: {\n","        \"objective\": \"RMSE\",\n","        \"verbose\": 0,\n","        \"random_seed\": Config.RANDOM_SEED,\n","        \"eval_metric\": \"RMSE\",\n","        #\"iterations\": 1000,\n","        #\"early_stopping_rounds\": 100,\n","        'grow_policy':  'Lossguide',\n","        'bootstrap_type': 'Poisson',\n","        'task_type': 'GPU'\n","    }\n","}"]},{"cell_type":"code","execution_count":238,"metadata":{"trusted":true},"outputs":[],"source":["# For RandomForest\n","# tuned_model_params = {'n_estimators': 1300, 'max_depth': 17, 'min_samples_leaf': 3, 'min_samples_split': 3, 'max_features': 'sqrt'}\n","# For CatBoost\n","cb_tuned_model_params = {'learning_rate': 0.0026752932092600212, 'n_estimators': 4550, 'max_depth': 6, 'min_data_in_leaf': 73, 'num_leaves': 136, 'subsample': 0.9417643579568004, 'reg_lambda': 99.65892476752238, 'random_strength': 0.6286348851856994, 'early_stopping_rounds': 200, 'max_bin': 57}\n","# For XGBoost\n","xgb_tuned_model_params = {'learning_rate': 0.028614729311166577, 'n_estimators': 3200, 'max_depth': 4, 'min_child_weight': 17, 'subsample': 0.8642950041583155, 'colsample_bytree': 0.6804130458486328, 'reg_lambda': 3.8611185565274893, 'reg_alpha': 9.227741719171974, 'max_leaves': 157, 'early_stopping_rounds': 46, 'max_bin': 64, 'gamma': 1.2844801638262502}\n","# For LGBM\n","lgbm_tuned_model_params = {'learning_rate': 0.04384599885192124, 'n_estimators': 1850, 'max_depth': 4, 'min_data_in_leaf': 79, 'num_leaves': 20, 'min_child_weight': 1.3000000000000003, 'subsample': 0.6909074597205864, 'colsample_bytree': 0.7928274099493369, 'reg_lambda': 178.39029552790532, 'reg_alpha': 1.704574120515208, 'early_stopping_rounds': 200, 'max_bin': 184}\n","\n","# cb_tuned_model_params = None"]},{"cell_type":"code","execution_count":239,"metadata":{"trusted":true},"outputs":[],"source":["def get_train_data():\n","    df_train = pd.read_csv(DATA_READPATH + \"train.csv\")\n","    if Config.USE_ORIGINAL_DATA:\n","        # df_train_orig = pd.read_csv(\"/kaggle/input/used-car-price-prediction-dataset/\" + \"used_cars.csv\")\n","        df_train_orig = pd.read_csv(DATA_READPATH + \"used_cars.csv\")\n","        df_train_orig[['milage', 'price']] = df_train_orig[['milage', 'price']].applymap(lambda x: int(re.sub(\"[^0-9]\", \"\", x)))\n","        df_train_orig['milage'] = df_train_orig['milage'].astype('int64')\n","        df_train_orig['price'] = df_train_orig['price'].astype('int64')\n","        # add df_train_orig rows to df_train\n","        df_train = pd.concat([df_train, df_train_orig], axis=0, ignore_index=True)        \n","    return df_train"]},{"cell_type":"code","execution_count":240,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["df_train.shape: (192542, 13)\n","df_test.shape: (125690, 13)\n","df_combined shape: (318232, 13)\n"]}],"source":["df_train = get_train_data()\n","print(f\"df_train.shape: {df_train.shape}\")\n","df_test = pd.read_csv(DATA_READPATH + \"test.csv\")\n","df_test[\"price\"] = 0\n","print(f\"df_test.shape: {df_test.shape}\")\n","df_combined = pd.concat([df_train, df_test],axis=0,ignore_index=True)\n","print(\"df_combined shape:\", df_combined.shape )\n","# keep a copy of original train and test data for later use\n","df_train_orig = df_train.copy()\n","df_test_orig = df_test.copy()\n","# # drop id column\n","# df_train = df_train.drop(\"id\", axis=1)\n","# df_test = df_test.drop(\"id\", axis=1)"]},{"cell_type":"code","execution_count":241,"metadata":{},"outputs":[],"source":["def extract_age_features(df):\n","    current_year = 2024\n","    df['Vehicle_Age'] = current_year - df['model_year']\n","    # set Vehicle_Age to 1 where Vehicle_Age = 0\n","    df.loc[df['Vehicle_Age'] == 0, 'Vehicle_Age'] = 1\n","    df['Mileage_per_Year'] = df['milage'] / df['Vehicle_Age']\n","    df['milage_with_age'] =  df.groupby('Vehicle_Age')['milage'].transform('mean')\n","    df['Mileage_per_Year_with_age'] =  df.groupby('Vehicle_Age')['Mileage_per_Year'].transform('mean')\n","    return df"]},{"cell_type":"code","execution_count":242,"metadata":{},"outputs":[],"source":["def extract_engine_features(df):\n","    \n","    def extract_horsepower(engine):\n","        try:\n","            return float(engine.split('HP')[0])\n","        except:\n","            return None\n","\n","    def extract_engine_size(engine):\n","        try:\n","            return float(engine.split(' ')[1].replace('L', ''))\n","        except:\n","            return None\n","\n","    df['Horsepower'] = df['engine'].apply(extract_horsepower)\n","    df['Engine_Size'] = df['engine'].apply(extract_engine_size)\n","    df['Power_to_Weight_Ratio'] = df['Horsepower'] / df['Engine_Size']\n","    \n","    return df"]},{"cell_type":"code","execution_count":243,"metadata":{},"outputs":[],"source":["def extract_other_features(df):\n","    luxury_brands = ['Mercedes-Benz', 'Bentley', 'Aston', 'Jaguar', 'Tesla', 'Lamborghini', 'Land', 'RAM', \n","                                'Cadillac', 'Alfa', 'Ferrari', 'Porsche', 'Bugatti', 'McLaren', 'Rolls-Royce', 'Lucid', \n","                                'Maserati', 'Rivian', 'Genesis']\n","    df['is_luxury_brand'] = df['brand'].isin(luxury_brands)\n","    return df    "]},{"cell_type":"code","execution_count":244,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 36.5 ms, sys: 0 ns, total: 36.5 ms\n","Wall time: 36.1 ms\n"]}],"source":["%%time\n","\n","df_train = extract_age_features(df_train)\n","df_test = extract_age_features(df_test)\n","\n","# train = extract_engine_features(train)\n","# test = extract_engine_features(test)\n","\n","df_train = extract_other_features(df_train)\n","df_test = extract_other_features(df_test)"]},{"cell_type":"code","execution_count":245,"metadata":{"trusted":true},"outputs":[],"source":["def update(df):    \n","    t = 100    \n","    cat_c = ['brand','model','fuel_type','engine','transmission','ext_col','int_col','accident','clean_title']\n","    re_ = ['model','engine','transmission','ext_col','int_col']\n","    \n","    for col in re_:\n","        df.loc[df[col].value_counts(dropna=False)[df[col]].values < t, col] = \"noise\"\n","        \n","    for col in cat_c:\n","        df[col] = df[col].fillna('missing')\n","        df[col] = df[col].astype('category')\n","        \n","    return df\n","\n","df_train = update(df_train)\n","df_test = update(df_test)"]},{"cell_type":"code","execution_count":246,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["feature_cols: ['brand', 'model', 'model_year', 'milage', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title', 'Vehicle_Age', 'Mileage_per_Year', 'milage_with_age', 'Mileage_per_Year_with_age', 'is_luxury_brand']\n","cat_cols: ['brand', 'model', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n"]}],"source":["# do not include 'id' column in the list of int columns\n","int_cols = [col for col in df_train.columns if df_train[col].dtypes == 'int64' and col not in COLS_TO_LEAVE]\n","float_cols = [col for col in df_train.columns if df_train[col].dtypes == 'float64']\n","bool_cols = [col for col in df_train.columns if df_train[col].dtypes == 'bool']\n","cat_cols = [col for col in df_train.columns if df_train[col].dtypes in ['object', 'category'] and col not in COLS_TO_LEAVE]\n","feature_cols = [x for x in df_train.columns if x not in COLS_TO_LEAVE]\n","print(f\"feature_cols: {feature_cols}\")\n","print(f\"cat_cols: {cat_cols}\")"]},{"cell_type":"code","execution_count":247,"metadata":{},"outputs":[{"data":{"text/plain":["is_price_outlier\n","0    181418\n","1     11124\n","Name: count, dtype: int64"]},"execution_count":247,"metadata":{},"output_type":"execute_result"}],"source":["# create a new column in df_train called is_price_outlier and set it 1 if price > 99250 else set it to 0\n","df_train['is_price_outlier'] = np.where(df_train['price'] > 99250, 1, 0)\n","df_train['is_price_outlier'].value_counts()"]},{"cell_type":"code","execution_count":248,"metadata":{},"outputs":[],"source":["callbacks = [log_evaluation(period=300), early_stopping(stopping_rounds=200)]\n","\n","def get_is_price_outlier_oof(df, target, lgb_params, model_type='LGBM'):    \n","    oof_predictions = np.zeros(len(df))\n","    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","    models = []\n","    auc_scores = []\n","    \n","    for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n","        print(f\"Training fold {fold + 1}/{5} with {model_type}\")\n","\n","        X_train, X_val = df.iloc[train_idx], df.iloc[val_idx]\n","        y_train, y_val = target.iloc[train_idx], target.iloc[val_idx]\n","        \n","        train_data = lgb.Dataset(X_train, label=y_train)\n","        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)            \n","        model = lgb.train(\n","            lgb_params,\n","            train_data,\n","            valid_sets=[train_data, val_data],\n","            valid_names=['train', 'valid'],\n","            callbacks=callbacks    \n","        )                \n","        models.append(model)                \n","        \n","        pred = model.predict(X_val, num_iteration=model.best_iteration)        \n","        fold_auc = roc_auc_score(y_val, pred)\n","        auc_scores.append(fold_auc)\n","        print(f'{model_type} Fold AUC: {fold_auc}')        \n","        oof_predictions[val_idx] = pred\n","        \n","    print(f'Mean AUC: {np.mean(auc_scores)}')\n","    return oof_predictions, models"]},{"cell_type":"code","execution_count":249,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training fold 1/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Number of positive: 8863, number of negative: 145170\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015485 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1722\n","[LightGBM] [Info] Number of data points in the train set: 154033, number of used features: 16\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.057540 -> initscore=-2.796020\n","[LightGBM] [Info] Start training from score -2.796020\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[40]\ttrain's auc: 0.918758\tvalid's auc: 0.876206\n","LGBM Fold AUC: 0.8762061608901712\n","Training fold 2/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Number of positive: 8985, number of negative: 145048\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014420 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1722\n","[LightGBM] [Info] Number of data points in the train set: 154033, number of used features: 16\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.058332 -> initscore=-2.781508\n","[LightGBM] [Info] Start training from score -2.781508\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[35]\ttrain's auc: 0.915395\tvalid's auc: 0.879147\n","LGBM Fold AUC: 0.8791468984746277\n","Training fold 3/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Number of positive: 8852, number of negative: 145182\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009413 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1722\n","[LightGBM] [Info] Number of data points in the train set: 154034, number of used features: 16\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.057468 -> initscore=-2.797345\n","[LightGBM] [Info] Start training from score -2.797345\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[35]\ttrain's auc: 0.914177\tvalid's auc: 0.889253\n","LGBM Fold AUC: 0.8892533860090115\n","Training fold 4/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Number of positive: 8883, number of negative: 145151\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013734 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1722\n","[LightGBM] [Info] Number of data points in the train set: 154034, number of used features: 16\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.057669 -> initscore=-2.793635\n","[LightGBM] [Info] Start training from score -2.793635\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[15]\ttrain's auc: 0.900155\tvalid's auc: 0.879334\n","LGBM Fold AUC: 0.8793335737289898\n","Training fold 5/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Number of positive: 8913, number of negative: 145121\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016045 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1721\n","[LightGBM] [Info] Number of data points in the train set: 154034, number of used features: 16\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.057864 -> initscore=-2.790057\n","[LightGBM] [Info] Start training from score -2.790057\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[28]\ttrain's auc: 0.910213\tvalid's auc: 0.879484\n","LGBM Fold AUC: 0.8794840924102871\n","Mean AUC: 0.8806848223026174\n"]}],"source":["lgb_params_1 = {\n","    'objective': 'binary',\n","    'n_estimators': 1000,\n","    'random_state': 42,\n","    'metric': 'auc',\n","}\n","\n","X = df_train[feature_cols]\n","y = df_train['is_price_outlier']\n","oof_predictions_lgbm, models_lgbm = get_is_price_outlier_oof(X, y, lgb_params_1, model_type='LGBM')\n","df_train['lgbm_price_outlier_proba'] = oof_predictions_lgbm\n","\n","LGBM_preds = np.zeros(len(df_test[feature_cols]))\n","for model in models_lgbm:\n","    LGBM_preds += model.predict(df_test[feature_cols]) / len(models_lgbm)\n","df_test['lgbm_price_outlier_proba'] = LGBM_preds"]},{"cell_type":"code","execution_count":250,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["feature_cols: ['brand', 'model', 'model_year', 'milage', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title', 'Vehicle_Age', 'Mileage_per_Year', 'milage_with_age', 'Mileage_per_Year_with_age', 'is_luxury_brand', 'lgbm_price_outlier_proba']\n","cat_cols: ['brand', 'model', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n"]}],"source":["cat_cols = [col for col in df_train.columns if df_train[col].dtypes in ['object', 'category'] and col not in COLS_TO_LEAVE]\n","feature_cols = [x for x in df_train.columns if x not in COLS_TO_LEAVE]\n","print(f\"feature_cols: {feature_cols}\")\n","print(f\"cat_cols: {cat_cols}\")"]},{"cell_type":"code","execution_count":251,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training fold 1/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022591 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1977\n","[LightGBM] [Info] Number of data points in the train set: 154033, number of used features: 17\n","[LightGBM] [Info] Start training from score 30775.000000\n","Training until validation scores don't improve for 200 rounds\n","[300]\ttrain's l1: 16259.3\tvalid's l1: 17337.8\n","[600]\ttrain's l1: 15982.5\tvalid's l1: 17337.7\n","Early stopping, best iteration is:\n","[427]\ttrain's l1: 16123.1\tvalid's l1: 17336.5\n","LGBM Fold RMSE: 75981.08997022854\n","Training fold 2/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018207 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1977\n","[LightGBM] [Info] Number of data points in the train set: 154033, number of used features: 17\n","[LightGBM] [Info] Start training from score 30775.000000\n","Training until validation scores don't improve for 200 rounds\n","[300]\ttrain's l1: 16320.8\tvalid's l1: 16978.7\n","[600]\ttrain's l1: 16064.2\tvalid's l1: 16975.4\n","Early stopping, best iteration is:\n","[484]\ttrain's l1: 16154\tvalid's l1: 16972.1\n","LGBM Fold RMSE: 68827.22554858247\n","Training fold 3/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020536 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1977\n","[LightGBM] [Info] Number of data points in the train set: 154034, number of used features: 17\n","[LightGBM] [Info] Start training from score 30950.000000\n","Training until validation scores don't improve for 200 rounds\n","[300]\ttrain's l1: 16303.4\tvalid's l1: 17017.1\n","Early stopping, best iteration is:\n","[278]\ttrain's l1: 16341.1\tvalid's l1: 17015.3\n","LGBM Fold RMSE: 70263.672630004\n","Training fold 4/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017794 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1977\n","[LightGBM] [Info] Number of data points in the train set: 154034, number of used features: 17\n","[LightGBM] [Info] Start training from score 30775.000000\n","Training until validation scores don't improve for 200 rounds\n","[300]\ttrain's l1: 16293.1\tvalid's l1: 17288.3\n","[600]\ttrain's l1: 16001.4\tvalid's l1: 17279.1\n","Early stopping, best iteration is:\n","[549]\ttrain's l1: 16043.9\tvalid's l1: 17276.9\n","LGBM Fold RMSE: 76109.76790519977\n","Training fold 5/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013733 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1976\n","[LightGBM] [Info] Number of data points in the train set: 154034, number of used features: 17\n","[LightGBM] [Info] Start training from score 30900.000000\n","Training until validation scores don't improve for 200 rounds\n","[300]\ttrain's l1: 16239.8\tvalid's l1: 17336\n","[600]\ttrain's l1: 15984.2\tvalid's l1: 17333.2\n","Early stopping, best iteration is:\n","[651]\ttrain's l1: 15936.7\tvalid's l1: 17328.7\n","LGBM Fold RMSE: 76305.33300234229\n","Mean RMSE: 73497.41781127141\n","Training fold 1/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018142 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1977\n","[LightGBM] [Info] Number of data points in the train set: 154033, number of used features: 17\n","[LightGBM] [Info] Start training from score 43824.155038\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[21]\ttrain's l2: 4.80597e+09\tvalid's l2: 5.7067e+09\n","LGBM Fold RMSE: 75542.71271282747\n","Training fold 2/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008979 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1977\n","[LightGBM] [Info] Number of data points in the train set: 154033, number of used features: 17\n","[LightGBM] [Info] Start training from score 43968.700402\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[32]\ttrain's l2: 4.83553e+09\tvalid's l2: 4.66055e+09\n","LGBM Fold RMSE: 68268.22749519588\n","Training fold 3/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009999 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1977\n","[LightGBM] [Info] Number of data points in the train set: 154034, number of used features: 17\n","[LightGBM] [Info] Start training from score 43948.990690\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[19]\ttrain's l2: 5.0343e+09\tvalid's l2: 4.9018e+09\n","LGBM Fold RMSE: 70012.8732097625\n","Training fold 4/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050218 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 1977\n","[LightGBM] [Info] Number of data points in the train set: 154034, number of used features: 17\n","[LightGBM] [Info] Start training from score 43855.835549\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[29]\ttrain's l2: 4.68992e+09\tvalid's l2: 5.70428e+09\n","LGBM Fold RMSE: 75526.65796731824\n","Training fold 5/5 with LGBM\n","[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n","[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007650 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1976\n","[LightGBM] [Info] Number of data points in the train set: 154034, number of used features: 17\n","[LightGBM] [Info] Start training from score 43862.689724\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[30]\ttrain's l2: 4.6534e+09\tvalid's l2: 5.69387e+09\n","LGBM Fold RMSE: 75457.73947676818\n","Mean RMSE: 72961.64217237446\n"]}],"source":["callbacks = [log_evaluation(period=300), early_stopping(stopping_rounds=200)]\n","\n","def get_MAE_oof(df, target, lgb_params, cat_params=None, model_type='LGBM'):    \n","    oof_predictions = np.zeros(len(df))\n","    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","    models = []\n","    rmse_scores = []\n","    \n","    for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n","        print(f\"Training fold {fold + 1}/{5} with {model_type}\")\n","\n","        X_train, X_val = df.iloc[train_idx], df.iloc[val_idx]\n","        y_train, y_val = target.iloc[train_idx], target.iloc[val_idx]\n","\n","        if model_type == 'LGBM':\n","            train_data = lgb.Dataset(X_train, label=y_train)\n","            val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)            \n","            model = lgb.train(\n","                lgb_params,\n","                train_data,\n","                valid_sets=[train_data, val_data],\n","                valid_names=['train', 'valid'],\n","                callbacks=callbacks    \n","            )        \n","        elif model_type == 'CAT':\n","            train_data = Pool(data=X_train, label=y_train , cat_features=cat_cols)\n","            val_data = Pool(data=X_val, label=y_val , cat_features=cat_cols )            \n","            model = CatBoostRegressor(**cat_params)\n","            model.fit(train_data, eval_set=val_data, verbose=150, early_stopping_rounds=200)\n","        \n","        models.append(model)\n","        \n","        if model_type == 'LGBM':\n","            pred = model.predict(X_val, num_iteration=model.best_iteration)\n","        elif model_type == 'CAT':\n","            pred = model.predict(X_val)\n","        \n","        rmse = np.sqrt(mean_squared_error(y_val, pred))\n","        rmse_scores.append(rmse)\n","        print(f'{model_type} Fold RMSE: {rmse}')        \n","        oof_predictions[val_idx] = pred\n","        \n","    print(f'Mean RMSE: {np.mean(rmse_scores)}')\n","    return oof_predictions, models\n","\n","lgb_params = {\n","    'objective': 'MAE',\n","    'n_estimators': 1000,\n","    'random_state': 42,\n","}\n","\n","X = df_train[feature_cols]\n","y = df_train['price']\n","oof_predictions_lgbm, models_lgbm = get_MAE_oof(X, y, lgb_params, model_type='LGBM')\n","df_train['LGBM_MAE'] = oof_predictions_lgbm\n","\n","LGBM_preds = np.zeros(len(df_test[feature_cols]))\n","for model in models_lgbm:\n","    LGBM_preds += model.predict(df_test[feature_cols]) / len(models_lgbm)\n","df_test['LGBM_MAE'] = LGBM_preds\n","\n","lgb_params = {\n","    'objective': 'MSE',\n","    'n_estimators': 1000,\n","    'random_state': 42,\n","}\n","\n","oof_predictions_lgbm, models_lgbm = get_MAE_oof(X, y, lgb_params, model_type='LGBM')\n","df_train['LGBM_MSE_diff'] = oof_predictions_lgbm - df_train['LGBM_MAE']\n","\n","LGBM_preds = np.zeros(len(df_test[feature_cols]))\n","for model in models_lgbm:\n","    LGBM_preds += model.predict(df_test[feature_cols]) / len(models_lgbm)\n","df_test['LGBM_MSE_diff'] = LGBM_preds - df_test['LGBM_MAE']"]},{"cell_type":"code","execution_count":252,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>model_year</th>\n","      <th>milage</th>\n","      <th>price</th>\n","      <th>Vehicle_Age</th>\n","      <th>Mileage_per_Year</th>\n","      <th>milage_with_age</th>\n","      <th>Mileage_per_Year_with_age</th>\n","      <th>is_price_outlier</th>\n","      <th>lgbm_price_outlier_proba</th>\n","      <th>LGBM_MAE</th>\n","      <th>LGBM_MSE_diff</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>188533.000000</td>\n","      <td>192542.000000</td>\n","      <td>192542.000000</td>\n","      <td>1.925420e+05</td>\n","      <td>192542.000000</td>\n","      <td>192542.000000</td>\n","      <td>192542.000000</td>\n","      <td>192542.000000</td>\n","      <td>192542.000000</td>\n","      <td>192542.000000</td>\n","      <td>192542.000000</td>\n","      <td>192542.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>94266.000000</td>\n","      <td>2015.823452</td>\n","      <td>65684.728927</td>\n","      <td>4.389207e+04</td>\n","      <td>8.177421</td>\n","      <td>8684.833645</td>\n","      <td>65684.728927</td>\n","      <td>8684.833645</td>\n","      <td>0.057774</td>\n","      <td>0.057916</td>\n","      <td>35906.340140</td>\n","      <td>8286.823842</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>54424.933488</td>\n","      <td>5.670724</td>\n","      <td>49851.512980</td>\n","      <td>7.881711e+04</td>\n","      <td>5.669542</td>\n","      <td>6251.326532</td>\n","      <td>35495.308987</td>\n","      <td>1107.818872</td>\n","      <td>0.233317</td>\n","      <td>0.101303</td>\n","      <td>23527.828508</td>\n","      <td>11618.404407</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>1974.000000</td>\n","      <td>100.000000</td>\n","      <td>2.000000e+03</td>\n","      <td>1.000000</td>\n","      <td>5.263158</td>\n","      <td>9745.115355</td>\n","      <td>1258.575385</td>\n","      <td>0.000000</td>\n","      <td>0.002808</td>\n","      <td>2763.112810</td>\n","      <td>-45380.402858</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>47133.000000</td>\n","      <td>2013.000000</td>\n","      <td>24115.000000</td>\n","      <td>1.700000e+04</td>\n","      <td>4.000000</td>\n","      <td>5150.000000</td>\n","      <td>34436.373284</td>\n","      <td>8609.093321</td>\n","      <td>0.000000</td>\n","      <td>0.007160</td>\n","      <td>17795.733112</td>\n","      <td>3074.104233</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>94266.000000</td>\n","      <td>2017.000000</td>\n","      <td>57550.000000</td>\n","      <td>3.082500e+04</td>\n","      <td>7.000000</td>\n","      <td>8000.000000</td>\n","      <td>67981.161419</td>\n","      <td>8885.004937</td>\n","      <td>0.000000</td>\n","      <td>0.017169</td>\n","      <td>32353.852109</td>\n","      <td>6226.699267</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>141399.000000</td>\n","      <td>2020.000000</td>\n","      <td>95400.000000</td>\n","      <td>4.990000e+04</td>\n","      <td>11.000000</td>\n","      <td>11000.000000</td>\n","      <td>92817.275956</td>\n","      <td>9522.712359</td>\n","      <td>0.000000</td>\n","      <td>0.055415</td>\n","      <td>47172.774414</td>\n","      <td>10067.435026</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>188532.000000</td>\n","      <td>2024.000000</td>\n","      <td>405000.000000</td>\n","      <td>2.954083e+06</td>\n","      <td>50.000000</td>\n","      <td>235000.000000</td>\n","      <td>134082.653779</td>\n","      <td>9775.812469</td>\n","      <td>1.000000</td>\n","      <td>0.829225</td>\n","      <td>263745.920088</td>\n","      <td>360649.941748</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  id     model_year         milage         price  \\\n","count  188533.000000  192542.000000  192542.000000  1.925420e+05   \n","mean    94266.000000    2015.823452   65684.728927  4.389207e+04   \n","std     54424.933488       5.670724   49851.512980  7.881711e+04   \n","min         0.000000    1974.000000     100.000000  2.000000e+03   \n","25%     47133.000000    2013.000000   24115.000000  1.700000e+04   \n","50%     94266.000000    2017.000000   57550.000000  3.082500e+04   \n","75%    141399.000000    2020.000000   95400.000000  4.990000e+04   \n","max    188532.000000    2024.000000  405000.000000  2.954083e+06   \n","\n","         Vehicle_Age  Mileage_per_Year  milage_with_age  \\\n","count  192542.000000     192542.000000    192542.000000   \n","mean        8.177421       8684.833645     65684.728927   \n","std         5.669542       6251.326532     35495.308987   \n","min         1.000000          5.263158      9745.115355   \n","25%         4.000000       5150.000000     34436.373284   \n","50%         7.000000       8000.000000     67981.161419   \n","75%        11.000000      11000.000000     92817.275956   \n","max        50.000000     235000.000000    134082.653779   \n","\n","       Mileage_per_Year_with_age  is_price_outlier  lgbm_price_outlier_proba  \\\n","count              192542.000000     192542.000000             192542.000000   \n","mean                 8684.833645          0.057774                  0.057916   \n","std                  1107.818872          0.233317                  0.101303   \n","min                  1258.575385          0.000000                  0.002808   \n","25%                  8609.093321          0.000000                  0.007160   \n","50%                  8885.004937          0.000000                  0.017169   \n","75%                  9522.712359          0.000000                  0.055415   \n","max                  9775.812469          1.000000                  0.829225   \n","\n","            LGBM_MAE  LGBM_MSE_diff  \n","count  192542.000000  192542.000000  \n","mean    35906.340140    8286.823842  \n","std     23527.828508   11618.404407  \n","min      2763.112810  -45380.402858  \n","25%     17795.733112    3074.104233  \n","50%     32353.852109    6226.699267  \n","75%     47172.774414   10067.435026  \n","max    263745.920088  360649.941748  "]},"execution_count":252,"metadata":{},"output_type":"execute_result"}],"source":["df_train.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# df['Vehicle_Age'] = current_year - df['model_year']\n","#     df['Mileage_per_Year'] = df['milage'] / df['Vehicle_Age']\n","#     df['milage_with_age'] =  df.groupby('Vehicle_Age')['milage'].transform('mean')\n","#     df['Mileage_per_Year_with_age'] =  df.groupby('Vehicle_Age')['Mileage_per_Year'].transform('mean')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cat_cols = [col for col in df_train.columns if df_train[col].dtypes in ['object', 'category'] and col not in COLS_TO_LEAVE]\n","feature_cols = [x for x in df_train.columns if x not in COLS_TO_LEAVE]\n","print(f\"feature_cols: {feature_cols}\")\n","print(f\"cat_cols: {cat_cols}\")"]},{"cell_type":"code","execution_count":110,"metadata":{"trusted":true},"outputs":[],"source":["df_train = cv_split_utils.strat_kfold_dataframe(df_train, \n","                                                random_state=Config.RANDOM_SEED, \n","                                                num_folds=Config.NUM_FOLDS,\n","                                                target_col_name=Config.TARGET_COL_NAME, \n","                                                n_bins=40)"]},{"cell_type":"code","execution_count":112,"metadata":{"trusted":true},"outputs":[],"source":["# preprocessing\n","preprocessor = None\n","imputation_config = None\n","cat_encoders = {col: [\n","                       OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n","                     ]\n","                    for col in cat_cols\n","                }"]},{"cell_type":"code","execution_count":113,"metadata":{"trusted":true},"outputs":[],"source":["cb_level_params_totune = {\n","    \"1\": [\"learning_rate\", \"n_estimators\"],\n","    \"2\": [\"max_depth\", \"min_data_in_leaf\", \"num_leaves\"],\n","    \"3\": [\"subsample\", \"reg_lambda\", \"random_strength\", \"early_stopping_rounds\", \"max_bin\"]\n","}\n","\n","cb_param_ranges = {\n","    'learning_rate': {'type': 'loguniform', 'min_value': 1e-3, 'max_value': 0.1},    \n","    'max_depth': {'type': 'int', 'min_value': 4, 'max_value': 20},    \n","    # 'subsample': {'type': 'float', 'min_value': 0.2, 'max_value': 1},\n","    'reg_lambda': {'type': 'loguniform', 'min_value': 1e-3, 'max_value': 10},\n","    'random_strength': {'type': 'int', 'min_value': 0, 'max_value': 10}\n","}\n","\n","cb_params_defaults = {\n","    'max_depth': 6,\n","    'min_data_in_leaf': 1,\n","    'subsample': 0.8,\n","    # comment colsample_bylevel for GPU training\n","    #'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1),\n","    'num_leaves': 96,\n","    'reg_lambda': 3,\n","    'random_strength': 1,\n","    'early_stopping_rounds': 100,\n","    'max_bin': 254\n","}"]},{"cell_type":"code","execution_count":114,"metadata":{"trusted":true},"outputs":[],"source":["lgbm_level_params_totune = {\n","    \"1\": [\"learning_rate\", \"n_estimators\", \"max_depth\"],\n","    \"2\": [\"min_data_in_leaf\", \"num_leaves\", \"min_child_weight\"],\n","    \"3\": [\"subsample\", \"colsample_bytree\", \"reg_lambda\", \"reg_alpha\", \"early_stopping_rounds\", \"max_bin\"]\n","}\n","\n","lgbm_param_ranges = {\n","    'learning_rate': {'type': 'float', 'min_value': 0.005, 'max_value': 0.3, 'log': True},\n","    'n_estimators': {'type': 'int', 'min_value': 500, 'max_value': 5000, 'step': 50},\n","    'max_depth': {'type': 'int', 'min_value': 4, 'max_value': 20},\n","    'min_data_in_leaf': {'type': 'int', 'min_value': 5, 'max_value': 100},\n","    'num_leaves': {'type': 'int', 'min_value': 4, 'max_value': 256, 'step': 4},\n","    'min_child_weight': {'type': 'float', 'min_value': 0.1, 'max_value': 10, 'step': 0.2},\n","    'subsample': {'type': 'float', 'min_value': 0.5, 'max_value': 1},\n","    'colsample_bytree': {'type': 'float', 'min_value': 0.5, 'max_value': 1},\n","    'reg_lambda': {'type': 'float', 'min_value': 1, 'max_value': 300},\n","    'reg_alpha': {'type': 'float', 'min_value': 0, 'max_value': 5},    \n","    'early_stopping_rounds': {'type': 'int', 'min_value': 50, 'max_value': 500, 'step': 20},\n","    'max_bin': {'type': 'int', 'min_value': 32, 'max_value': 255}\n","}\n","\n","lgbm_params_defaults = {\n","    'max_depth': 5,\n","    'min_data_in_leaf': 20,\n","    'num_leaves': 31,\n","    'min_child_weight': 1.0,\n","    'subsample': 0.8,    \n","    'colsample_bytree': 0.8,\n","    'reg_lambda': 3,\n","    'reg_alpha': 0,\n","    'random_strength': 1,\n","    'early_stopping_rounds': 100,\n","    'max_bin': 255\n","}"]},{"cell_type":"code","execution_count":115,"metadata":{"trusted":true},"outputs":[],"source":["xgb_level_params_totune = {\n","    \"1\": [\"learning_rate\", \"n_estimators\", \"max_depth\"],\n","    \"2\": [\"min_child_weight\", \"subsample\", \"colsample_bytree\"],\n","    \"3\": [\"reg_lambda\", \"reg_alpha\", \"early_stopping_rounds\", \"max_bin\", \"max_leaves\", \"gamma\"]\n","}\n","\n","xgb_param_ranges = {\n","    'learning_rate': {'type': 'float', 'min_value': 0.005, 'max_value': 0.3, 'log': True},\n","    'n_estimators': {'type': 'int', 'min_value': 100, 'max_value': 5000, 'step': 50},\n","    'max_depth': {'type': 'int', 'min_value': 4, 'max_value': 20},        \n","    'min_child_weight': {'type': 'int', 'min_value': 1, 'max_value': 20},\n","    'subsample': {'type': 'float', 'min_value': 0.5, 'max_value': 1},\n","    'colsample_bytree': {'type': 'float', 'min_value': 0.5, 'max_value': 1},\n","    'reg_lambda': {'type': 'float', 'min_value': 0.01, 'max_value': 10},\n","    'reg_alpha': {'type': 'float', 'min_value': 0.0, 'max_value': 10.0},   \n","    'max_leaves': {'type': 'int', 'min_value': 0, 'max_value': 256}, \n","    'early_stopping_rounds': {'type': 'int', 'min_value': 10, 'max_value': 100},\n","    'max_bin': {'type': 'int', 'min_value': 32, 'max_value': 255},\n","    'gamma': {'type': 'float', 'min_value': 0.0, 'max_value': 10.0}\n","}\n","\n","xgb_params_defaults = {\n","    'max_depth': 5,    \n","    'min_child_weight': 1,\n","    'subsample': 0.8,    \n","    'colsample_bytree': 0.8,\n","    'reg_lambda': 0,\n","    'reg_alpha': 0,    \n","    'early_stopping_rounds': 15,\n","    'max_bin': 255,\n","    'gamma': 0.0,\n","    'max_leaves': 0\n","}"]},{"cell_type":"code","execution_count":116,"metadata":{"trusted":true},"outputs":[],"source":["def get_tuning_params(model_name):\n","    if model_name == enums.ModelName.LGBM:\n","        level_params_totune = lgbm_level_params_totune\n","        param_ranges = lgbm_param_ranges\n","        params_defaults = lgbm_params_defaults\n","    elif model_name == enums.ModelName.CatBoost:\n","        level_params_totune = cb_level_params_totune\n","        param_ranges = cb_param_ranges\n","        params_defaults = cb_params_defaults\n","    elif model_name == enums.ModelName.XGBoost:\n","        level_params_totune = xgb_level_params_totune\n","        param_ranges = xgb_param_ranges\n","        params_defaults = xgb_params_defaults\n","    return level_params_totune, param_ranges, params_defaults"]},{"cell_type":"code","execution_count":117,"metadata":{"trusted":true},"outputs":[],"source":["# if cb_tuned_model_params is None:\n","#     #df = df_train.sample(frac=0.1, random_state=Config.RANDOM_SEED)\n","#     level_params_totune, param_ranges, params_defaults = get_tuning_params(Config.MODEL_TYPE)\n","#     tuned_model_params = ptu.tune_model_params(\n","#                             study_name=Config.MODEL_TYPE + \"_ModelTuning\", \n","#                             study_direction=\"minimize\",\n","#                             num_trials=Config.NUM_TUNING_TRIALS,\n","#                             model_name=Config.MODEL_TYPE,\n","#                             preprocessor=preprocessor,\n","#                             df=df_train,\n","#                             feature_cols=feature_cols,\n","#                             metric=Config.METRIC,\n","#                             target_col_name=Config.TARGET_COL_NAME,\n","#                             single_fold=Config.TUNE_ON_SINGLE_FOLD,\n","#                             num_folds=Config.NUM_FOLDS,\n","#                             imputation_config=imputation_config,\n","#                             cat_features=cat_cols,\n","#                             cat_encoders=cat_encoders,\n","#                             stepwise=Config.TUNE_STEPWISE,\n","#                             level_params_totune=level_params_totune,\n","#                             params_defaults=params_defaults,\n","#                             static_params=model_static_params,\n","#                             param_ranges=param_ranges\n","#                         )\n","#     print(f\"Tuned model params: {tuned_model_params}\")"]},{"cell_type":"code","execution_count":118,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cb_model_params: {'objective': 'RMSE', 'verbose': 0, 'random_seed': 42, 'eval_metric': 'RMSE', 'grow_policy': 'Lossguide', 'bootstrap_type': 'Poisson', 'task_type': 'GPU', 'learning_rate': 0.0026752932092600212, 'n_estimators': 4550, 'max_depth': 6, 'min_data_in_leaf': 73, 'num_leaves': 136, 'subsample': 0.9417643579568004, 'reg_lambda': 99.65892476752238, 'random_strength': 0.6286348851856994, 'early_stopping_rounds': 200, 'max_bin': 57}\n"]}],"source":["model_params = None\n","cb_params_static = model_static_params.get(ModelName.CatBoost)\n","cb_model_params = {**cb_params_static, **cb_tuned_model_params}\n","print(f\"cb_model_params: {cb_model_params}\")    \n","lgbm_params_static = model_static_params.get(ModelName.LGBM)\n","lgbm_model_params = {**lgbm_params_static, **lgbm_tuned_model_params}\n","print(f\"lgbm_model_params: {lgbm_model_params}\")    \n","xgb_params_static = model_static_params.get(ModelName.XGBoost)\n","xgb_model_params = {**xgb_params_static, **xgb_tuned_model_params}\n","print(f\"xgb_model_params: {xgb_model_params}\")    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","cb_fold_metrics_model, df_oof_preds_cb, _ = tt.train_and_validate(\n","        model_name=ModelName.CatBoost,\n","        model_params=cb_model_params,\n","        preprocessor=None,\n","        df=df_train,\n","        feature_cols=feature_cols,\n","        target_col_name=Config.TARGET_COL_NAME,\n","        metric=Config.METRIC,\n","        single_fold=Config.TRAIN_SINGLE_FOLD,\n","        num_folds=Config.NUM_FOLDS,\n","        suppress_print=False,\n","        imputation_config=imputation_config,\n","        cat_features=cat_cols,\n","        cat_encoders=None\n",")"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["tt.persist(\n","    model_name=ModelName.CatBoost, \n","    fold_metrics_model=cb_fold_metrics_model, \n","    df_oof_preds=df_oof_preds_cb, \n","    persist_model=Config.PERSIST_MODEL, \n","    output_path=DATA_WRITEPATH\n",")"]},{"cell_type":"code","execution_count":81,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","lgbm_fold_metrics_model, df_oof_preds_lgbm, _ = tt.train_and_validate(\n","        model_name=ModelName.LGBM,\n","        model_params=lgbm_model_params,\n","        preprocessor=None,\n","        df=df_train,\n","        feature_cols=feature_cols,\n","        target_col_name=Config.TARGET_COL_NAME,\n","        metric=Config.METRIC,\n","        single_fold=Config.TRAIN_SINGLE_FOLD,\n","        num_folds=Config.NUM_FOLDS,\n","        suppress_print=False,\n","        imputation_config=None,\n","        cat_features=None,\n","        cat_encoders=cat_encoders\n",")"]},{"cell_type":"code","execution_count":82,"metadata":{"trusted":true},"outputs":[],"source":["tt.persist(\n","    model_name=ModelName.LGBM, \n","    fold_metrics_model=lgbm_fold_metrics_model, \n","    df_oof_preds=df_oof_preds_lgbm, \n","    persist_model=Config.PERSIST_MODEL, \n","    output_path=DATA_WRITEPATH\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","xgb_fold_metrics_model, df_oof_preds_xgb, _ = tt.train_and_validate(\n","        model_name=ModelName.XGBoost,\n","        model_params=xgb_model_params,\n","        preprocessor=None,\n","        df=df_train,\n","        feature_cols=feature_cols,\n","        target_col_name=Config.TARGET_COL_NAME,\n","        metric=Config.METRIC,\n","        single_fold=Config.TRAIN_SINGLE_FOLD,\n","        num_folds=Config.NUM_FOLDS,\n","        suppress_print=False,\n","        imputation_config=None,\n","        cat_features=None,\n","        cat_encoders=cat_encoders\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tt.persist(\n","    model_name=ModelName.XGBoost, \n","    fold_metrics_model=xgb_fold_metrics_model, \n","    df_oof_preds=df_oof_preds_xgb, \n","    persist_model=Config.PERSIST_MODEL, \n","    output_path=DATA_WRITEPATH\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_oof_preds = pd.DataFrame()\n","df_oof_preds[\"cb_preds\"] = df_oof_preds_cb[\"oof_preds\"]\n","df_oof_preds[\"lgbm_preds\"] = df_oof_preds_lgbm[\"oof_preds\"]\n","df_oof_preds[\"xgb_preds\"] = df_oof_preds_xgb[\"oof_preds\"]\n","df_oof_preds[\"price\"] = df_oof_preds_cb[\"price\"]"]},{"cell_type":"code","execution_count":83,"metadata":{"trusted":true},"outputs":[],"source":["df_test_preds_cb = tt.get_test_preds(cb_fold_metrics_model, df_test, feature_cols, preprocessor=None, num_folds=Config.NUM_FOLDS)\n","df_test_preds_cb.to_csv(DATA_WRITEPATH + f'df_test_preds_{ModelName.CatBoost}.csv',index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# perform categorical encoding for test data\n","if cat_encoders is not None:\n","    for col, encoders in cat_encoders.items():    \n","        for encoder in encoders:\n","            df_train[[col]] = encoder.fit_transform(df_train[[col]], df_train[Config.TARGET_COL_NAME])\n","            df_test[[col]] = encoder.transform(df_test[[col]])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_test_preds_lgbm = tt.get_test_preds(lgbm_fold_metrics_model, df_test, feature_cols, preprocessor=None, num_folds=Config.NUM_FOLDS)\n","df_test_preds_lgbm.to_csv(DATA_WRITEPATH + f'df_test_preds_{ModelName.LGBM}.csv',index=False)\n","df_test_preds_xgb = tt.get_test_preds(xgb_fold_metrics_model, df_test, feature_cols, preprocessor=None, num_folds=Config.NUM_FOLDS)\n","df_test_preds_xgb.to_csv(DATA_WRITEPATH + f'df_test_preds_{ModelName.XGBoost}.csv',index=False)\n","print(f\"Completed prediction for {len(df_test)} test rows\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def rmse_func(weights, oof_preds, target):\n","    pred = (oof_preds * weights).sum(axis=1)\n","    rmse = np.sqrt(1 / len(pred) * ((target - pred)**2).sum())\n","    return rmse"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from scipy.optimize import minimize\n","\n","def optimize_weights(oof_preds, target, initial_weights):    \n","    # Use the squared weights to ensure non-negativity\n","    def objective(squared_weights):\n","        weights = squared_weights**2\n","        weights /= np.sum(weights)  # Normalize to sum to 1\n","        return rmse_func(weights, oof_preds, target)\n","\n","    # Optimize using SLSQP method which supports constraints\n","    res = minimize(\n","        objective,\n","        np.sqrt(initial_weights),  # Use square root of initial weights\n","        method='SLSQP',\n","        # constraints is a list of dictionaries each with keys 'type' and 'fun'\n","        # type can be 'eq' for equality or 'ineq' for inequality\n","        # Equality constraint means that the constraint function result is to be zero whereas \n","        # inequality means that it is to be non-negative\n","        constraints={'type': 'eq', 'fun': lambda w: np.sum(w**2) - 1},\n","        options={'ftol': 1e-9, 'disp': True}\n","    )\n","\n","    # Square the optimized weights and normalize\n","    optimized_weights = res.x**2\n","    optimized_weights /= np.sum(optimized_weights)\n","    \n","    return optimized_weights, res.fun"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example usage\n","n_models = 3\n","pred_cols = [\"cb_preds\", \"lgbm_preds\", \"xgb_preds\"]\n","initial_weights = np.ones(n_models) / n_models\n","target = df_oof_preds[Config.TARGET_COL_NAME]\n","\n","model_weights, rmse = optimize_weights(df_oof_preds[pred_cols].to_numpy(), target, initial_weights)\n","\n","print(\"Optimal Model Weights:\", model_weights)\n","print(\"Optimal RMSE:\", rmse)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_oof_preds[\"ensemble_preds\"] = model_weights[0] * df_oof_preds[\"cb_preds\"] + model_weights[1] * df_oof_preds[\"lgbm_preds\"] + model_weights[2] * df_oof_preds[\"xgb_preds\"]\n","rmse = np.sqrt(1 / len(df_oof_preds) * ((df_oof_preds[\"price\"] - df_oof_preds[\"ensemble_preds\"])**2).sum())\n","print(\"Ensemble RMSE:\", rmse)"]},{"cell_type":"code","execution_count":84,"metadata":{"trusted":true},"outputs":[],"source":["df_submission = pd.read_csv(SUBMISSION_FILEPATH + 'sample_submission.csv')\n","df_submission[Config.TARGET_COL_NAME] = model_weights[0] * df_test_preds_cb[\"test_preds\"] + model_weights[1] * df_test_preds_lgbm['test_preds'] + + model_weights[2] * df_test_preds_xgb[\"test_preds\"]\n","df_submission.to_csv(DATA_WRITEPATH + f'submission_CB_LGBM.csv',index=False)\n","df_submission.head()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":9057646,"sourceId":76728,"sourceType":"competition"},{"datasetId":5673520,"sourceId":9427097,"sourceType":"datasetVersion"},{"datasetId":3742543,"sourceId":6478229,"sourceType":"datasetVersion"},{"sourceId":177547654,"sourceType":"kernelVersion"},{"sourceId":197880835,"sourceType":"kernelVersion"},{"sourceId":198322424,"sourceType":"kernelVersion"},{"sourceId":198481075,"sourceType":"kernelVersion"},{"sourceId":198545748,"sourceType":"kernelVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
