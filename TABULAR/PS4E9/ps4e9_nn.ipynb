{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, TargetEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from functools import partial\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"/home/bk_anupam/code/ML/ML_UTILS/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_tabular_utils as tt\n",
    "import cv_split_utils\n",
    "import enums\n",
    "from enums import ModelName\n",
    "import data_utils\n",
    "import param_tuning_utils as ptu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RUNTIME = \"LOCAL\"\n",
    "    RANDOM_SEED = 42\n",
    "    NUM_FOLDS = 5\n",
    "    TARGET_COL_NAME = \"price\"            \n",
    "    METRIC = enums.Metrics.RMSE\n",
    "    # These values are more dynamic   \n",
    "    MODEL_TO_USE = ModelName.TabNetRegressor    \n",
    "    TRAIN_SINGLE_FOLD = True    \n",
    "    PERSIST_MODEL = False    \n",
    "    USE_MANUAL_FEATURES = False\n",
    "    USE_ORIGINAL_DATA = False        \n",
    "\n",
    "COLS_TO_LEAVE = [\"id\", \"price\", \"kfold\", \"transmission_speed\", \"target_grp\"]\n",
    "CPU_COUNT = os.cpu_count()\n",
    "\n",
    "DATA_READPATH = \"./data/\"\n",
    "DATA_WRITEPATH = \"./output/\"\n",
    "SUBMISSION_FILEPATH = DATA_READPATH\n",
    "if Config.RUNTIME == \"KAGGLE\":    \n",
    "    DATA_READPATH = \"/kaggle/input/playground-series-s4e9/\"\n",
    "    if Config.USE_MANUAL_FEATURES:\n",
    "        DATA_READPATH = \"/kaggle/input/ps4e9-fe/\"\n",
    "    SUBMISSION_FILEPATH = \"/kaggle/input/playground-series-s4e9/\"\n",
    "    DATA_WRITEPATH = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# parameters for tabnet\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mTabNetConfig\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mWEIGHT_DECAY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m    \u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m, in \u001b[0;36mTabNetConfig\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m NUM_WORKERS \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mcpu_count()\n\u001b[1;32m      8\u001b[0m NUM_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m    \n\u001b[0;32m----> 9\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/cuda/__init__.py:128\u001b[0m, in \u001b[0;36mis_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m device_count() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# The default availability inspection never throws and returns 0 if the driver is missing or can't\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# be initialized. This uses the CUDA Runtime API `cudaGetDeviceCount` which in turn initializes the CUDA Driver\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# API via `cuInit`\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_getDeviceCount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parameters for tabnet\n",
    "class TabNetConfig:\n",
    "    PATIENCE = 10\n",
    "    WEIGHT_DECAY = 1e-6    \n",
    "    PRECISION = \"16-mixed\"\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_WORKERS = mp.cpu_count()\n",
    "    NUM_EPOCHS = 2    \n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
    "\n",
    "class SchedulerConfig:\n",
    "    # for ReduceLROnPlateau (number of epochs with no improvement after which the learning rate will be reduced)\n",
    "    SCHEDULER_PATIENCE = 5  \n",
    "    # for ReduceLROnPlateau (factor by which the learning rate will be reduced)\n",
    "    FACTOR = 0.5 \n",
    "    SCHEDULER = \"ReduceLROnPlateau\"\n",
    "    T_0 = 10 # for CosineAnnealingWarmRestarts (Number of epochs before the first restart)\n",
    "    MIN_LR = 5e-7 # for CosineAnnealingWarmRestarts (Minimum learning rate)\n",
    "    T_mult = 1 # for CosineAnnealingWarmRestarts (Factor by which Ti(number of epochs between two restarts) increases)\n",
    "    MAX_LR = 1e-2 # for CosineAnnealing (Initial learning rate)\n",
    "    STEPS_PER_EPOCH = 13 # for OneCycleLR\n",
    "    STEP_SIZE = 3 # for StepLR\n",
    "    GAMMA = 0.1 # for StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbConfig:\n",
    "    WANDB_KEY = \"c5e2877bf080e6b62fcc57231c91e3a1455f97d0\"\n",
    "    WANDB_RUN_NAME = \"tabnet_cv_5folds\"\n",
    "    WANDB_PROJECT = \"ps4e9_nn\"\n",
    "    USE_WANDB = False        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_to_dict(cfg):\n",
    "    # dir is an inbuilt python function that returns the list of attributes and methods of any object\n",
    "    return dict((name, getattr(cfg, name)) for name in dir(cfg) if not name.startswith('__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = config_to_dict(Config)\n",
    "tabnet_config_dict = config_to_dict(TabNetConfig)\n",
    "schd_config_dict = config_to_dict(SchedulerConfig)\n",
    "wandb_config_dict = config_to_dict(WandbConfig)\n",
    "merged_config_dict = {**config_dict, **tabnet_config_dict, **schd_config_dict, **wandb_config_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.USE_MANUAL_FEATURES and not Config.USE_ORIGINAL_DATA:\n",
    "    df_train = pd.read_csv(DATA_READPATH + \"train_preprocessed.csv\")\n",
    "    df_test = pd.read_csv(DATA_READPATH + \"test_preprocessed.csv\")        \n",
    "    # remove rows where price > 2000000\n",
    "    # df_train = df_train[df_train['price'] <= 2000000]\n",
    "elif Config.USE_MANUAL_FEATURES and Config.USE_ORIGINAL_DATA:\n",
    "    df_train = pd.read_csv(DATA_READPATH + \"train_withorig_preprocessed.csv\")\n",
    "    df_test = pd.read_csv(DATA_READPATH + \"test_withorig_preprocessed.csv\")\n",
    "else:\n",
    "    df_train = pd.read_csv(DATA_READPATH + \"train.csv\")\n",
    "    print(f\"df_train.shape: {df_train.shape}\")\n",
    "    df_test = pd.read_csv(DATA_READPATH + \"test.csv\")\n",
    "    df_test[\"price\"] = 0\n",
    "    print(f\"df_test.shape: {df_test.shape}\")\n",
    "    df_combined = pd.concat([df_train, df_test],axis=0,ignore_index=True)\n",
    "    print(\"df_combined shape:\", df_combined.shape )\n",
    "# keep a copy of original train and test data for later use\n",
    "df_train_orig = df_train.copy()\n",
    "df_test_orig = df_test.copy()\n",
    "# # drop id column\n",
    "# df_train = df_train.drop(\"id\", axis=1)\n",
    "# df_test = df_test.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in df_combined.columns if not c in COLS_TO_LEAVE ]\n",
    "num_cols = ['milage']\n",
    "cat_cols = [c for c in feature_cols if not c in num_cols]\n",
    "cat_idxs = [ i for i, f in enumerate(feature_cols) if f in cat_cols]\n",
    "print(\"Feature columns:\", feature_cols)\n",
    "print(\"Categorical features:\", cat_cols )\n",
    "print(\"Numerical features:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.get_col_stats(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numerical features\n",
    "print(\"STANDARDIZING: \",end=\"\")\n",
    "for col in num_cols:\n",
    "    print(col, \", \", end=\"\")\n",
    "    scaler = StandardScaler()\n",
    "    df_combined[[col]] = scaler.fit_transform(df_combined[[col]])\n",
    "    # after standardization the mean of the numerical column is 0, so filling missing values with 0 instead of mean\n",
    "    df_combined[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode categorical features\n",
    "print(\"LABEL ENCODING: \")\n",
    "# number of unique categories in each categorical column\n",
    "cat_cols_dims = {}\n",
    "# categorical embedding size for each categorical column\n",
    "cat_cols_emb = {}\n",
    "val_cnt = None\n",
    "col_rare_cat = {}\n",
    "for col in cat_cols:    \n",
    "    le = LabelEncoder()\n",
    "    df_combined[col] = le.fit_transform(df_combined[col])\n",
    "    col_num_cat = len(le.classes_)\n",
    "    col_min = df_combined[col].min()\n",
    "    col_max = df_combined[col].max()\n",
    "    val_cnt = df_combined[col].value_counts()\n",
    "    col_rare_cat[col] = val_cnt.loc[val_cnt < 40].index.values\n",
    "    # Increment the encoding by 1 as 0 will be used for rare categories\n",
    "    df_combined[col] += 1\n",
    "    # Replace rare categories in the column with 0\n",
    "    df_combined.loc[df_combined[col].isin(col_rare_cat[col]), col] = 0\n",
    "    # add one for rare categories\n",
    "    col_num_cat = (col_max+1)+1    \n",
    "    cat_cols_dims[col] = col_num_cat\n",
    "    cat_cols_emb[col] = int(np.ceil(np.sqrt(col_num_cat)))\n",
    "    print(f'{col}: col_num_cat={col_num_cat}, min={col_min}, max={col_max}, num_rare_cat={len(col_rare_cat[col])},'\n",
    "          f' emb_size={cat_cols_emb[col]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_combined.iloc[:len(df_train)]\n",
    "test = df_combined.iloc[len(df_train):]\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    # COMPARE TEST CAT VALUES TO TRAIN CAT VALUES\n",
    "    A = train[col].unique()\n",
    "    B = test[col].unique()\n",
    "    C = np.setdiff1d(B,A)\n",
    "    print(f\"{col}: Test has label encodes = {C} which are not in train.\")\n",
    "    if len(C) > 0:\n",
    "        print(f\" => {len(test.loc[test[col].isin(C)])} rows\" )\n",
    "        \n",
    "    # RELABEL UNSEEN TEST VALUES AS ZERO\n",
    "    test.loc[test[col].isin(C), col] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cv_split_utils.strat_kfold_dataframe(train, \n",
    "                                            random_state=Config.RANDOM_SEED, \n",
    "                                            num_folds=Config.NUM_FOLDS,\n",
    "                                            target_col_name=Config.TARGET_COL_NAME, \n",
    "                                            n_bins=25)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do not include 'id' column in the list of int columns\n",
    "# int_cols = [col for col in df_train.columns if df_train[col].dtypes == 'int64' and col not in COLS_TO_LEAVE]\n",
    "# float_cols = [col for col in df_train.columns if df_train[col].dtypes == 'float64']\n",
    "# bool_cols = [col for col in df_train.columns if df_train[col].dtypes == 'bool']\n",
    "# cat_cols = [col for col in df_train.columns if df_train[col].dtypes == 'object' and col not in COLS_TO_LEAVE]\n",
    "# feature_cols = [x for x in df_train.columns if x not in COLS_TO_LEAVE]\n",
    "# cat_idxs = [ i for i, f in enumerate(feature_cols) if f in cat_cols]\n",
    "# print(f\"feature_cols = {feature_cols}\")\n",
    "# print(f\"cat_cols = {cat_cols}\")\n",
    "# print(f\"cat_idxs = {cat_idxs}\")\n",
    "# print(f\"int_cols = {int_cols}\")\n",
    "# print(f\"float_cols = {float_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation_config = {\n",
    "#         'horsepower': SimpleImputer(strategy=\"median\"),\n",
    "#         'capacity': SimpleImputer(strategy=\"median\"),\n",
    "#         'cylinders': SimpleImputer(strategy=\"median\"),\n",
    "#         'transmission_speed': SimpleImputer(strategy=\"median\"),\n",
    "#     }\n",
    "# for column, imputer in imputation_config.items():\n",
    "#     imputer.fit(df_train[[column]])\n",
    "#     df_train[column] = imputer.transform(df_train[[column]])\n",
    "#     if column != 'horsepower':\n",
    "#         # convert column datatype to int\n",
    "#         df_train[column] = df_train[column].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Handle categorical columns\n",
    "# cat_cols = df_train.select_dtypes(include=['object']).columns\n",
    "# cat_cols_dims = {}\n",
    "# for col in cat_cols:\n",
    "#     le = LabelEncoder()\n",
    "#     df_train[col] = le.fit_transform(df_train[col].astype(str))\n",
    "#     cat_cols_dims[col] = len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale numerical features\n",
    "# scaler = StandardScaler()\n",
    "# num_cols = int_cols + float_cols\n",
    "# df_train[num_cols] = scaler.fit_transform(df_train[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"turbo\"] = df_train[\"turbo\"].astype(int)\n",
    "# df_train[\"hybrid\"] = df_train[\"hybrid\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "oof = np.zeros(len(train))\n",
    "pred = np.zeros(len(test))\n",
    "kf = KFold(n_splits=Config.NUM_FOLDS, random_state=Config.RANDOM_SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.MODEL_TO_USE == ModelName.TabNetRegressor:\n",
    "    # 2. Cross-validation setup\n",
    "    X = train[feature_cols].values\n",
    "    y = train[Config.TARGET_COL_NAME].values.reshape(-1, 1)\n",
    "    # 3. Model training and evaluation\n",
    "    rmse_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "        print(\"#\"*25)\n",
    "        print(f\"### Fold {fold+1} ###\")\n",
    "        print(\"#\"*25)\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # By default, PyTorch TabNet uses:cat_emb_dim = min(50, (cat_dim + 1) // 2) if cat_emb_dim is not specified.    \n",
    "        model = TabNetRegressor(\n",
    "            n_d=64, n_a=64, n_steps=5,\n",
    "            gamma=1.5, n_independent=2, n_shared=2,\n",
    "            cat_idxs=cat_idxs, cat_dims=list(cat_cols_dims.values()),\n",
    "            lambda_sparse=1e-3, momentum=0.3, clip_value=2.,\n",
    "            optimizer_fn=torch.optim.Adam,\n",
    "            optimizer_params=dict(lr=SchedulerConfig.MAX_LR, weight_decay=TabNetConfig.WEIGHT_DECAY),\n",
    "            scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "            scheduler_params=dict(step_size=SchedulerConfig.STEP_SIZE, gamma=SchedulerConfig.GAMMA),\n",
    "            # scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            # scheduler_params=dict(mode=\"min\",\n",
    "            #                       patience=SchedulerConfig.SCHEDULER_PATIENCE,\n",
    "            #                       min_lr=SchedulerConfig.MIN_LR,\n",
    "            #                       factor=SchedulerConfig.FACTOR),\n",
    "            # scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "            # scheduler_params=dict(T_0=SchedulerConfig.T_0,\n",
    "            #                       T_mult=SchedulerConfig.T_mult,\n",
    "            #                       eta_min=SchedulerConfig.MIN_LR),\n",
    "            mask_type='sparsemax',\n",
    "            device_name=TabNetConfig.DEVICE        \n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            max_epochs=TabNetConfig.NUM_EPOCHS,\n",
    "            patience=TabNetConfig.PATIENCE,\n",
    "            batch_size=TabNetConfig.BATCH_SIZE,\n",
    "            virtual_batch_size=128,\n",
    "            num_workers=TabNetConfig.NUM_WORKERS,\n",
    "            drop_last=False,\n",
    "            eval_metric=[\"rmse\"]\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))        \n",
    "        rmse_scores.append(rmse)        \n",
    "        print(f\"RMSE: {rmse:.4f}\")    \n",
    "        oof[val_idx] = y_pred\n",
    "        print()\n",
    "        if Config.TRAIN_SINGLE_FOLD:\n",
    "            break\n",
    "        \n",
    "        # TEST PREDS    \n",
    "        test_preds = model.predict(test[feature_cols].values)\n",
    "        test_preds = test_preds.flatten()\n",
    "        \n",
    "        if fold == 0:\n",
    "            pred = test_preds\n",
    "        else:\n",
    "            pred += test_preds\n",
    "\n",
    "    pred /= Config.NUM_FOLDS\n",
    "    # Print and log average scores\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    std_rmse = np.std(rmse_scores)\n",
    "    print(f\"Average RMSE: {avg_rmse:.4f} (+/- {std_rmse:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNetwork(nn.Module):\n",
    "    def __init__(self, cat_sizes, cat_emb_sizes, num_features):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(cat_size, emb_size) \n",
    "                                         for cat_size, emb_size in zip(cat_sizes, cat_emb_sizes)])\n",
    "        \n",
    "        total_emb_size = sum(cat_emb_sizes) + num_features\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(total_emb_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, cat_inputs, num_inputs):\n",
    "        emb_outputs = [emb(cat_inputs[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        emb_outputs = torch.cat(emb_outputs, dim=1)\n",
    "        combined = torch.cat([emb_outputs, num_inputs], dim=1)\n",
    "        return self.fc_layers(combined)\n",
    "\n",
    "def build_model(cat_sizes, cat_emb_sizes, num_features):\n",
    "    return EmbeddingNetwork(cat_sizes, cat_emb_sizes, num_features)\n",
    "\n",
    "def rmse_metric(predictions, targets):\n",
    "    return torch.sqrt(torch.mean((predictions - targets) ** 2))\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, optimizer, scheduler, criterion, eval_metric, device, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for cat_inputs, num_inputs, targets in train_loader:\n",
    "            cat_inputs, num_inputs, targets = cat_inputs.to(device), num_inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(cat_inputs, num_inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        valid_metric = 0\n",
    "        with torch.no_grad():\n",
    "            for cat_inputs, num_inputs, targets in valid_loader:\n",
    "                cat_inputs, num_inputs, targets = cat_inputs.to(device), num_inputs.to(device), targets.to(device)\n",
    "                outputs = model(cat_inputs, num_inputs)\n",
    "                valid_loss += criterion(outputs, targets).item()\n",
    "                valid_metric += eval_metric(outputs, targets).item()\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print epoch results including the current learning rate and evaluation metric\n",
    "        print(f'Epoch {epoch+1}/{epochs}, '\n",
    "              f'Validation Loss: {valid_loss/len(valid_loader):.6f}, '\n",
    "              f'Validation Metric: {valid_metric/len(valid_loader):.6f}, '\n",
    "              f'Learning Rate: {scheduler.get_last_lr()[0]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_dataloaders(fold, df, cat_cols, num_cols, target_col_name):\n",
    "    df_train_fold = df[df[\"kfold\"] != fold].reset_index(drop=True)\n",
    "    df_val_fold = df[df[\"kfold\"] == fold].reset_index(drop=True)\n",
    "    X_train_cats = torch.LongTensor(df_train_fold.loc[:, cat_cols].values)\n",
    "    X_train_nums = torch.FloatTensor(df_train_fold.loc[:, num_cols].values)\n",
    "    y_train = torch.FloatTensor(df_train_fold.loc[:, target_col_name].values).unsqueeze(1)\n",
    "    X_valid_cats = torch.LongTensor(df_val_fold.loc[:, cat_cols].values)\n",
    "    X_valid_nums = torch.FloatTensor(df_val_fold.loc[:, num_cols].values)\n",
    "    y_valid = torch.FloatTensor(df_val_fold.loc[:, target_col_name].values).unsqueeze(1)\n",
    "    train_dataset = TensorDataset(X_train_cats, X_train_nums, y_train)\n",
    "    valid_dataset = TensorDataset(X_valid_cats, X_valid_nums, y_valid)        \n",
    "    train_loader = DataLoader(train_dataset, batch_size=TabNetConfig.BATCH_SIZE, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=TabNetConfig.BATCH_SIZE)\n",
    "    return train_loader, valid_loader, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 1\n",
    "if Config.MODEL_TO_USE == ModelName.NeuralNet:\n",
    "    rmse_scores = []        \n",
    "    for i, (train_index, val_index) in enumerate(kf.split(train)):\n",
    "        print(\"#\"*25)\n",
    "        print(f\"### Fold {i+1} ###\")\n",
    "        print(\"#\"*25)\n",
    "\n",
    "        X_train_cats = torch.LongTensor(train.loc[train_index, cat_cols].values)\n",
    "        X_train_nums = torch.FloatTensor(train.loc[train_index, num_cols].values)\n",
    "        y_train = torch.FloatTensor(train.loc[train_index, \"price\"].values).unsqueeze(1)\n",
    "\n",
    "        X_valid_cats = torch.LongTensor(train.loc[val_index, cat_cols].values)\n",
    "        X_valid_nums = torch.FloatTensor(train.loc[val_index, num_cols].values)\n",
    "        y_valid = torch.FloatTensor(train.loc[val_index, \"price\"].values).unsqueeze(1)\n",
    "\n",
    "        X_test_cats = torch.LongTensor(test[cat_cols].values)\n",
    "        X_test_nums = torch.FloatTensor(test[num_cols].values)\n",
    "\n",
    "        train_dataset = TensorDataset(X_train_cats, X_train_nums, y_train)\n",
    "        valid_dataset = TensorDataset(X_valid_cats, X_valid_nums, y_valid)\n",
    "        test_dataset = TensorDataset(X_test_cats, X_test_nums)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=TabNetConfig.BATCH_SIZE, shuffle=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=TabNetConfig.BATCH_SIZE)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=512)\n",
    "\n",
    "        CAT_SIZE = list(cat_cols_dims.values())\n",
    "        CAT_EMB = list(cat_cols_emb.values())\n",
    "        model = build_model(CAT_SIZE, CAT_EMB, len(num_cols)).to(TabNetConfig.DEVICE)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=SchedulerConfig.MAX_LR)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=SchedulerConfig.STEP_SIZE, \n",
    "                                                    gamma=SchedulerConfig.GAMMA)\n",
    "        criterion = nn.MSELoss()\n",
    "        eval_metric = rmse_metric\n",
    "\n",
    "        train_model(model, \n",
    "                    train_loader, valid_loader, optimizer, \n",
    "                    scheduler=scheduler,\n",
    "                    criterion=criterion, \n",
    "                    device=TabNetConfig.DEVICE, \n",
    "                    epochs=TabNetConfig.NUM_EPOCHS,\n",
    "                    eval_metric=eval_metric)\n",
    "\n",
    "        torch.save(model.state_dict(), f'{DATA_WRITEPATH}/NN_v{VER}_f{i}.weights.pth')\n",
    "        \n",
    "        # OOF PREDS\n",
    "        model.eval()\n",
    "        oof_preds = []\n",
    "        with torch.no_grad():\n",
    "            for cat_inputs, num_inputs, _ in valid_loader:\n",
    "                cat_inputs, num_inputs = cat_inputs.to(TabNetConfig.DEVICE), num_inputs.to(TabNetConfig.DEVICE)\n",
    "                outputs = model(cat_inputs, num_inputs)\n",
    "                oof_preds.extend(outputs.cpu().numpy().flatten())\n",
    "\n",
    "        oof_preds = np.array(oof_preds)\n",
    "        rmse = np.sqrt(np.mean((oof_preds - y_valid.numpy().flatten())**2))\n",
    "        rmse_scores.append(rmse)\n",
    "        print(f' => RMSE = {rmse}\\n')\n",
    "        oof[val_index] = oof_preds\n",
    "        \n",
    "        if Config.TRAIN_SINGLE_FOLD:\n",
    "            break\n",
    "\n",
    "        # TEST PREDS\n",
    "        test_preds = []\n",
    "        with torch.no_grad():\n",
    "            for cat_inputs, num_inputs in test_loader:\n",
    "                cat_inputs, num_inputs = cat_inputs.to(TabNetConfig.DEVICE), num_inputs.to(TabNetConfig.DEVICE)\n",
    "                outputs = model(cat_inputs, num_inputs)\n",
    "                test_preds.extend(outputs.cpu().numpy().flatten())\n",
    "\n",
    "        test_preds = np.array(test_preds)\n",
    "        if i == 0:\n",
    "            pred = test_preds\n",
    "        else:\n",
    "            pred += test_preds\n",
    "\n",
    "    pred /= Config.NUM_FOLDS\n",
    "    # Print and log average scores\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    std_rmse = np.std(rmse_scores)\n",
    "    print(f\"Average RMSE: {avg_rmse:.4f} (+/- {std_rmse:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE AND DISPLAY CV RSME SCORE\n",
    "if not Config.TRAIN_SINGLE_FOLD:\n",
    "    rmse = np.sqrt(np.mean((oof - train.price.values)**2))\n",
    "    print(\"Overall CV RMSE =\", rmse)\n",
    "\n",
    "    # SAVE OOF \n",
    "    oof_df = train[[\"id\"]].copy()\n",
    "    oof_df[\"pred\"] = oof\n",
    "    oof_df.to_csv(f'{DATA_WRITEPATH}/oof_v{VER}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Config.TRAIN_SINGLE_FOLD:\n",
    "    sub = pd.read_csv(\"/kaggle/input/playground-series-s4e9/sample_submission.csv\")\n",
    "    sub.price = pred\n",
    "    print(\"Submission shape:\",sub.shape)\n",
    "    sub.to_csv(f\"submission_v{VER}.csv\",index=False)\n",
    "    sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "[ 2  4  6  8 10 12 14 16 18 20]\n",
      "[ 3  6  9 12 15 18 21 24 27 30]\n",
      "[ 3  6  9 12 15 18 21 24 27 30]\n",
      "[ 6 12 18 24 30 36 42 48 54 60]\n",
      "[ 4  8 12 16 20 24 28 32 36 40]\n",
      "[ 10  20  30  40  50  60  70  80  90 100]\n",
      "[ 5 10 15 20 25 30 35 40 45 50]\n",
      "[ 15  30  45  60  75  90 105 120 135 150]\n",
      "#########################\n",
      "[ 15  30  45  60  75  90 105 120 135 150]\n",
      "[ 5 10 15 20 25 30 35 40 45 50]\n",
      "[ 3.  6.  9. 12. 15. 18. 21. 24. 27. 30.]\n"
     ]
    }
   ],
   "source": [
    "# pred = np.zeros(10)\n",
    "# for fold in range(5):\n",
    "#     my_arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "#     my_arr = my_arr * (fold+1)\n",
    "#     if fold == 0:\n",
    "#         pred = my_arr\n",
    "#     else:\n",
    "#         pred += my_arr\n",
    "#     print(my_arr)\n",
    "#     print(pred)\n",
    "\n",
    "# print(\"#\"*25)\n",
    "# print(pred)\n",
    "# print(my_arr)\n",
    "# print(pred / 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
