{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, TargetEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from functools import partial\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"/home/bk_anupam/code/ML/ML_UTILS/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_tabular_utils as tt\n",
    "import cv_split_utils\n",
    "import enums\n",
    "from enums import ModelName\n",
    "import data_utils\n",
    "import param_tuning_utils as ptu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'ModelName' has no attribute 'NeuralNet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mConfig\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mRUNTIME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLOCAL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mRANDOM_SEED\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\n",
      "Cell \u001b[0;32mIn[42], line 8\u001b[0m, in \u001b[0;36mConfig\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m METRIC \u001b[38;5;241m=\u001b[39m enums\u001b[38;5;241m.\u001b[39mMetrics\u001b[38;5;241m.\u001b[39mRMSE\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# These values are more dynamic   \u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m MODEL_TO_USE \u001b[38;5;241m=\u001b[39m \u001b[43mModelName\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNeuralNet\u001b[49m    \n\u001b[1;32m      9\u001b[0m TRAIN_SINGLE_FOLD \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m    \n\u001b[1;32m     10\u001b[0m PERSIST_MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m    \n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ModelName' has no attribute 'NeuralNet'"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    RUNTIME = \"LOCAL\"\n",
    "    RANDOM_SEED = 42\n",
    "    NUM_FOLDS = 5\n",
    "    TARGET_COL_NAME = \"price\"            \n",
    "    METRIC = enums.Metrics.RMSE\n",
    "    # These values are more dynamic   \n",
    "    MODEL_TO_USE = ModelName.NeuralNet    \n",
    "    TRAIN_SINGLE_FOLD = True    \n",
    "    PERSIST_MODEL = False    \n",
    "    USE_MANUAL_FEATURES = False\n",
    "    USE_ORIGINAL_DATA = True\n",
    "\n",
    "COLS_TO_LEAVE = [\"id\", \"price\", \"kfold\", \"transmission_speed\", \"target_grp\"]\n",
    "CPU_COUNT = os.cpu_count()\n",
    "\n",
    "DATA_READPATH = \"./data/\"\n",
    "DATA_WRITEPATH = \"./output/\"\n",
    "SUBMISSION_FILEPATH = DATA_READPATH\n",
    "if Config.RUNTIME == \"KAGGLE\":    \n",
    "    DATA_READPATH = \"/kaggle/input/playground-series-s4e9/\"\n",
    "    if Config.USE_MANUAL_FEATURES:\n",
    "        DATA_READPATH = \"/kaggle/input/ps4e9-fe/\"\n",
    "    SUBMISSION_FILEPATH = \"/kaggle/input/playground-series-s4e9/\"\n",
    "    DATA_WRITEPATH = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for tabnet\n",
    "class TabNetConfig:\n",
    "    PATIENCE = 10\n",
    "    WEIGHT_DECAY = 1e-6    \n",
    "    PRECISION = \"16-mixed\"\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_WORKERS = mp.cpu_count()\n",
    "    NUM_EPOCHS = 2    \n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
    "\n",
    "class SchedulerConfig:\n",
    "    # for ReduceLROnPlateau (number of epochs with no improvement after which the learning rate will be reduced)\n",
    "    SCHEDULER_PATIENCE = 5  \n",
    "    # for ReduceLROnPlateau (factor by which the learning rate will be reduced)\n",
    "    FACTOR = 0.5 \n",
    "    SCHEDULER = \"ReduceLROnPlateau\"\n",
    "    T_0 = 10 # for CosineAnnealingWarmRestarts (Number of epochs before the first restart)\n",
    "    MIN_LR = 5e-7 # for CosineAnnealingWarmRestarts (Minimum learning rate)\n",
    "    T_mult = 1 # for CosineAnnealingWarmRestarts (Factor by which Ti(number of epochs between two restarts) increases)\n",
    "    MAX_LR = 1e-2 # for CosineAnnealing (Initial learning rate)\n",
    "    STEPS_PER_EPOCH = 13 # for OneCycleLR\n",
    "    STEP_SIZE = 3 # for StepLR\n",
    "    GAMMA = 0.1 # for StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbConfig:\n",
    "    WANDB_KEY = \"c5e2877bf080e6b62fcc57231c91e3a1455f97d0\"\n",
    "    WANDB_RUN_NAME = \"tabnet_cv_5folds\"\n",
    "    WANDB_PROJECT = \"ps4e9_nn\"\n",
    "    USE_WANDB = False        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_to_dict(cfg):\n",
    "    # dir is an inbuilt python function that returns the list of attributes and methods of any object\n",
    "    return dict((name, getattr(cfg, name)) for name in dir(cfg) if not name.startswith('__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = config_to_dict(Config)\n",
    "tabnet_config_dict = config_to_dict(TabNetConfig)\n",
    "schd_config_dict = config_to_dict(SchedulerConfig)\n",
    "wandb_config_dict = config_to_dict(WandbConfig)\n",
    "merged_config_dict = {**config_dict, **tabnet_config_dict, **schd_config_dict, **wandb_config_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    df_train = pd.read_csv(DATA_READPATH + \"train.csv\")\n",
    "    if Config.USE_ORIGINAL_DATA:\n",
    "        df_train_orig = pd.read_csv(DATA_READPATH + \"used_cars.csv\")\n",
    "        df_train_orig[['milage', 'price']] = df_train_orig[['milage', 'price']].applymap(lambda x: int(re.sub(\"[^0-9]\", \"\", x)))\n",
    "        df_train_orig['milage'] = df_train_orig['milage'].astype('int64')\n",
    "        df_train_orig['price'] = df_train_orig['price'].astype('int64')\n",
    "        # add df_train_orig rows to df_train\n",
    "        df_train = pd.concat([df_train, df_train_orig], axis=0, ignore_index=True)        \n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train.shape: (188533, 13)\n",
      "df_test.shape: (125690, 13)\n",
      "df_combined shape: (314223, 13)\n"
     ]
    }
   ],
   "source": [
    "df_train = get_train_data()\n",
    "print(f\"df_train.shape: {df_train.shape}\")\n",
    "df_test = pd.read_csv(DATA_READPATH + \"test.csv\")\n",
    "df_test[\"price\"] = 0\n",
    "print(f\"df_test.shape: {df_test.shape}\")\n",
    "df_combined = pd.concat([df_train, df_test],axis=0,ignore_index=True)\n",
    "print(\"df_combined shape:\", df_combined.shape )\n",
    "# keep a copy of original train and test data for later use\n",
    "df_train_orig = df_train.copy()\n",
    "df_test_orig = df_test.copy()\n",
    "# # drop id column\n",
    "# df_train = df_train.drop(\"id\", axis=1)\n",
    "# df_test = df_test.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_engine_info(engine_desc: str, brand: str) -> dict:\n",
    "    # check if engine_desc is a valid string\n",
    "    if not isinstance(engine_desc, str):\n",
    "        return None\n",
    "    engine_desc = engine_desc.lower()\n",
    "    brand = brand.lower()\n",
    "    # Define patterns for each attribute\n",
    "    horsepower_pattern = r'(\\d+(\\.\\d+)?\\s*)hp'\n",
    "    capacity_pattern = r'(\\d+(\\.\\d+)?\\s*)l'\n",
    "    cylinders_pattern = r'(\\d+)\\s*cylinder|v(\\d+)'\n",
    "    fuel_pattern = r'(gasoline|diesel|flex|electric|dohc|ohv)'    \n",
    "    # Extract horsepower\n",
    "    horsepower_match = re.search(horsepower_pattern, engine_desc)\n",
    "    horsepower = float(horsepower_match.group(1)) if horsepower_match else None\n",
    "    # Extract capacity\n",
    "    capacity_match = re.search(capacity_pattern, engine_desc)\n",
    "    capacity = float(capacity_match.group(1)) if capacity_match else None\n",
    "    # Extract cylinders\n",
    "    cylinders_match = re.search(cylinders_pattern, engine_desc)    \n",
    "    cylinders = int(cylinders_match.group(1) or cylinders_match.group(2)) if cylinders_match else None\n",
    "    # Extract fuel type\n",
    "    fuel_match = re.search(fuel_pattern, engine_desc)\n",
    "    fuel = fuel_match.group(0) if fuel_match else None\n",
    "    if fuel in ('dohc', 'ohv'):\n",
    "        fuel = \"gasoline\"\n",
    "    # check is fuel_type is None and brand is \"Tesla\" then set fuel_type to \"electric\"\n",
    "    if fuel is None and brand == \"tesla\":\n",
    "        fuel = \"electric\"\n",
    "    # Extract turbo\n",
    "    turbo_match = re.search(r'turbo', engine_desc)\n",
    "    turbo = True if turbo_match else False\n",
    "    # extract hybrid\n",
    "    hybrid_match = re.search(r'hybrid', engine_desc)\n",
    "    hybrid = True if hybrid_match else False\n",
    "    return {\n",
    "        \"horsepower\": horsepower, \n",
    "        \"capacity\": capacity,\n",
    "        \"cylinders\": cylinders,\n",
    "        \"fuel\": fuel,\n",
    "        \"turbo\": turbo,\n",
    "        \"hybrid\": hybrid\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_transmission_info(transmission_desc: str) -> dict:\n",
    "    if not isinstance(transmission_desc, str):\n",
    "        return None\n",
    "    transmission_desc = transmission_desc.lower()\n",
    "    patterns = {\n",
    "        \"transmission_speed\": r\"(\\d+)[\\s-]speed\",\n",
    "        \"auto\": r\"automatic|cvt|a/t|\\sat|transmission overdrive switch\",\n",
    "        \"manual\": r\"manual|m/t|\\smt\",\n",
    "        \"single_speed\": r\"single-speed\"\n",
    "    }\n",
    "    transmission_info = {}\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, transmission_desc)\n",
    "        if key == \"transmission_speed\":\n",
    "            transmission_info[key] = int(match.group(1)) if match else None\n",
    "        elif key == \"auto\" and match:\n",
    "            transmission_info[\"transmission_type\"] = \"automatic\"\n",
    "            break\n",
    "        elif key == \"manual\" and match:\n",
    "            transmission_info[\"transmission_type\"] = \"manual\"\n",
    "            break\n",
    "        elif key == \"single_speed\" and match:\n",
    "            transmission_info[\"transmission_type\"] = \"single_speed\"\n",
    "            break\n",
    "\n",
    "    if \"transmission_type\" not in transmission_info:\n",
    "        transmission_info[\"transmission_type\"] = \"automatic\" if transmission_desc == \"f\" else \"Unknown\"\n",
    "\n",
    "    return transmission_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_resale_price_brands = ['Mercedes-Benz', 'Bentley', 'Aston', 'Jaguar', 'Tesla', 'Lamborghini', 'Land', 'RAM', \n",
    "                            'Cadillac', 'Alfa', 'Ferrari', 'Porsche', 'Bugatti', 'McLaren', 'Rolls-Royce', 'Lucid', \n",
    "                            'Maserati', 'Rivian', 'Genesis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_from_text_cols(df):\n",
    "    # apply the \"extract_engine_info\" function to the 'engine' and 'brand' columns and extract each of the returned values into new columns\n",
    "    df[['horsepower', 'capacity', 'cylinders', 'fuel', 'turbo', 'hybrid']] = \\\n",
    "        df.apply(lambda x: extract_engine_info(x['engine'], x['brand']), axis=1).apply(pd.Series)\n",
    "    # apply the \"extract_transmission_info\" function to the 'transmission' column and extract each of the returned values into new columns\n",
    "    df[['transmission_speed', 'transmission_type']] = \\\n",
    "        df['transmission'].apply(extract_transmission_info).apply(pd.Series)\n",
    "    # by subtract model_year from current year create a new feature \"age\"\n",
    "    df['age'] = 2024 - df['model_year']    \n",
    "    # Create the new column 'is_high_resale_price_brand'\n",
    "    df['is_high_resale_price_brand'] = df['brand'].isin(high_resale_price_brands)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = create_features_from_text_cols(df_train)\n",
    "df_test = create_features_from_text_cols(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns: ['brand', 'model', 'model_year', 'milage', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
      "Categorical features: ['brand', 'model', 'model_year', 'fuel_type', 'engine', 'transmission', 'ext_col', 'int_col', 'accident', 'clean_title']\n",
      "Numerical features: ['milage']\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [c for c in df_combined.columns if not c in COLS_TO_LEAVE ]\n",
    "num_cols = ['milage']\n",
    "cat_cols = [c for c in feature_cols if not c in num_cols]\n",
    "cat_idxs = [ i for i, f in enumerate(feature_cols) if f in cat_cols]\n",
    "print(\"Feature columns:\", feature_cols)\n",
    "print(\"Categorical features:\", cat_cols )\n",
    "print(\"Numerical features:\", num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>datatype</th>\n",
       "      <th>null_count</th>\n",
       "      <th>unique_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brand</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model_year</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>milage</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fuel_type</td>\n",
       "      <td>object</td>\n",
       "      <td>8466</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>engine</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>transmission</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ext_col</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>int_col</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>accident</td>\n",
       "      <td>object</td>\n",
       "      <td>4084</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>clean_title</td>\n",
       "      <td>object</td>\n",
       "      <td>35658</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>price</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        col_name datatype  null_count  unique_categories\n",
       "0             id    int64           0                  0\n",
       "1          brand   object           0                 57\n",
       "2          model   object           0               1898\n",
       "3     model_year    int64           0                  0\n",
       "4         milage    int64           0                  0\n",
       "5      fuel_type   object        8466                  8\n",
       "6         engine   object           0               1118\n",
       "7   transmission   object           0                 52\n",
       "8        ext_col   object           0                319\n",
       "9        int_col   object           0                156\n",
       "10      accident   object        4084                  3\n",
       "11   clean_title   object       35658                  2\n",
       "12         price    int64           0                  0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_utils.get_col_stats(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STANDARDIZING: milage , "
     ]
    }
   ],
   "source": [
    "# Standardize numerical features\n",
    "print(\"STANDARDIZING: \",end=\"\")\n",
    "for col in num_cols:\n",
    "    print(col, \", \", end=\"\")\n",
    "    scaler = StandardScaler()\n",
    "    df_combined[[col]] = scaler.fit_transform(df_combined[[col]])\n",
    "    # after standardization the mean of the numerical column is 0, so filling missing values with 0 instead of mean\n",
    "    df_combined[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>model_year</th>\n",
       "      <th>milage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>ext_col</th>\n",
       "      <th>int_col</th>\n",
       "      <th>accident</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MINI</td>\n",
       "      <td>Cooper S Base</td>\n",
       "      <td>2007</td>\n",
       "      <td>2.945022</td>\n",
       "      <td>Gasoline</td>\n",
       "      <td>172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel</td>\n",
       "      <td>A/T</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Gray</td>\n",
       "      <td>None reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id brand          model  model_year    milage fuel_type  \\\n",
       "0   0  MINI  Cooper S Base        2007  2.945022  Gasoline   \n",
       "\n",
       "                                         engine transmission ext_col int_col  \\\n",
       "0  172.0HP 1.6L 4 Cylinder Engine Gasoline Fuel          A/T  Yellow    Gray   \n",
       "\n",
       "        accident clean_title  price  \n",
       "0  None reported         Yes   4200  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL ENCODING: \n",
      "brand: col_num_cat=58, min=0, max=56, num_rare_cat=8, emb_size=8\n",
      "model: col_num_cat=1899, min=0, max=1897, num_rare_cat=551, emb_size=44\n",
      "model_year: col_num_cat=37, min=0, max=35, num_rare_cat=4, emb_size=7\n",
      "fuel_type: col_num_cat=9, min=0, max=7, num_rare_cat=1, emb_size=3\n",
      "engine: col_num_cat=1119, min=0, max=1117, num_rare_cat=308, emb_size=34\n",
      "transmission: col_num_cat=53, min=0, max=51, num_rare_cat=8, emb_size=8\n",
      "ext_col: col_num_cat=320, min=0, max=318, num_rare_cat=99, emb_size=18\n",
      "int_col: col_num_cat=157, min=0, max=155, num_rare_cat=48, emb_size=13\n",
      "accident: col_num_cat=4, min=0, max=2, num_rare_cat=0, emb_size=2\n",
      "clean_title: col_num_cat=3, min=0, max=1, num_rare_cat=0, emb_size=2\n"
     ]
    }
   ],
   "source": [
    "# Label encode categorical features\n",
    "print(\"LABEL ENCODING: \")\n",
    "# number of unique categories in each categorical column\n",
    "cat_cols_dims = {}\n",
    "# categorical embedding size for each categorical column\n",
    "cat_cols_emb = {}\n",
    "val_cnt = None\n",
    "col_rare_cat = {}\n",
    "for col in cat_cols:    \n",
    "    le = LabelEncoder()\n",
    "    df_combined[col] = le.fit_transform(df_combined[col])\n",
    "    col_num_cat = len(le.classes_)\n",
    "    col_min = df_combined[col].min()\n",
    "    col_max = df_combined[col].max()\n",
    "    val_cnt = df_combined[col].value_counts()\n",
    "    col_rare_cat[col] = val_cnt.loc[val_cnt < 40].index.values\n",
    "    # Increment the encoding by 1 as 0 will be used for rare categories\n",
    "    df_combined[col] += 1\n",
    "    # Replace rare categories in the column with 0\n",
    "    df_combined.loc[df_combined[col].isin(col_rare_cat[col]), col] = 0\n",
    "    # add one for rare categories\n",
    "    col_num_cat = (col_max+1)+1    \n",
    "    cat_cols_dims[col] = col_num_cat\n",
    "    cat_cols_emb[col] = int(np.ceil(np.sqrt(col_num_cat)))\n",
    "    print(f'{col}: col_num_cat={col_num_cat}, min={col_min}, max={col_max}, num_rare_cat={len(col_rare_cat[col])},'\n",
    "          f' emb_size={cat_cols_emb[col]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((188533, 13), (125690, 13))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df_combined.iloc[:len(df_train)]\n",
    "test = df_combined.iloc[len(df_train):]\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand: Test has label encodes = [] which are not in train.\n",
      "model: Test has label encodes = [] which are not in train.\n",
      "model_year: Test has label encodes = [] which are not in train.\n",
      "fuel_type: Test has label encodes = [] which are not in train.\n",
      "engine: Test has label encodes = [] which are not in train.\n",
      "transmission: Test has label encodes = [] which are not in train.\n",
      "ext_col: Test has label encodes = [] which are not in train.\n",
      "int_col: Test has label encodes = [] which are not in train.\n",
      "accident: Test has label encodes = [] which are not in train.\n",
      "clean_title: Test has label encodes = [] which are not in train.\n"
     ]
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    # COMPARE TEST CAT VALUES TO TRAIN CAT VALUES\n",
    "    A = train[col].unique()\n",
    "    B = test[col].unique()\n",
    "    C = np.setdiff1d(B,A)\n",
    "    print(f\"{col}: Test has label encodes = {C} which are not in train.\")\n",
    "    if len(C) > 0:\n",
    "        print(f\" => {len(test.loc[test[col].isin(C)])} rows\" )\n",
    "        \n",
    "    # RELABEL UNSEEN TEST VALUES AS ZERO\n",
    "    test.loc[test[col].isin(C), col] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cv_split_utils.strat_kfold_dataframe(train, \n",
    "                                            random_state=Config.RANDOM_SEED, \n",
    "                                            num_folds=Config.NUM_FOLDS,\n",
    "                                            target_col_name=Config.TARGET_COL_NAME, \n",
    "                                            n_bins=25)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do not include 'id' column in the list of int columns\n",
    "# int_cols = [col for col in df_train.columns if df_train[col].dtypes == 'int64' and col not in COLS_TO_LEAVE]\n",
    "# float_cols = [col for col in df_train.columns if df_train[col].dtypes == 'float64']\n",
    "# bool_cols = [col for col in df_train.columns if df_train[col].dtypes == 'bool']\n",
    "# cat_cols = [col for col in df_train.columns if df_train[col].dtypes == 'object' and col not in COLS_TO_LEAVE]\n",
    "# feature_cols = [x for x in df_train.columns if x not in COLS_TO_LEAVE]\n",
    "# cat_idxs = [ i for i, f in enumerate(feature_cols) if f in cat_cols]\n",
    "# print(f\"feature_cols = {feature_cols}\")\n",
    "# print(f\"cat_cols = {cat_cols}\")\n",
    "# print(f\"cat_idxs = {cat_idxs}\")\n",
    "# print(f\"int_cols = {int_cols}\")\n",
    "# print(f\"float_cols = {float_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation_config = {\n",
    "#         'horsepower': SimpleImputer(strategy=\"median\"),\n",
    "#         'capacity': SimpleImputer(strategy=\"median\"),\n",
    "#         'cylinders': SimpleImputer(strategy=\"median\"),\n",
    "#         'transmission_speed': SimpleImputer(strategy=\"median\"),\n",
    "#     }\n",
    "# for column, imputer in imputation_config.items():\n",
    "#     imputer.fit(df_train[[column]])\n",
    "#     df_train[column] = imputer.transform(df_train[[column]])\n",
    "#     if column != 'horsepower':\n",
    "#         # convert column datatype to int\n",
    "#         df_train[column] = df_train[column].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Handle categorical columns\n",
    "# cat_cols = df_train.select_dtypes(include=['object']).columns\n",
    "# cat_cols_dims = {}\n",
    "# for col in cat_cols:\n",
    "#     le = LabelEncoder()\n",
    "#     df_train[col] = le.fit_transform(df_train[col].astype(str))\n",
    "#     cat_cols_dims[col] = len(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scale numerical features\n",
    "# scaler = StandardScaler()\n",
    "# num_cols = int_cols + float_cols\n",
    "# df_train[num_cols] = scaler.fit_transform(df_train[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"turbo\"] = df_train[\"turbo\"].astype(int)\n",
    "# df_train[\"hybrid\"] = df_train[\"hybrid\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "oof = np.zeros(len(train))\n",
    "pred = np.zeros(len(test))\n",
    "kf = KFold(n_splits=Config.NUM_FOLDS, random_state=Config.RANDOM_SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 2 ###\n",
      "#########################\n",
      "epoch 0  | loss: 6021955065.74834| val_0_rmse: 77510.62401|  0:03:00s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 40\u001b[0m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m TabNetRegressor(\n\u001b[1;32m     18\u001b[0m     n_d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, n_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     19\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m, n_independent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_shared\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     device_name\u001b[38;5;241m=\u001b[39mTabNetConfig\u001b[38;5;241m.\u001b[39mDEVICE        \n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTabNetConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTabNetConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTabNetConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvirtual_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTabNetConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_WORKERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrmse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     53\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:262\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[0;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eval_name, valid_dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_names, valid_dataloaders):\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# Call method on_epoch_end for all callbacks\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_epoch_end(\n\u001b[1;32m    266\u001b[0m     epoch_idx, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mepoch_metrics\n\u001b[1;32m    267\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:562\u001b[0m, in \u001b[0;36mTabModel._predict_epoch\u001b[0;34m(self, name, loader)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# Main loop\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[0;32m--> 562\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m     list_y_true\u001b[38;5;241m.\u001b[39mappend(y)\n\u001b[1;32m    564\u001b[0m     list_y_score\u001b[38;5;241m.\u001b[39mappend(scores)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:590\u001b[0m, in \u001b[0;36mTabModel._predict_batch\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    587\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# compute model output\u001b[39;00m\n\u001b[0;32m--> 590\u001b[0m scores, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scores, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    593\u001b[0m     scores \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m scores]\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py:616\u001b[0m, in \u001b[0;36mTabNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    615\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder(x)\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtabnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py:492\u001b[0m, in \u001b[0;36mTabNetNoEmbeddings.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    491\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 492\u001b[0m     steps_output, M_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m     res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mstack(steps_output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_multi_task:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;66;03m# Result will be in list format\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py:169\u001b[0m, in \u001b[0;36mTabNetEncoder.forward\u001b[0;34m(self, x, prior)\u001b[0m\n\u001b[1;32m    166\u001b[0m     prior \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((bs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_dim))\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    168\u001b[0m M_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 169\u001b[0m att \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_splitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_d :]\n\u001b[1;32m    170\u001b[0m steps_output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps):\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py:738\u001b[0m, in \u001b[0;36mFeatTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    737\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared(x)\n\u001b[0;32m--> 738\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecifics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py:780\u001b[0m, in \u001b[0;36mGLU_Block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    777\u001b[0m     layers_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_glu)\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m glu_id \u001b[38;5;129;01min\u001b[39;00m layers_left:\n\u001b[0;32m--> 780\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39madd(x, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglu_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mglu_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    781\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m*\u001b[39m scale\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py:803\u001b[0m, in \u001b[0;36mGLU_Layer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 803\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x)\n\u001b[1;32m    805\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(x[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim], torch\u001b[38;5;241m.\u001b[39msigmoid(x[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim :]))\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.11/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if Config.MODEL_TO_USE == ModelName.TabNetRegressor:\n",
    "    # 2. Cross-validation setup\n",
    "    X = train[feature_cols].values\n",
    "    y = train[Config.TARGET_COL_NAME].values.reshape(-1, 1)\n",
    "    # 3. Model training and evaluation\n",
    "    rmse_scores = []\n",
    "    print(\"Training TabNetRegressor\")\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(\"#\"*25)\n",
    "        print(f\"### Fold {fold+1} ###\")\n",
    "        print(\"#\"*25)\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # By default, PyTorch TabNet uses:cat_emb_dim = min(50, (cat_dim + 1) // 2) if cat_emb_dim is not specified.    \n",
    "        model = TabNetRegressor(\n",
    "            n_d=64, n_a=64, n_steps=5,\n",
    "            gamma=1.5, n_independent=2, n_shared=2,\n",
    "            cat_idxs=cat_idxs, cat_dims=list(cat_cols_dims.values()),\n",
    "            lambda_sparse=1e-3, momentum=0.3, clip_value=2.,\n",
    "            optimizer_fn=torch.optim.Adam,\n",
    "            optimizer_params=dict(lr=SchedulerConfig.MAX_LR, weight_decay=TabNetConfig.WEIGHT_DECAY),\n",
    "            scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "            scheduler_params=dict(step_size=SchedulerConfig.STEP_SIZE, gamma=SchedulerConfig.GAMMA),\n",
    "            # scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            # scheduler_params=dict(mode=\"min\",\n",
    "            #                       patience=SchedulerConfig.SCHEDULER_PATIENCE,\n",
    "            #                       min_lr=SchedulerConfig.MIN_LR,\n",
    "            #                       factor=SchedulerConfig.FACTOR),\n",
    "            # scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
    "            # scheduler_params=dict(T_0=SchedulerConfig.T_0,\n",
    "            #                       T_mult=SchedulerConfig.T_mult,\n",
    "            #                       eta_min=SchedulerConfig.MIN_LR),\n",
    "            mask_type='sparsemax',\n",
    "            device_name=TabNetConfig.DEVICE        \n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            max_epochs=TabNetConfig.NUM_EPOCHS,\n",
    "            patience=TabNetConfig.PATIENCE,\n",
    "            batch_size=TabNetConfig.BATCH_SIZE,\n",
    "            virtual_batch_size=128,\n",
    "            num_workers=TabNetConfig.NUM_WORKERS,\n",
    "            drop_last=False,\n",
    "            eval_metric=[\"rmse\"]\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))        \n",
    "        rmse_scores.append(rmse)        \n",
    "        print(f\"RMSE: {rmse:.4f}\")    \n",
    "        oof[val_idx] = y_pred\n",
    "        print()\n",
    "        if Config.TRAIN_SINGLE_FOLD:\n",
    "            break\n",
    "        \n",
    "        # TEST PREDS    \n",
    "        test_preds = model.predict(test[feature_cols].values)\n",
    "        test_preds = test_preds.flatten()\n",
    "        \n",
    "        if fold == 0:\n",
    "            pred = test_preds\n",
    "        else:\n",
    "            pred += test_preds\n",
    "\n",
    "    pred /= Config.NUM_FOLDS\n",
    "    # Print and log average scores\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    std_rmse = np.std(rmse_scores)\n",
    "    print(f\"Average RMSE: {avg_rmse:.4f} (+/- {std_rmse:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNetwork(nn.Module):\n",
    "    def __init__(self, cat_sizes, cat_emb_sizes, num_features):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(cat_size, emb_size) \n",
    "                                         for cat_size, emb_size in zip(cat_sizes, cat_emb_sizes)])\n",
    "        \n",
    "        total_emb_size = sum(cat_emb_sizes) + num_features\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(total_emb_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, cat_inputs, num_inputs):\n",
    "        emb_outputs = [emb(cat_inputs[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        emb_outputs = torch.cat(emb_outputs, dim=1)\n",
    "        combined = torch.cat([emb_outputs, num_inputs], dim=1)\n",
    "        return self.fc_layers(combined)\n",
    "\n",
    "def build_model(cat_sizes, cat_emb_sizes, num_features):\n",
    "    return EmbeddingNetwork(cat_sizes, cat_emb_sizes, num_features)\n",
    "\n",
    "def rmse_metric(predictions, targets):\n",
    "    return torch.sqrt(torch.mean((predictions - targets) ** 2))\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, optimizer, scheduler, criterion, eval_metric, device, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for cat_inputs, num_inputs, targets in train_loader:\n",
    "            cat_inputs, num_inputs, targets = cat_inputs.to(device), num_inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(cat_inputs, num_inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        valid_loss = 0\n",
    "        valid_metric = 0\n",
    "        with torch.no_grad():\n",
    "            for cat_inputs, num_inputs, targets in valid_loader:\n",
    "                cat_inputs, num_inputs, targets = cat_inputs.to(device), num_inputs.to(device), targets.to(device)\n",
    "                outputs = model(cat_inputs, num_inputs)\n",
    "                valid_loss += criterion(outputs, targets).item()\n",
    "                valid_metric += eval_metric(outputs, targets).item()\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Print epoch results including the current learning rate and evaluation metric\n",
    "        print(f'Epoch {epoch+1}/{epochs}, '\n",
    "              f'Validation Loss: {valid_loss/len(valid_loader):.6f}, '\n",
    "              f'Validation Metric: {valid_metric/len(valid_loader):.6f}, '\n",
    "              f'Learning Rate: {scheduler.get_last_lr()[0]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_dataloaders(fold, df, cat_cols, num_cols, target_col_name):\n",
    "    df_train_fold = df[df[\"kfold\"] != fold].reset_index(drop=True)\n",
    "    df_val_fold = df[df[\"kfold\"] == fold].reset_index(drop=True)\n",
    "    X_train_cats = torch.LongTensor(df_train_fold.loc[:, cat_cols].values)\n",
    "    X_train_nums = torch.FloatTensor(df_train_fold.loc[:, num_cols].values)\n",
    "    y_train = torch.FloatTensor(df_train_fold.loc[:, target_col_name].values).unsqueeze(1)\n",
    "    X_valid_cats = torch.LongTensor(df_val_fold.loc[:, cat_cols].values)\n",
    "    X_valid_nums = torch.FloatTensor(df_val_fold.loc[:, num_cols].values)\n",
    "    y_valid = torch.FloatTensor(df_val_fold.loc[:, target_col_name].values).unsqueeze(1)\n",
    "    train_dataset = TensorDataset(X_train_cats, X_train_nums, y_train)\n",
    "    valid_dataset = TensorDataset(X_valid_cats, X_valid_nums, y_valid)        \n",
    "    train_loader = DataLoader(train_dataset, batch_size=TabNetConfig.BATCH_SIZE, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=TabNetConfig.BATCH_SIZE)\n",
    "    return train_loader, valid_loader, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 1\n",
    "if Config.MODEL_TO_USE == ModelName.NeuralNet:\n",
    "    rmse_scores = []        \n",
    "    for i, (train_index, val_index) in enumerate(kf.split(train)):\n",
    "        print(\"#\"*25)\n",
    "        print(f\"### Fold {i+1} ###\")\n",
    "        print(\"#\"*25)\n",
    "\n",
    "        X_train_cats = torch.LongTensor(train.loc[train_index, cat_cols].values)\n",
    "        X_train_nums = torch.FloatTensor(train.loc[train_index, num_cols].values)\n",
    "        y_train = torch.FloatTensor(train.loc[train_index, \"price\"].values).unsqueeze(1)\n",
    "\n",
    "        X_valid_cats = torch.LongTensor(train.loc[val_index, cat_cols].values)\n",
    "        X_valid_nums = torch.FloatTensor(train.loc[val_index, num_cols].values)\n",
    "        y_valid = torch.FloatTensor(train.loc[val_index, \"price\"].values).unsqueeze(1)\n",
    "\n",
    "        X_test_cats = torch.LongTensor(test[cat_cols].values)\n",
    "        X_test_nums = torch.FloatTensor(test[num_cols].values)\n",
    "\n",
    "        train_dataset = TensorDataset(X_train_cats, X_train_nums, y_train)\n",
    "        valid_dataset = TensorDataset(X_valid_cats, X_valid_nums, y_valid)\n",
    "        test_dataset = TensorDataset(X_test_cats, X_test_nums)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=TabNetConfig.BATCH_SIZE, shuffle=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=TabNetConfig.BATCH_SIZE)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=512)\n",
    "\n",
    "        CAT_SIZE = list(cat_cols_dims.values())\n",
    "        CAT_EMB = list(cat_cols_emb.values())\n",
    "        model = build_model(CAT_SIZE, CAT_EMB, len(num_cols)).to(TabNetConfig.DEVICE)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=SchedulerConfig.STEP_SIZE, \n",
    "                                                    gamma=SchedulerConfig.GAMMA)\n",
    "        criterion = nn.MSELoss()\n",
    "        eval_metric = rmse_metric\n",
    "\n",
    "        train_model(model, \n",
    "                    train_loader, valid_loader, optimizer, \n",
    "                    scheduler=scheduler,\n",
    "                    criterion=criterion, \n",
    "                    device=TabNetConfig.DEVICE, \n",
    "                    epochs=TabNetConfig.NUM_EPOCHS,\n",
    "                    eval_metric=eval_metric)\n",
    "\n",
    "        torch.save(model.state_dict(), f'{DATA_WRITEPATH}/NN_v{VER}_f{i}.weights.pth')\n",
    "        \n",
    "        # OOF PREDS\n",
    "        model.eval()\n",
    "        oof_preds = []\n",
    "        with torch.no_grad():\n",
    "            for cat_inputs, num_inputs, _ in valid_loader:\n",
    "                cat_inputs, num_inputs = cat_inputs.to(TabNetConfig.DEVICE), num_inputs.to(TabNetConfig.DEVICE)\n",
    "                outputs = model(cat_inputs, num_inputs)\n",
    "                oof_preds.extend(outputs.cpu().numpy().flatten())\n",
    "\n",
    "        oof_preds = np.array(oof_preds)\n",
    "        rmse = np.sqrt(np.mean((oof_preds - y_valid.numpy().flatten())**2))\n",
    "        rmse_scores.append(rmse)\n",
    "        print(f' => RMSE = {rmse}\\n')\n",
    "        oof[val_index] = oof_preds\n",
    "        \n",
    "        if Config.TRAIN_SINGLE_FOLD:\n",
    "            break\n",
    "\n",
    "        # TEST PREDS\n",
    "        test_preds = []\n",
    "        with torch.no_grad():\n",
    "            for cat_inputs, num_inputs in test_loader:\n",
    "                cat_inputs, num_inputs = cat_inputs.to(TabNetConfig.DEVICE), num_inputs.to(TabNetConfig.DEVICE)\n",
    "                outputs = model(cat_inputs, num_inputs)\n",
    "                test_preds.extend(outputs.cpu().numpy().flatten())\n",
    "\n",
    "        test_preds = np.array(test_preds)\n",
    "        if i == 0:\n",
    "            pred = test_preds\n",
    "        else:\n",
    "            pred += test_preds\n",
    "\n",
    "    pred /= Config.NUM_FOLDS\n",
    "    # Print and log average scores\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    std_rmse = np.std(rmse_scores)\n",
    "    print(f\"Average RMSE: {avg_rmse:.4f} (+/- {std_rmse:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE AND DISPLAY CV RSME SCORE\n",
    "if not Config.TRAIN_SINGLE_FOLD:\n",
    "    rmse = np.sqrt(np.mean((oof - train.price.values)**2))\n",
    "    print(\"Overall CV RMSE =\", rmse)\n",
    "\n",
    "    # SAVE OOF \n",
    "    oof_df = train[[\"id\"]].copy()\n",
    "    oof_df[\"pred\"] = oof\n",
    "    oof_df.to_csv(f'{DATA_WRITEPATH}df_val_preds_{Config.MODEL_TO_USE}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Config.TRAIN_SINGLE_FOLD:\n",
    "    sub = pd.read_csv(DATA_READPATH + \"sample_submission.csv\")\n",
    "    sub.price = pred\n",
    "    print(\"Submission shape:\",sub.shape)\n",
    "    sub.to_csv(f\"{DATA_WRITEPATH}submission_{Config.MODEL_TO_USE}.csv\",index=False)\n",
    "    sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
