{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import statistics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer\n",
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "from functools import partial\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"/home/bk_anupam/code/ML/ML_UTILS/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_tabular as tt\n",
    "import cv_split_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelType:\n",
    "    LGBM = \"LGBM\"\n",
    "    XGB = \"XGB\"\n",
    "    RF = \"RF\"\n",
    "    RIDGE = \"Ridge\"\n",
    "    CATBOOST = \"CATBOOST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RANDOM_SEED = 42\n",
    "    NUM_FOLDS = 5\n",
    "    TARGET_COL_NAME = \"Rings\"    \n",
    "    SKEW_THRESHOLD = 0.5\n",
    "    EARLY_STOPPING = 500\n",
    "    RESULTS_FILE = \"model_execution_results.pkl\"\n",
    "    MODEL_TYPE = ModelType.RIDGE\n",
    "    REMOVE_OUTLIERS = True\n",
    "    POWER_TRANSFORM = False\n",
    "    NORMALIZE_DATA = True\n",
    "    SCALER = \"StandardScaler\"    \n",
    "\n",
    "DATA_PATH = \"./data/\"\n",
    "COLS_TO_LEAVE = [\"Rings\", \"kfold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train dataset locally from data folder\n",
    "df_train = pd.read_csv(\"./data/train.csv\")\n",
    "# import test dataset locally from data folder\n",
    "df_test = pd.read_csv(\"./data/test.csv\")\n",
    "# drop id column\n",
    "df_train = df_train.drop(\"id\", axis=1)\n",
    "df_test = df_test.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3705</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.7390</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0590</td>\n",
       "      <td>0.4275</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Whole weight.1  Whole weight.2  \\\n",
       "0   I   0.490     0.380   0.125        0.5290          0.2165          0.1375   \n",
       "1   I   0.420     0.345   0.100        0.3705          0.1625          0.0795   \n",
       "2   M   0.555     0.440   0.135        0.7390          0.3515          0.1575   \n",
       "3   F   0.535     0.410   0.140        0.7090          0.2505          0.1700   \n",
       "4   F   0.605     0.455   0.150        1.0590          0.4275          0.2210   \n",
       "\n",
       "   Shell weight  Rings  kfold  \n",
       "0        0.1550      7      3  \n",
       "1        0.1025      7      3  \n",
       "2        0.2350      9      0  \n",
       "3        0.1900      9      4  \n",
       "4        0.3100     10      2  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = cv_split_utils.strat_kfold_dataframe(\n",
    "                                    df=df_train, \n",
    "                                    target_col_name=Config.TARGET_COL_NAME, \n",
    "                                    num_folds=Config.NUM_FOLDS,\n",
    "                                    random_state=Config.RANDOM_SEED\n",
    "                                )\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_float = df_train.select_dtypes(include=[\"float\"]).columns.to_list()\n",
    "cols_int = df_train.select_dtypes(include=[\"int64\"]).columns.to_list()\n",
    "cols_str = df_train.select_dtypes(include=[\"object\"]).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outliers_iqr(df, col_name, remove_outliers=True):\n",
    "    Q1 = df[col_name].quantile(0.25)\n",
    "    Q3 = df[col_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1    \n",
    "    min_val = Q1 - 1.5 * IQR\n",
    "    max_val = Q3 + 1.5 * IQR    \n",
    "    outlier_count = df[(df[col_name] < min_val) | (df[col_name] > max_val)].shape[0]\n",
    "    if remove_outliers:\n",
    "        df = df[(df[col_name] >= min_val) & (df[col_name] <= max_val)]\n",
    "    # Create a DataFrame for the results\n",
    "    result = pd.DataFrame({\n",
    "        'col_name': [col_name],\n",
    "        'Q1': [Q1],\n",
    "        'Q3': [Q3],\n",
    "        'IQR': [IQR],\n",
    "        'min_val': [min_val],\n",
    "        'max_val': [max_val],\n",
    "        'outlier_count': [outlier_count]\n",
    "    })    \n",
    "    return df, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_transform(df, col_name, skew_threshold=0.5):    \n",
    "    transformed = False\n",
    "    skew = df[col_name].skew()\n",
    "    print(f\"{col_name} has skewness of {skew}\")\n",
    "    power_transformer = PowerTransformer(method='yeo-johnson', standardize=True)    \n",
    "    if abs(skew) > skew_threshold:\n",
    "        transformed = True\n",
    "        print(\"Will apply power transform.\")\n",
    "        col_transformed = power_transformer.fit_transform(df[[col_name]])\n",
    "        df.loc[:, col_name] = col_transformed\n",
    "    return df, transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q3</th>\n",
       "      <th>IQR</th>\n",
       "      <th>min_val</th>\n",
       "      <th>max_val</th>\n",
       "      <th>outlier_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Length</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.21250</td>\n",
       "      <td>0.83250</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diameter</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.65000</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Height</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.03500</td>\n",
       "      <td>0.23500</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whole weight</td>\n",
       "      <td>0.4405</td>\n",
       "      <td>1.0730</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>-0.50825</td>\n",
       "      <td>2.02175</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whole weight.1</td>\n",
       "      <td>0.1865</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.2760</td>\n",
       "      <td>-0.22750</td>\n",
       "      <td>0.87650</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Whole weight.2</td>\n",
       "      <td>0.0905</td>\n",
       "      <td>0.2310</td>\n",
       "      <td>0.1405</td>\n",
       "      <td>-0.12025</td>\n",
       "      <td>0.44175</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shell weight</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.3005</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>-0.13575</td>\n",
       "      <td>0.56225</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         col_name      Q1      Q3     IQR  min_val  max_val outlier_count\n",
       "0          Length  0.4450  0.6000  0.1550  0.21250  0.83250          1460\n",
       "1        Diameter  0.3500  0.4700  0.1200  0.17000  0.65000           372\n",
       "2          Height  0.1100  0.1600  0.0500  0.03500  0.23500            73\n",
       "3    Whole weight  0.4405  1.0730  0.6325 -0.50825  2.02175           621\n",
       "4  Whole weight.1  0.1865  0.4625  0.2760 -0.22750  0.87650           600\n",
       "5  Whole weight.2  0.0905  0.2310  0.1405 -0.12025  0.44175           130\n",
       "6    Shell weight  0.1260  0.3005  0.1745 -0.13575  0.56225           593"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty DataFrame to store the results\n",
    "df_float_outliers = pd.DataFrame(columns=['col_name', 'Q1', 'Q3', 'IQR', 'min_val', 'max_val', 'outlier_count'])\n",
    "for col_name in cols_float:\n",
    "    df_train, df_col_ouliers = process_outliers_iqr(df_train, col_name, Config.REMOVE_OUTLIERS)\n",
    "    df_float_outliers = df_float_outliers.append(df_col_ouliers)\n",
    "    if Config.POWER_TRANSFORM:\n",
    "        df_train, transformed = power_transform(df_train, col_name, Config.SKEW_THRESHOLD)\n",
    "df_float_outliers = df_float_outliers.reset_index(drop=True)\n",
    "df_float_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of categorical variables\n",
    "df_train_onehot = pd.get_dummies(df_train, columns=cols_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df_train_onehot.columns.drop([\"Rings\", \"kfold\"]).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df, cont_col_names, cols_to_leave):\n",
    "    # normalize continuous features\n",
    "    scaler = None\n",
    "    if Config.SCALER == \"StandardScaler\":\n",
    "        scaler = StandardScaler()\n",
    "    elif Config.SCALER == \"RobustScaler\":\n",
    "        scaler = RobustScaler()\n",
    "    else:\n",
    "        scaler = MinMaxScaler()\n",
    "    X_cont = df[cont_col_names]\n",
    "    if Config.NORMALIZE_DATA:    \n",
    "        X_cont = scaler.fit_transform(X_cont)     \n",
    "    # get the columns other than continuous features\n",
    "    other_col_names = [item for item in df.columns.values.tolist() if item not in cont_col_names + cols_to_leave]\n",
    "    # combine the normalized continuous features with others\n",
    "    X_processed = np.concatenate([X_cont, df[other_col_names]], axis=1)    \n",
    "    return X_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_data(fold, df, cont_col_names, cols_to_leave, target_col_name):\n",
    "    df_train = df[df.kfold != fold]\n",
    "    df_val = df[df.kfold == fold]        \n",
    "    X_train = extract_features(df_train, cont_col_names, cols_to_leave)\n",
    "    X_val = extract_features(df_val, cont_col_names, cols_to_leave)\n",
    "    y_train = df_train[target_col_name]\n",
    "    y_val = df_val[target_col_name]\n",
    "    return X_train, y_train, X_val, y_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_params, model_type):\n",
    "    model = None\n",
    "    if model_type == ModelType.RIDGE:\n",
    "        model = Ridge(\n",
    "            random_state=Config.RANDOM_SEED,\n",
    "            alpha=model_params[\"alpha\"]\n",
    "        )\n",
    "    # elif model_type == ModelType.RF:\n",
    "    #     model = RandomForestClassifier(\n",
    "    #                 n_estimators=model_params[\"n_estimators\"],                 \n",
    "    #                 max_depth=model_params[\"max_depth\"],\n",
    "    #                 min_samples_leaf=model_params[\"min_samples_leaf\"],\n",
    "    #                 min_samples_split=model_params[\"min_samples_split\"],\n",
    "    #                 max_features=model_params[\"max_features\"],\n",
    "    #                 random_state=Config.RANDOM_SEED,\n",
    "    #                 n_jobs=-1\n",
    "    #             )     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_tuning_params(trial, model_type):\n",
    "    if model_type == ModelType.RIDGE:\n",
    "        return {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-4, 1e4, log=True)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, train_X, train_y, val_X, val_y):    \n",
    "    model.fit(train_X, train_y.ravel())\n",
    "    val_y_pred = model.predict(val_X)    \n",
    "    val_y_pred = [item if item > 0 else 0 for item in val_y_pred]\n",
    "    rmsle = root_mean_squared_log_error(val_y, val_y_pred)\n",
    "    return rmsle, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparams_tuning_objective(trial, df_train, cols_float, cols_to_leave):       \n",
    "    params = get_model_tuning_params(trial, Config.MODEL_TYPE)\n",
    "    model = create_model(params, Config.MODEL_TYPE)\n",
    "    fold_metric = []\n",
    "    for fold in range(Config.NUM_FOLDS):\n",
    "        train_X, train_y, val_X, val_y = get_fold_data(\n",
    "                                            fold=fold, \n",
    "                                            df=df_train, \n",
    "                                            cont_col_names=cols_float, \n",
    "                                            cols_to_leave=cols_to_leave,\n",
    "                                            target_col_name=Config.TARGET_COL_NAME\n",
    "                                        )\n",
    "        rmsle, _, = run_training(model, train_X, train_y, val_X, val_y)\n",
    "        fold_metric.append(rmsle)\n",
    "    mean_metric = statistics.mean(fold_metric)                \n",
    "    return mean_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-05-04 21:53:19,980]\u001b[0m A new study created in memory with name: RidgeModelTuning\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:20,298]\u001b[0m Trial 0 finished with value: 0.1630465201179936 and parameters: {'alpha': 0.0011500035478797823}. Best is trial 0 with value: 0.1630465201179936.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:20,540]\u001b[0m Trial 1 finished with value: 0.16301092138584422 and parameters: {'alpha': 18.326228903718363}. Best is trial 1 with value: 0.16301092138584422.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:20,799]\u001b[0m Trial 2 finished with value: 0.16304044352881442 and parameters: {'alpha': 3.0242801756049498}. Best is trial 1 with value: 0.16301092138584422.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:21,110]\u001b[0m Trial 3 finished with value: 0.16304650701222795 and parameters: {'alpha': 0.007625847226755735}. Best is trial 1 with value: 0.16301092138584422.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:21,294]\u001b[0m Trial 4 finished with value: 0.16304648619384832 and parameters: {'alpha': 0.017913052068439322}. Best is trial 1 with value: 0.16301092138584422.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:21,532]\u001b[0m Trial 5 finished with value: 0.16300657431450172 and parameters: {'alpha': 20.670232978017538}. Best is trial 5 with value: 0.16300657431450172.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:21,766]\u001b[0m Trial 6 finished with value: 0.16304550866013712 and parameters: {'alpha': 0.5014930023619354}. Best is trial 5 with value: 0.16300657431450172.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:21,943]\u001b[0m Trial 7 finished with value: 0.16304488897676153 and parameters: {'alpha': 0.8085963301118008}. Best is trial 5 with value: 0.16300657431450172.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:22,219]\u001b[0m Trial 8 finished with value: 0.1630458619795899 and parameters: {'alpha': 0.32658568275653566}. Best is trial 5 with value: 0.16300657431450172.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:22,519]\u001b[0m Trial 9 finished with value: 0.1630434778118919 and parameters: {'alpha': 1.509540825096879}. Best is trial 5 with value: 0.16300657431450172.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:22,752]\u001b[0m Trial 10 finished with value: 0.1670361324706828 and parameters: {'alpha': 6925.148963414143}. Best is trial 5 with value: 0.16300657431450172.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:22,979]\u001b[0m Trial 11 finished with value: 0.162691530481197 and parameters: {'alpha': 327.0575042461508}. Best is trial 11 with value: 0.162691530481197.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:23,180]\u001b[0m Trial 12 finished with value: 0.16263027491590898 and parameters: {'alpha': 452.43208614820026}. Best is trial 12 with value: 0.16263027491590898.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:23,381]\u001b[0m Trial 13 finished with value: 0.16253927240582539 and parameters: {'alpha': 2510.2817845769573}. Best is trial 13 with value: 0.16253927240582539.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:23,578]\u001b[0m Trial 14 finished with value: 0.16672205750541444 and parameters: {'alpha': 6618.626305091348}. Best is trial 13 with value: 0.16253927240582539.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:23,756]\u001b[0m Trial 15 finished with value: 0.1626940721128016 and parameters: {'alpha': 321.8391572264756}. Best is trial 13 with value: 0.16253927240582539.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:23,939]\u001b[0m Trial 16 finished with value: 0.16266952650406577 and parameters: {'alpha': 379.6652894674883}. Best is trial 13 with value: 0.16253927240582539.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:24,130]\u001b[0m Trial 17 finished with value: 0.16237716646101658 and parameters: {'alpha': 2279.730463168317}. Best is trial 17 with value: 0.16237716646101658.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:24,312]\u001b[0m Trial 18 finished with value: 0.16296655470001578 and parameters: {'alpha': 43.46517838657325}. Best is trial 17 with value: 0.16237716646101658.\u001b[0m\n",
      "\u001b[32m[I 2024-05-04 21:53:24,713]\u001b[0m Trial 19 finished with value: 0.1622034958985353 and parameters: {'alpha': 1963.7467180572462}. Best is trial 19 with value: 0.1622034958985353.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: number = 19, value = 0.1622034958985353, params = {'alpha': 1963.7467180572462}\n"
     ]
    }
   ],
   "source": [
    "hyperparams_tuning_obj_partial = partial(\n",
    "                                        hyperparams_tuning_objective, \n",
    "                                         df_train=df_train_onehot, \n",
    "                                         cols_float=cols_float, \n",
    "                                         cols_to_leave=COLS_TO_LEAVE\n",
    "                                    )\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"RidgeModelTuning\")    \n",
    "study.optimize(hyperparams_tuning_obj_partial, n_trials=20,)\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best trial: number = {best_trial.number}, value = {best_trial.value}, params = {best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "      <th>kfold</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_I</th>\n",
       "      <th>Sex_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.431562</td>\n",
       "      <td>-0.414679</td>\n",
       "      <td>-0.206522</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.827586</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.686795</td>\n",
       "      <td>-0.612844</td>\n",
       "      <td>-0.626812</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.093398</td>\n",
       "      <td>0.080734</td>\n",
       "      <td>-0.061594</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.034483</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.141707</td>\n",
       "      <td>-0.289908</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.421900</td>\n",
       "      <td>0.359633</td>\n",
       "      <td>0.398551</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Length  Diameter  Height  Whole weight  Whole weight.1  Whole weight.2  \\\n",
       "0 -0.344828     -0.36    -0.3     -0.431562       -0.414679       -0.206522   \n",
       "1 -0.827586     -0.64    -0.8     -0.686795       -0.612844       -0.626812   \n",
       "2  0.103448      0.12    -0.1     -0.093398        0.080734       -0.061594   \n",
       "3 -0.034483     -0.12     0.0     -0.141707       -0.289908        0.028986   \n",
       "4  0.448276      0.24     0.2      0.421900        0.359633        0.398551   \n",
       "\n",
       "   Shell weight  Rings  kfold  Sex_F  Sex_I  Sex_M  \n",
       "0     -0.400000    7.0    3.0    0.0    1.0    0.0  \n",
       "1     -0.700000    7.0    3.0    0.0    1.0    0.0  \n",
       "2      0.057143    9.0    0.0    0.0    0.0    1.0  \n",
       "3     -0.200000    9.0    4.0    1.0    0.0    0.0  \n",
       "4      0.485714   10.0    2.0    1.0    0.0    0.0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "df_float = df_train_onehot[cols_float]\n",
    "other_col_names = [item for item in df_train_onehot.columns.values.tolist() if item not in cols_float]\n",
    "cat_cols = [item for item in other_col_names if item not in COLS_TO_LEAVE]\n",
    "df_float_scaled = pd.DataFrame(scaler.fit_transform(df_float), columns = df_float.columns)\n",
    "df_train_other = df_train_onehot[other_col_names]\n",
    "df_train_oh_scaled = pd.concat([df_float_scaled, df_train_other], axis=1)\n",
    "df_train_oh_scaled.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29259/2856466390.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdummy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# fit dummy_model on cols_float of df_train_oh_scaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdummy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_float\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcat_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Rings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_val_0_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols_float\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcat_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_val_0_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_0_pred\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_0_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1472\u001b[0m                 )\n\u001b[1;32m   1473\u001b[0m             ):\n\u001b[0;32m-> 1474\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \"\"\"\n\u001b[1;32m   1166\u001b[0m         \u001b[0m_accept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_valid_accept_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1168\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         )\n\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1264\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1050\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             )\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "df_train_0 = df_train_oh_scaled[df_train_oh_scaled.kfold != 0]\n",
    "df_val_0 = df_train_oh_scaled[df_train_oh_scaled.kfold == 0]\n",
    "dummy_model = Ridge()\n",
    "# fit dummy_model on cols_float of df_train_oh_scaled\n",
    "dummy_model = dummy_model.fit(X=df_train_0[cols_float + cat_cols], y=df_train_0[\"Rings\"])\n",
    "y_val_0_pred = dummy_model.predict(df_val_0[cols_float + cat_cols])\n",
    "y_val_0_pred = np.where(y_val_0_pred < 0, 0, y_val_0_pred)\n",
    "y_val_0_pred = [round(item) for item in y_val_0_pred]\n",
    "df_val_0.loc[:, \"Rings_pred\"] = y_val_0_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
