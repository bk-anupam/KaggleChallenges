{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q xgboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q openfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import statistics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer\n",
    "from functools import partial\n",
    "from openfe import OpenFE, transform\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"/home/bk_anupam/code/ML/ML_UTILS/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_tabular_utils as tt\n",
    "import cv_split_utils\n",
    "import enums\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RUN_MODE = \"LOCAL\"\n",
    "    RANDOM_SEED = 42\n",
    "    NUM_FOLDS = 5\n",
    "    TARGET_COL_NAME = \"Rings\"    \n",
    "    SKEW_THRESHOLD = 0.5\n",
    "    EARLY_STOPPING = 500\n",
    "    RESULTS_FILE = \"model_execution_results.pkl\"\n",
    "    MODEL_TYPE = enums.ModelName.LGBM\n",
    "    REMOVE_OUTLIERS = False\n",
    "    POWER_TRANSFORM = False\n",
    "    NORMALIZE_DATA = True\n",
    "    SCALER = enums.Scaler.StandardScaler\n",
    "    METRIC = enums.Metrics.RMSLE\n",
    "    NUM_TUNING_TRIALS = 40\n",
    "    TUNE_ON_SINGLE_FOLD = True\n",
    "    GENERATE_AUTO_FEATURES = False\n",
    "    PERSIST_MODEL = True\n",
    "    # perform log transformation on target to train on RMSLE objective\n",
    "    TRANSFORM_TARGET = True\n",
    "\n",
    "COLS_TO_LEAVE = [\"Rings\", \"kfold\"]\n",
    "CPU_COUNT = os.cpu_count()\n",
    "\n",
    "DATA_READPATH = \"./data/\"\n",
    "DATA_WRITEPATH = \"./output/\"\n",
    "SUBMISSION_FILEPATH = DATA_READPATH\n",
    "if Config.RUN_MODE == \"KAGGLE\":\n",
    "    # If we are not generating features, we are using already generated features\n",
    "    if Config.GENERATE_AUTO_FEATURES:\n",
    "        DATA_READPATH = \"/kaggle/input/playground-series-s4e4/\"\n",
    "        SUBMISSION_FILEPATH = DATA_READPATH\n",
    "    else:\n",
    "        DATA_READPATH = \"/kaggle/input/abalone-openfe/\"\n",
    "        SUBMISSION_FILEPATH = \"/kaggle/input/playground-series-s4e4/\"\n",
    "    DATA_WRITEPATH = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params_static = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmsle\",\n",
    "    \"seed\": Config.RANDOM_SEED,\n",
    "    \"verbosity\": 0,\n",
    "}\n",
    "lgbm_params_static = {\n",
    "        \"objective\": \"root_mean_squared_error\",\n",
    "        \"metric\": 'rmse',\n",
    "        \"verbosity\": -1,    # <0: fatal, =0: error (warn), =1: info, >1: debug\n",
    "        \"boosting_type\": \"gbdt\"\n",
    "    }\n",
    "\n",
    "params_static = lgbm_params_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train dataset locally from data folder\n",
    "df_train = pd.read_csv(DATA_READPATH + \"train_openfe.csv\")\n",
    "# import test dataset locally from data folder\n",
    "df_test = pd.read_csv(DATA_READPATH + \"test_openfe.csv\")\n",
    "# drop id column\n",
    "#df_train = df_train.drop(\"id\", axis=1)\n",
    "#df_test = df_test.drop(\"id\", axis=1)\n",
    "# keep a copy of original train and test data for later use\n",
    "df_train_orig = df_train.copy()\n",
    "df_test_orig = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Log Error (RMSLE):\n",
    "\n",
    "- This metric penalizes large errors in predictions more than small errors.\n",
    "- It's commonly used for regression problems where the target variable represents quantities or measurements that are naturally positive (e.g., housing prices, sales figures).\n",
    "\n",
    "LightGBM with \"mean_squared_error\" Objective:\n",
    "\n",
    "- By default, LightGBM's \"mean_squared_error\" objective minimizes the squared difference between predicted and actual target values.\n",
    "\n",
    "Transformation with numpy.log1p(target):\n",
    "\n",
    "- numpy.log1p(target) applies a natural log (ln) function after adding 1 to each target value.\n",
    "- This transformation ensures that the logarithm can be applied to target values that might include zeros.\n",
    "- It also puts more emphasis on relative errors for smaller target values, aligning better with the nature of RMSLE.\n",
    "\n",
    "Impact on Training:\n",
    "\n",
    "- By training on the transformed target (numpy.log1p(target)), LightGBM is implicitly minimizing the squared difference between the log-transformed predictions and log-transformed actual values.\n",
    "- However, during evaluation, you'll need to transform the predicted values back using the inverse function (np.expm1(predicted_values)) to recover the original scale for calculating the actual RMSLE.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "- This approach is more suitable for LightGBM's \"mean_squared_error\" objective because it aligns the training process with the logic of RMSLE.\n",
    "It avoids potential issues with taking the logarithm of zero target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_for_fe = [x for x in df_train.columns if x not in COLS_TO_LEAVE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_features(df_train, df_test, feature_cols, NUM_NEW_FEATURES=10):\n",
    "    train_X = df_train[feature_cols] \n",
    "    test_X = df_test[feature_cols]   \n",
    "    train_y = df_train[Config.TARGET_COL_NAME]\n",
    "    ofe = OpenFE()\n",
    "    features = ofe.fit(data=train_X, label=train_y, n_jobs=CPU_COUNT, verbose=False)  # generate new features\n",
    "    # OpenFE recommends a list of new features. We include the top 10\n",
    "    # generated features to see how they influence the model performance\n",
    "    train_X, test_X = transform(train_X, test_X, ofe.new_features_list[:NUM_NEW_FEATURES], n_jobs=CPU_COUNT)\n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.GENERATE_AUTO_FEATURES:\n",
    "    df_train, df_test = generate_new_features(df_train, df_test, feature_cols_for_fe)    \n",
    "    df_train_labels = df_train_orig[[Config.TARGET_COL_NAME]]\n",
    "    # Add the label data to the dataframe\n",
    "    df_train = pd.concat([df_train, df_train_labels], axis=1)\n",
    "    # save the new train and test data with openfe features to csv files for later use\n",
    "    df_train.to_csv(DATA_WRITEPATH + \"train_openfe.csv\", index=False)\n",
    "    df_test.to_csv(DATA_WRITEPATH + \"test_openfe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_float = [ x for x in df_train.select_dtypes(include=[\"float\"]).columns.to_list() if x not in COLS_TO_LEAVE]\n",
    "cols_int = df_train.select_dtypes(include=[\"int64\"]).columns.to_list()\n",
    "cols_str = df_train.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "feature_cols_to_normalize = cols_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>autoFE_f_0</th>\n",
       "      <th>autoFE_f_1</th>\n",
       "      <th>autoFE_f_2</th>\n",
       "      <th>autoFE_f_3</th>\n",
       "      <th>autoFE_f_4</th>\n",
       "      <th>autoFE_f_5</th>\n",
       "      <th>autoFE_f_6</th>\n",
       "      <th>autoFE_f_7</th>\n",
       "      <th>autoFE_f_8</th>\n",
       "      <th>autoFE_f_9</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>2.291667</td>\n",
       "      <td>1.368750</td>\n",
       "      <td>1.791667</td>\n",
       "      <td>2.348554</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>2637.0</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.145</td>\n",
       "      <td>1.1300</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>1.968750</td>\n",
       "      <td>1.431250</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>2.467249</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.4650</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.818182</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>1.502000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.435419</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>2088.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>2.810127</td>\n",
       "      <td>1.870886</td>\n",
       "      <td>2.151899</td>\n",
       "      <td>2.116373</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Whole weight.1  Whole weight.2  \\\n",
       "0   F   0.550     0.430   0.150        0.7715          0.3285          0.1465   \n",
       "1   F   0.630     0.490   0.145        1.1300          0.4580          0.2765   \n",
       "2   I   0.160     0.110   0.025        0.0210          0.0055          0.0030   \n",
       "3   M   0.595     0.475   0.150        0.9145          0.3755          0.2055   \n",
       "4   I   0.555     0.425   0.130        0.7820          0.3695          0.1600   \n",
       "\n",
       "   Shell weight  autoFE_f_0  autoFE_f_1  autoFE_f_2  autoFE_f_3  autoFE_f_4  \\\n",
       "0        0.2400    2.291667    1.368750    1.791667    2.348554      0.3100   \n",
       "1        0.3200    1.968750    1.431250    1.531250    2.467249      0.3100   \n",
       "2        0.0050   32.000000    1.100000   22.000000    3.818182      0.1550   \n",
       "3        0.2500    2.380000    1.502000    1.900000    2.435419      0.3450   \n",
       "4        0.1975    2.810127    1.870886    2.151899    2.116373      0.3575   \n",
       "\n",
       "   autoFE_f_5  autoFE_f_6  autoFE_f_7  autoFE_f_8  autoFE_f_9  Rings  \n",
       "0      0.4430      0.3900      2637.0      0.2400      0.1900     11  \n",
       "1      0.6720      0.4650      1173.0      0.3200      0.1700     11  \n",
       "2      0.0155      0.0300       487.0      0.0050      0.1050      6  \n",
       "3      0.5390      0.4000      2088.0      0.2500      0.2250     10  \n",
       "4      0.4125      0.3275        32.0      0.1975      0.2275      9  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>autoFE_f_0</th>\n",
       "      <th>autoFE_f_1</th>\n",
       "      <th>autoFE_f_2</th>\n",
       "      <th>autoFE_f_3</th>\n",
       "      <th>autoFE_f_4</th>\n",
       "      <th>autoFE_f_5</th>\n",
       "      <th>autoFE_f_6</th>\n",
       "      <th>autoFE_f_7</th>\n",
       "      <th>autoFE_f_8</th>\n",
       "      <th>autoFE_f_9</th>\n",
       "      <th>Rings</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>3.161290</td>\n",
       "      <td>1.396774</td>\n",
       "      <td>2.451613</td>\n",
       "      <td>2.443418</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.2800</td>\n",
       "      <td>774.0</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.3705</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>4.097561</td>\n",
       "      <td>1.585366</td>\n",
       "      <td>3.365854</td>\n",
       "      <td>2.280000</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.7390</td>\n",
       "      <td>0.3515</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>2.361702</td>\n",
       "      <td>1.495745</td>\n",
       "      <td>1.872340</td>\n",
       "      <td>2.102418</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3875</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>2.815789</td>\n",
       "      <td>1.318421</td>\n",
       "      <td>2.157895</td>\n",
       "      <td>2.830339</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.4585</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>0.605</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0590</td>\n",
       "      <td>0.4275</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>1.951613</td>\n",
       "      <td>1.379032</td>\n",
       "      <td>1.467742</td>\n",
       "      <td>2.477193</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.6315</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Whole weight.1  Whole weight.2  \\\n",
       "0   I   0.490     0.380   0.125        0.5290          0.2165          0.1375   \n",
       "1   I   0.420     0.345   0.100        0.3705          0.1625          0.0795   \n",
       "2   M   0.555     0.440   0.135        0.7390          0.3515          0.1575   \n",
       "3   F   0.535     0.410   0.140        0.7090          0.2505          0.1700   \n",
       "4   F   0.605     0.455   0.150        1.0590          0.4275          0.2210   \n",
       "\n",
       "   Shell weight  autoFE_f_0  autoFE_f_1  autoFE_f_2  autoFE_f_3  autoFE_f_4  \\\n",
       "0        0.1550    3.161290    1.396774    2.451613    2.443418      0.3350   \n",
       "1        0.1025    4.097561    1.585366    3.365854    2.280000      0.3175   \n",
       "2        0.2350    2.361702    1.495745    1.872340    2.102418      0.3200   \n",
       "3        0.1900    2.815789    1.318421    2.157895    2.830339      0.3450   \n",
       "4        0.3100    1.951613    1.379032    1.467742    2.477193      0.2950   \n",
       "\n",
       "   autoFE_f_5  autoFE_f_6  autoFE_f_7  autoFE_f_8  autoFE_f_9  Rings  kfold  \n",
       "0      0.3125      0.2800       774.0      0.1550      0.2250      7      2  \n",
       "1      0.2080      0.2025       148.0      0.1025      0.2425      7      2  \n",
       "2      0.3875      0.3700      1311.0      0.2350      0.2050      9      4  \n",
       "3      0.4585      0.3300      1017.0      0.1900      0.2200      9      2  \n",
       "4      0.6315      0.4600      1020.0      0.3100      0.1450     10      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = cv_split_utils.kfold_dataframe(\n",
    "                                    df=df_train,                           \n",
    "                                    num_folds=Config.NUM_FOLDS,\n",
    "                                    random_state=Config.RANDOM_SEED\n",
    "                                )\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(df, features_to_preprocess):\n",
    "    float_outliers = []\n",
    "    for col_name in features_to_preprocess:\n",
    "        df, df_col_outliers = data_utils.process_outliers_iqr(df, col_name, Config.REMOVE_OUTLIERS)\n",
    "        df_float_outliers = float_outliers.append(df_col_outliers)\n",
    "        if Config.POWER_TRANSFORM:\n",
    "            df, transformed = data_utils.power_transform(df, col_name, Config.SKEW_THRESHOLD)\n",
    "    df_float_outliers = pd.concat(float_outliers, axis=0)        \n",
    "    df_float_outliers = df_float_outliers.reset_index(drop=True)\n",
    "    return df, df_float_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess float features for train and test data\n",
    "df_train, df_train_float_outliers = preprocess_features(df_train, cols_float)\n",
    "_, df_test_float_outliers = preprocess_features(df_test, cols_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of categorical variables\n",
    "df_train_onehot = pd.get_dummies(df_train, columns=cols_str)\n",
    "df_test_onehot = pd.get_dummies(df_test, columns=cols_str)\n",
    "\n",
    "if Config.NORMALIZE_DATA:\n",
    "    # normalize\n",
    "    df_train_onehot = tt.normalize_features(df_train_onehot, \n",
    "                                            scaler=Config.SCALER,\n",
    "                                            features_to_normalize=feature_cols_to_normalize)\n",
    "    df_test_onehot = tt.normalize_features(df_test_onehot,\n",
    "                                           scaler=Config.SCALER, \n",
    "                                           features_to_normalize=feature_cols_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Length', 'Diameter', 'Height', 'Whole weight', 'Whole weight.1', 'Whole weight.2', 'Shell weight', 'autoFE_f_0', 'autoFE_f_1', 'autoFE_f_2', 'autoFE_f_3', 'autoFE_f_4', 'autoFE_f_5', 'autoFE_f_6', 'autoFE_f_7', 'autoFE_f_8', 'autoFE_f_9', 'Sex_F', 'Sex_I', 'Sex_M']\n"
     ]
    }
   ],
   "source": [
    "feature_cols= [x for x in df_train_onehot.columns.to_list() if x not in COLS_TO_LEAVE]\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgbm_tuning_params(trial):    \n",
    "    params_dynamic = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=25),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 20),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 256, step=4),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 500, step=20)\n",
    "    }\n",
    "    return {**lgbm_params_static, **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_tuning_params(trial, model_name):\n",
    "    if model_name == enums.ModelName.Ridge:\n",
    "        return {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-4, 1e4, log=True)\n",
    "        }\n",
    "    if model_name == enums.ModelName.Lasso:\n",
    "        return {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-4, 1e4, log=True)\n",
    "        }\n",
    "    if model_name == enums.ModelName.RandomForest:\n",
    "        return {        \n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 3000, step=100),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 10, 30),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 2, 16),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 16),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"log2\", \"sqrt\", None])\n",
    "        }\n",
    "    if model_name == enums.ModelName.XGBoost:\n",
    "        xgb_params_dynamic = {            \n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 32),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "            'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 100, 500, step=20)\n",
    "        }\n",
    "        return {**xgb_params_static, **xgb_params_dynamic}\n",
    "    if model_name == enums.ModelName.LGBM:\n",
    "        return get_lgbm_tuning_params(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lgbm(model_name, df_train, target_col_name, feature_col_names=None, \n",
    "                metric=enums.Metrics.MAE, num_folds=5, single_fold=False, model_params=None, \n",
    "                val_preds_col=\"val_preds\", suppress_print=False):\n",
    "    fold_metrics_model = []\n",
    "    df_val_preds = pd.DataFrame()    \n",
    "    for fold in range(num_folds):\n",
    "        df_train_fold, df_val_fold = tt.get_fold_df(df_train, fold)        \n",
    "        train_X, train_y, val_X, val_y = tt.get_train_val_nparray(df_train_fold, df_val_fold, feature_col_names, target_col_name)\n",
    "        train_y = np.log1p(train_y)\n",
    "        train_data = lgbm.Dataset(data=df_train_fold[feature_col_names], label=train_y, feature_name=\"auto\")    \n",
    "        val_data = lgbm.Dataset(data=df_val_fold[feature_col_names], label=val_y, feature_name=\"auto\")\n",
    "        model = lgbm.train(params=model_params, train_set=train_data, valid_sets=val_data)\n",
    "        val_df = df_val_fold[feature_col_names]\n",
    "        val_preds = model.predict(val_df, num_iteration=model.best_iteration)\n",
    "        # Since we have trained on np.log1p(y) instead of y, we need to reverse the transformation to extract the actual predictions\n",
    "        val_preds = np.expm1(val_preds)\n",
    "        fold_val_metric = tt.get_eval_metric(metric, val_y, val_preds)\n",
    "        fold_metrics_model.append((fold_val_metric, model))            \n",
    "        if not suppress_print:\n",
    "            print(f\"Fold {fold} - {model_name} - {metric} : {fold_val_metric}\")\n",
    "        df_val_fold[val_preds_col] = val_preds\n",
    "        df_val_preds = pd.concat([df_val_preds, df_val_fold], axis=0)\n",
    "        if single_fold:\n",
    "            break\n",
    "    return fold_metrics_model, df_val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparams_tuning_objective(trial, model_name, df_train,  \n",
    "                                 feature_cols, metric, target_col_name, single_fold=False,\n",
    "                                 num_folds=5, val_preds_col=\"val_preds\"):           \n",
    "    model_params = get_model_tuning_params(trial, model_name)    \n",
    "    fold_metrics_model, df_val_preds = tt.run_training(\n",
    "        model_name=model_name,\n",
    "        df_train=df_train,\n",
    "        target_col_name=target_col_name,\n",
    "        feature_col_names=feature_cols,\n",
    "        metric=metric,            \n",
    "        num_folds=num_folds,\n",
    "        model_params=model_params,\n",
    "        val_preds_col=val_preds_col,\n",
    "        single_fold=single_fold,\n",
    "        suppress_print=True,\n",
    "        transform_target=Config.TRANSFORM_TARGET\n",
    "    )       \n",
    "    fold_metrics = [x[0] for x in fold_metrics_model]\n",
    "    mean_metric = statistics.mean(fold_metrics)                \n",
    "    return mean_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model_params(study_name, study_direction, num_trials, model_name, \n",
    "                      df_train,  feature_cols, metric, target_col_name, \n",
    "                      single_fold=False, num_folds=5, val_preds_col=\"val_preds\", transform_target=False):\n",
    "    model_params_tuning_obj_partial = partial(\n",
    "        hyperparams_tuning_objective,\n",
    "        model_name=model_name,        \n",
    "        df_train=df_train,\n",
    "        feature_cols=feature_cols,\n",
    "        metric=metric,\n",
    "        target_col_name=target_col_name,\n",
    "        single_fold=single_fold,\n",
    "        num_folds=num_folds,\n",
    "        val_preds_col=val_preds_col,\n",
    "        transform_target=transform_target\n",
    "    )\n",
    "    study = optuna.create_study(direction=study_direction, study_name=study_name)\n",
    "    study.optimize(model_params_tuning_obj_partial, n_trials=num_trials)\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"Best trial: number = {best_trial.number}, value = {best_trial.value}, params = {best_trial.params}\")\n",
    "    return best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned_model_params = tune_model_params(\n",
    "#                         study_name=Config.MODEL_TYPE + \"_ModelTuning\", \n",
    "#                         study_direction=\"minimize\",\n",
    "#                         num_trials=Config.NUM_TUNING_TRIALS,\n",
    "#                         model_name=Config.MODEL_TYPE,\n",
    "#                         df_train=df_train_onehot,\n",
    "#                         feature_cols=feature_cols,\n",
    "#                         metric=Config.METRIC,\n",
    "#                         target_col_name=Config.TARGET_COL_NAME,\n",
    "#                         single_fold=Config.TUNE_ON_SINGLE_FOLD,\n",
    "#                         num_folds=Config.NUM_FOLDS,\n",
    "#                         transform_target=Config.TRANSFORM_TARGET\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_params = {'learning_rate': 0.018786770693979188, 'n_estimators': 800, 'max_depth': 17, 'min_child_weight': 6, 'subsample': 0.8798366073391215, 'colsample_bytree': 0.9095830407561765, 'num_leaves': 108, 'reg_alpha': 0.8627821903308106, 'reg_lambda': 35.942036785421045}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {**params_static, **tuned_model_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import dump\n",
    "\n",
    "# val_preds_col = \"val_preds\"\n",
    "# fold_metrics_model, df_val_preds = train_lgbm(\n",
    "#             model_name=Config.MODEL_TYPE,\n",
    "#             df_train=df_train_onehot,\n",
    "#             target_col_name=Config.TARGET_COL_NAME,\n",
    "#             feature_col_names=feature_cols,\n",
    "#             metric=Config.METRIC,            \n",
    "#             num_folds=Config.NUM_FOLDS,\n",
    "#             model_params=model_params,\n",
    "#             val_preds_col=val_preds_col,\n",
    "#             single_fold=False\n",
    "#         )\n",
    "# if Config.PERSIST_MODEL:\n",
    "#     for index, model in enumerate(fold_metrics_model[1]):\n",
    "#         fold_model_name = DATA_WRITEPATH + f\"{Config.MODEL_TYPE}_{index}.joblib\"        \n",
    "#         dump(model, fold_model_name)\n",
    "#         print(f\"saved {fold_model_name}\")\n",
    "# cv = tt.get_cv_score(df_val_preds, Config.TARGET_COL_NAME, val_preds_col, Config.METRIC)\n",
    "# df_val_preds.to_csv(DATA_WRITEPATH + f\"df_val_preds_{Config.MODEL_TYPE}.csv\")\n",
    "# print(f\"Saved validation data predictions to df_val_preds_{Config.MODEL_TYPE}.csv\")\n",
    "# print(f\"{Config.MODEL_TYPE} CV score = {cv}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training LightGBM\n",
      "fold 0 metric = 0.14411187282895616\n",
      "fold 1 metric = 0.14872025111566442\n",
      "fold 2 metric = 0.14479983995225454\n",
      "fold 3 metric = 0.14774404425324897\n",
      "fold 4 metric = 0.14726344067275016\n",
      "saved ./output/LightGBM_0.joblib\n",
      "saved ./output/LightGBM_1.joblib\n",
      "saved ./output/LightGBM_2.joblib\n",
      "saved ./output/LightGBM_3.joblib\n",
      "saved ./output/LightGBM_4.joblib\n",
      "Saved validation data predictions to df_val_preds_LightGBM.csv\n",
      "LightGBM CV score = 0.14653856980567037\n"
     ]
    }
   ],
   "source": [
    "fold_metrics_model = tt.train_model(\n",
    "                            df = df_train_onehot,\n",
    "                            model_name=Config.MODEL_TYPE,\n",
    "                            model_params = model_params,\n",
    "                            feature_col_names = feature_cols,\n",
    "                            target_col_name = Config.TARGET_COL_NAME,\n",
    "                            metric = Config.METRIC,\n",
    "                            num_folds = Config.NUM_FOLDS,\n",
    "                            single_fold = False,\n",
    "                            persist_model = True,\n",
    "                            output_path = DATA_WRITEPATH,\n",
    "                            transform_target = Config.TRANSFORM_TARGET\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if Config.MODEL_TYPE == enums.ModelName.XGBoost:\n",
    "    xgb.plot_importance(booster=fold_metrics_model[0][1])\n",
    "elif Config.MODEL_TYPE == enums.ModelName.LGBM:\n",
    "    lgbm.plot_importance(fold_metrics_model[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = {}\n",
    "for fold in range(Config.NUM_FOLDS):\n",
    "    model = fold_metrics_model[fold][1]    \n",
    "    test_df = df_test_onehot[feature_cols]             \n",
    "    fold_test_preds = model.predict(test_df)    \n",
    "    if Config.TRANSFORM_TARGET:\n",
    "        # Since we have trained on np.log1p(y) instead of y, we need to reverse the transformation to extract the actual predictions\n",
    "        fold_test_preds = np.expm1(fold_test_preds)    \n",
    "    pred_col_name = f\"fold_{fold}_test_preds\"\n",
    "    test_preds[pred_col_name] = fold_test_preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed prediction for 60411 test rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90615</td>\n",
       "      <td>9.596677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90616</td>\n",
       "      <td>9.807114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90617</td>\n",
       "      <td>9.539277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90618</td>\n",
       "      <td>10.758233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90619</td>\n",
       "      <td>7.574626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      Rings\n",
       "0  90615   9.596677\n",
       "1  90616   9.807114\n",
       "2  90617   9.539277\n",
       "3  90618  10.758233\n",
       "4  90619   7.574626"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_preds = pd.DataFrame(test_preds)\n",
    "test_pred_cols = [f\"fold_{fold}_test_preds\" for fold in range(Config.NUM_FOLDS)]\n",
    "df_test_preds[\"mean_test_pred\"] = df_test_preds[test_pred_cols].mean(axis=1)\n",
    "df_test_preds[\"mean_test_pred_rounded\"] = np.round(df_test_preds[\"mean_test_pred\"]).astype(int)\n",
    "print(f\"Completed prediction for {len(df_test)} test rows\")\n",
    "df_submission = pd.read_csv(SUBMISSION_FILEPATH + 'sample_submission.csv')\n",
    "#df_submission['Rings']= df_test_preds[\"mean_test_pred_rounded\"]\n",
    "df_submission['Rings']= df_test_preds[\"mean_test_pred\"]\n",
    "df_submission.to_csv(DATA_WRITEPATH + f'submission_{Config.MODEL_TYPE}.csv',index=False)\n",
    "df_test_preds.to_csv(DATA_WRITEPATH + 'test_preds.csv',index=False)\n",
    "df_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
