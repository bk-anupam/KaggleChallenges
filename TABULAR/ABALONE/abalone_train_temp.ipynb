{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q xgboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q openfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import statistics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer\n",
    "from functools import partial\n",
    "from openfe import OpenFE, transform\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"/home/bk_anupam/code/ML/ML_UTILS/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_tabular_utils as tt\n",
    "import cv_split_utils\n",
    "import enums\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RUN_MODE = \"LOCAL\"\n",
    "    RANDOM_SEED = 42\n",
    "    NUM_FOLDS = 10\n",
    "    TARGET_COL_NAME = \"Rings\"    \n",
    "    SKEW_THRESHOLD = 0.5\n",
    "    EARLY_STOPPING = 500 \n",
    "    SCALER = enums.Scaler.StandardScaler\n",
    "    METRIC = enums.Metrics.RMSLE\n",
    "    # These values are more dynamic   \n",
    "    MODEL_TYPE = enums.ModelName.CatBoost\n",
    "    REMOVE_OUTLIERS = False\n",
    "    POWER_TRANSFORM = False\n",
    "    NORMALIZE_DATA = True    \n",
    "    NUM_TUNING_TRIALS = 2\n",
    "    TUNE_ON_SINGLE_FOLD = True\n",
    "    TRAIN_SINGLE_FOLD = True\n",
    "    GENERATE_AUTO_FEATURES = False\n",
    "    PERSIST_MODEL = False\n",
    "    # perform log transformation on target to train on RMSLE objective\n",
    "    TRANSFORM_TARGET = True\n",
    "\n",
    "COLS_TO_LEAVE = [\"Rings\", \"kfold\", \"outlier_labels\"]\n",
    "CPU_COUNT = os.cpu_count()\n",
    "\n",
    "DATA_READPATH = \"./data/\"\n",
    "DATA_WRITEPATH = \"./output/\"\n",
    "SUBMISSION_FILEPATH = DATA_READPATH\n",
    "if Config.RUN_MODE == \"KAGGLE\":\n",
    "    # If we are not generating features, we are using already generated features\n",
    "    if Config.GENERATE_AUTO_FEATURES:\n",
    "        DATA_READPATH = \"/kaggle/input/playground-series-s4e4/\"\n",
    "        SUBMISSION_FILEPATH = DATA_READPATH\n",
    "    else:\n",
    "        DATA_READPATH = \"/kaggle/input/abalone-openfe/\"\n",
    "        SUBMISSION_FILEPATH = \"/kaggle/input/playground-series-s4e4/\"\n",
    "    DATA_WRITEPATH = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the already tuned model parameters or set to None if hyperparameter tuning is required\n",
    "# tuned_model_params = {'learning_rate': 0.018786770693979188, 'n_estimators': 800, 'max_depth': 17, 'min_child_weight': 6, 'subsample': 0.8798366073391215, 'colsample_bytree': 0.9095830407561765, 'num_leaves': 108, 'reg_alpha': 0.8627821903308106, 'reg_lambda': 35.942036785421045}\n",
    "tuned_model_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params_static = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"seed\": Config.RANDOM_SEED,\n",
    "    \"verbosity\": 0,\n",
    "}\n",
    "lgbm_params_static = {\n",
    "        \"objective\": \"root_mean_squared_error\",\n",
    "        \"metric\": 'rmse',\n",
    "        \"verbosity\": -1,    # <0: fatal, =0: error (warn), =1: info, >1: debug\n",
    "        \"boosting_type\": \"gbdt\"\n",
    "    }\n",
    "cb_params_static = {\n",
    "    \"objective\": \"RMSE\",\n",
    "    \"verbose\": 0,\n",
    "    \"random_seed\": Config.RANDOM_SEED,\n",
    "    \"eval_metric\": \"RMSE\",\n",
    "    'grow_policy':  'Lossguide'\n",
    "}\n",
    "params_static = cb_params_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train dataset locally from data folder\n",
    "df_train = pd.read_csv(DATA_READPATH + \"train_openfe.csv\")\n",
    "# import test dataset locally from data folder\n",
    "df_test = pd.read_csv(DATA_READPATH + \"test_openfe.csv\")\n",
    "# drop id column\n",
    "#df_train = df_train.drop(\"id\", axis=1)\n",
    "#df_test = df_test.drop(\"id\", axis=1)\n",
    "# keep a copy of original train and test data for later use\n",
    "df_train_orig = df_train.copy()\n",
    "df_test_orig = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter df_train where value of Rings is greater than 25 or less than 3\n",
    "df_train = df_train[(df_train[\"Rings\"] > 2) & (df_train[\"Rings\"] < 25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Root Mean Squared Log Error (RMSLE):\n",
    "\n",
    "- This metric penalizes large errors in predictions more than small errors.\n",
    "- It's commonly used for regression problems where the target variable represents quantities or measurements that are naturally positive (e.g., housing prices, sales figures).\n",
    "\n",
    "LightGBM with \"mean_squared_error\" Objective:\n",
    "\n",
    "- By default, LightGBM's \"mean_squared_error\" objective minimizes the squared difference between predicted and actual target values.\n",
    "\n",
    "Transformation with numpy.log1p(target):\n",
    "\n",
    "- numpy.log1p(target) applies a natural log (ln) function after adding 1 to each target value.\n",
    "- This transformation ensures that the logarithm can be applied to target values that might include zeros.\n",
    "- It also puts more emphasis on relative errors for smaller target values, aligning better with the nature of RMSLE.\n",
    "\n",
    "Impact on Training:\n",
    "\n",
    "- By training on the transformed target (numpy.log1p(target)), LightGBM is implicitly minimizing the squared difference between the log-transformed predictions and log-transformed actual values.\n",
    "- However, during evaluation, you'll need to transform the predicted values back using the inverse function (np.expm1(predicted_values)) to recover the original scale for calculating the actual RMSLE.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "- This approach is more suitable for LightGBM's \"mean_squared_error\" objective because it aligns the training process with the logic of RMSLE.\n",
    "It avoids potential issues with taking the logarithm of zero target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_for_fe = [x for x in df_train.columns if x not in COLS_TO_LEAVE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_features(df_train, df_test, feature_cols, NUM_NEW_FEATURES=10):\n",
    "    train_X = df_train[feature_cols] \n",
    "    test_X = df_test[feature_cols]   \n",
    "    train_y = df_train[Config.TARGET_COL_NAME]\n",
    "    ofe = OpenFE()\n",
    "    features = ofe.fit(data=train_X, label=train_y, n_jobs=CPU_COUNT, verbose=False)  # generate new features\n",
    "    # OpenFE recommends a list of new features. We include the top 10\n",
    "    # generated features to see how they influence the model performance\n",
    "    train_X, test_X = transform(train_X, test_X, ofe.new_features_list[:NUM_NEW_FEATURES], n_jobs=CPU_COUNT)\n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.GENERATE_AUTO_FEATURES:\n",
    "    df_train, df_test = generate_new_features(df_train, df_test, feature_cols_for_fe)    \n",
    "    df_train_labels = df_train_orig[[Config.TARGET_COL_NAME]]\n",
    "    # Add the label data to the dataframe\n",
    "    df_train = pd.concat([df_train, df_train_labels], axis=1)\n",
    "    # save the new train and test data with openfe features to csv files for later use\n",
    "    df_train.to_csv(DATA_WRITEPATH + \"train_openfe.csv\", index=False)\n",
    "    df_test.to_csv(DATA_WRITEPATH + \"test_openfe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_float = [ x for x in df_train.select_dtypes(include=[\"float\"]).columns.to_list() if x not in COLS_TO_LEAVE]\n",
    "cols_int = df_train.select_dtypes(include=[\"int64\"]).columns.to_list()\n",
    "cols_str = df_train.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "feature_cols_to_normalize = cols_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>autoFE_f_0</th>\n",
       "      <th>autoFE_f_1</th>\n",
       "      <th>autoFE_f_2</th>\n",
       "      <th>autoFE_f_3</th>\n",
       "      <th>autoFE_f_4</th>\n",
       "      <th>autoFE_f_5</th>\n",
       "      <th>autoFE_f_6</th>\n",
       "      <th>autoFE_f_7</th>\n",
       "      <th>autoFE_f_8</th>\n",
       "      <th>autoFE_f_9</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>2.291667</td>\n",
       "      <td>1.368750</td>\n",
       "      <td>1.791667</td>\n",
       "      <td>2.348554</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>2637.0</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.145</td>\n",
       "      <td>1.1300</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>1.968750</td>\n",
       "      <td>1.431250</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>2.467249</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.4650</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.818182</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>1.502000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.435419</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>2088.0</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>2.810127</td>\n",
       "      <td>1.870886</td>\n",
       "      <td>2.151899</td>\n",
       "      <td>2.116373</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Whole weight.1  Whole weight.2  \\\n",
       "0   F   0.550     0.430   0.150        0.7715          0.3285          0.1465   \n",
       "1   F   0.630     0.490   0.145        1.1300          0.4580          0.2765   \n",
       "2   I   0.160     0.110   0.025        0.0210          0.0055          0.0030   \n",
       "3   M   0.595     0.475   0.150        0.9145          0.3755          0.2055   \n",
       "4   I   0.555     0.425   0.130        0.7820          0.3695          0.1600   \n",
       "\n",
       "   Shell weight  autoFE_f_0  autoFE_f_1  autoFE_f_2  autoFE_f_3  autoFE_f_4  \\\n",
       "0        0.2400    2.291667    1.368750    1.791667    2.348554      0.3100   \n",
       "1        0.3200    1.968750    1.431250    1.531250    2.467249      0.3100   \n",
       "2        0.0050   32.000000    1.100000   22.000000    3.818182      0.1550   \n",
       "3        0.2500    2.380000    1.502000    1.900000    2.435419      0.3450   \n",
       "4        0.1975    2.810127    1.870886    2.151899    2.116373      0.3575   \n",
       "\n",
       "   autoFE_f_5  autoFE_f_6  autoFE_f_7  autoFE_f_8  autoFE_f_9  Rings  \n",
       "0      0.4430      0.3900      2637.0      0.2400      0.1900     11  \n",
       "1      0.6720      0.4650      1173.0      0.3200      0.1700     11  \n",
       "2      0.0155      0.0300       487.0      0.0050      0.1050      6  \n",
       "3      0.5390      0.4000      2088.0      0.2500      0.2250     10  \n",
       "4      0.4125      0.3275        32.0      0.1975      0.2275      9  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_stratification_target(df, cols, threshold=25):\n",
    "    df[\"outlier_labels\"] = \"\"\n",
    "    for col in cols:\n",
    "        q1 = np.percentile(df[col], threshold)\n",
    "        q3 = np.percentile(df[col], 100 - threshold)\n",
    "        iqr = q3-q1\n",
    "        min_val = q1 - 1.5 * iqr\n",
    "        max_val = q3 + 1.5 * iqr        \n",
    "        outlier_indices = np.logical_or(df[col] < min_val, df[col] > max_val)\n",
    "        df.loc[outlier_indices, \"outlier_labels\"] = df.loc[outlier_indices, \"outlier_labels\"] + col + \"-\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_ouliers = [x for x in cols_float if \"autoFE_f_\" not in x]\n",
    "df_train = define_stratification_target(df_train, cols_with_ouliers, threshold=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>autoFE_f_0</th>\n",
       "      <th>autoFE_f_1</th>\n",
       "      <th>...</th>\n",
       "      <th>autoFE_f_3</th>\n",
       "      <th>autoFE_f_4</th>\n",
       "      <th>autoFE_f_5</th>\n",
       "      <th>autoFE_f_6</th>\n",
       "      <th>autoFE_f_7</th>\n",
       "      <th>autoFE_f_8</th>\n",
       "      <th>autoFE_f_9</th>\n",
       "      <th>Rings</th>\n",
       "      <th>outlier_labels</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.8295</td>\n",
       "      <td>0.2405</td>\n",
       "      <td>0.2005</td>\n",
       "      <td>0.265</td>\n",
       "      <td>1.962264</td>\n",
       "      <td>0.907547</td>\n",
       "      <td>...</td>\n",
       "      <td>3.449064</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.5890</td>\n",
       "      <td>0.405</td>\n",
       "      <td>2037.0</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.130</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.3155</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.245</td>\n",
       "      <td>2.326531</td>\n",
       "      <td>1.287755</td>\n",
       "      <td>...</td>\n",
       "      <td>2.551506</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.195</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.2740</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.380</td>\n",
       "      <td>1.763158</td>\n",
       "      <td>1.563158</td>\n",
       "      <td>...</td>\n",
       "      <td>2.144781</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.555</td>\n",
       "      <td>435.0</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.130</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.120</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>1.420833</td>\n",
       "      <td>...</td>\n",
       "      <td>2.146628</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>0.230</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.230</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>0.100</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.565000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.054313</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.210</td>\n",
       "      <td>707.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.235</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex  Length  Diameter  Height  Whole weight  Whole weight.1  Whole weight.2  \\\n",
       "0   F   0.520     0.395   0.140        0.8295          0.2405          0.2005   \n",
       "1   I   0.570     0.440   0.130        0.8050          0.3155          0.2000   \n",
       "2   F   0.670     0.510   0.175        1.2740          0.5940          0.3000   \n",
       "3   I   0.460     0.350   0.110        0.3660          0.1705          0.0855   \n",
       "4   I   0.435     0.335   0.110        0.3215          0.1565          0.0635   \n",
       "\n",
       "   Shell weight  autoFE_f_0  autoFE_f_1  ...  autoFE_f_3  autoFE_f_4  \\\n",
       "0         0.265    1.962264    0.907547  ...    3.449064       0.255   \n",
       "1         0.245    2.326531    1.287755  ...    2.551506       0.325   \n",
       "2         0.380    1.763158    1.563158  ...    2.144781       0.290   \n",
       "3         0.120    3.833333    1.420833  ...    2.146628       0.340   \n",
       "4         0.100    4.350000    1.565000  ...    2.054313       0.335   \n",
       "\n",
       "   autoFE_f_5  autoFE_f_6  autoFE_f_7  autoFE_f_8  autoFE_f_9  Rings  \\\n",
       "0      0.5890       0.405      2037.0       0.265       0.130     15   \n",
       "1      0.4895       0.375      1277.0       0.245       0.195      9   \n",
       "2      0.6800       0.555       435.0       0.380       0.130      9   \n",
       "3      0.1955       0.230      1586.0       0.120       0.230      8   \n",
       "4      0.1650       0.210       707.0       0.100       0.235      7   \n",
       "\n",
       "   outlier_labels kfold  \n",
       "0                     6  \n",
       "1                     1  \n",
       "2                     4  \n",
       "3                     1  \n",
       "4                     8  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = cv_split_utils.strat_kfold_dataframe(\n",
    "                                    df=df_train,                           \n",
    "                                    target_col_name=Config.TARGET_COL_NAME,\n",
    "                                    num_folds=Config.NUM_FOLDS,\n",
    "                                    random_state=Config.RANDOM_SEED\n",
    "                                )\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(df, features_to_preprocess):\n",
    "    float_outliers = []\n",
    "    for col_name in features_to_preprocess:\n",
    "        df, df_col_outliers = data_utils.process_outliers_iqr(df, col_name, Config.REMOVE_OUTLIERS)\n",
    "        df_float_outliers = float_outliers.append(df_col_outliers)\n",
    "        if Config.POWER_TRANSFORM:\n",
    "            df, transformed = data_utils.power_transform(df, col_name, Config.SKEW_THRESHOLD)\n",
    "    df_float_outliers = pd.concat(float_outliers, axis=0)        \n",
    "    df_float_outliers = df_float_outliers.reset_index(drop=True)\n",
    "    return df, df_float_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess float features for train and test data\n",
    "df_train, df_train_float_outliers = preprocess_features(df_train, cols_float)\n",
    "_, df_test_float_outliers = preprocess_features(df_test, cols_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of categorical variables\n",
    "df_train_onehot = pd.get_dummies(df_train, columns=cols_str)\n",
    "df_test_onehot = pd.get_dummies(df_test, columns=cols_str)\n",
    "\n",
    "if Config.NORMALIZE_DATA:\n",
    "    # normalize\n",
    "    df_train_onehot = tt.normalize_features(df_train_onehot, \n",
    "                                            scaler=Config.SCALER,\n",
    "                                            features_to_normalize=feature_cols_to_normalize)\n",
    "    df_test_onehot = tt.normalize_features(df_test_onehot,\n",
    "                                           scaler=Config.SCALER, \n",
    "                                           features_to_normalize=feature_cols_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Length', 'Diameter', 'Height', 'Whole weight', 'Whole weight.1', 'Whole weight.2', 'Shell weight', 'autoFE_f_0', 'autoFE_f_1', 'autoFE_f_2', 'autoFE_f_3', 'autoFE_f_4', 'autoFE_f_5', 'autoFE_f_6', 'autoFE_f_7', 'autoFE_f_8', 'autoFE_f_9', 'Sex_F', 'Sex_I', 'Sex_M']\n"
     ]
    }
   ],
   "source": [
    "feature_cols= [x for x in df_train_onehot.columns.to_list() if x not in COLS_TO_LEAVE]\n",
    "print(feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgbm_tuning_params(trial):    \n",
    "    params_dynamic = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=25),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 20),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 256, step=4),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 500, step=20)\n",
    "    }\n",
    "    return {**lgbm_params_static, **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catboost_tuning_params(trial):\n",
    "    params_dynamic = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 5000, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 16),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 256, step=4),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "        'random_strength': trial.suggest_loguniform('random_strength', 0.01, 10),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 500, step=20),\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255)\n",
    "    }\n",
    "    return {**cb_params_static, **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_tuning_params(trial, model_name):\n",
    "    if model_name == enums.ModelName.Ridge:\n",
    "        return {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-4, 1e4, log=True)\n",
    "        }\n",
    "    if model_name == enums.ModelName.Lasso:\n",
    "        return {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-4, 1e4, log=True)\n",
    "        }\n",
    "    if model_name == enums.ModelName.RandomForest:\n",
    "        return {        \n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 3000, step=100),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 10, 30),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 2, 16),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 16),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"log2\", \"sqrt\", None])\n",
    "        }\n",
    "    if model_name == enums.ModelName.XGBoost:\n",
    "        xgb_params_dynamic = {            \n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=100),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 32),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "            'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 100, 500, step=20)\n",
    "        }\n",
    "        return {**xgb_params_static, **xgb_params_dynamic}\n",
    "    if model_name == enums.ModelName.LGBM:\n",
    "        return get_lgbm_tuning_params(trial)\n",
    "    if model_name == enums.ModelName.CatBoost:\n",
    "        return get_catboost_tuning_params(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparams_tuning_objective(trial, model_name, df_train,  \n",
    "                                 feature_cols, metric, target_col_name, single_fold=False,\n",
    "                                 num_folds=5, val_preds_col=\"val_preds\"):           \n",
    "    model_params = get_model_tuning_params(trial, model_name)    \n",
    "    fold_metrics_model, df_val_preds = tt.run_training(\n",
    "        model_name=model_name,\n",
    "        df_train=df_train,\n",
    "        target_col_name=target_col_name,\n",
    "        feature_col_names=feature_cols,\n",
    "        metric=metric,            \n",
    "        num_folds=num_folds,\n",
    "        model_params=model_params,\n",
    "        val_preds_col=val_preds_col,\n",
    "        single_fold=single_fold,\n",
    "        suppress_print=True,\n",
    "        transform_target=Config.TRANSFORM_TARGET\n",
    "    )       \n",
    "    fold_metrics = [x[0] for x in fold_metrics_model]\n",
    "    mean_metric = statistics.mean(fold_metrics)                \n",
    "    return mean_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model_params(study_name, study_direction, num_trials, model_name, \n",
    "                      df_train,  feature_cols, metric, target_col_name, \n",
    "                      single_fold=False, num_folds=5, val_preds_col=\"val_preds\"):\n",
    "    model_params_tuning_obj_partial = partial(\n",
    "        hyperparams_tuning_objective,\n",
    "        model_name=model_name,        \n",
    "        df_train=df_train,\n",
    "        feature_cols=feature_cols,\n",
    "        metric=metric,\n",
    "        target_col_name=target_col_name,\n",
    "        single_fold=single_fold,\n",
    "        num_folds=num_folds,\n",
    "        val_preds_col=val_preds_col\n",
    "    )\n",
    "    study = optuna.create_study(direction=study_direction, study_name=study_name)\n",
    "    study.optimize(model_params_tuning_obj_partial, n_trials=num_trials)\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"Best trial: number = {best_trial.number}, value = {best_trial.value}, params = {best_trial.params}\")\n",
    "    return best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-17 21:25:06,912] A new study created in memory with name: CatBoost_ModelTuning\n",
      "[I 2024-05-17 21:30:02,423] Trial 0 finished with value: 0.14438552534799184 and parameters: {'learning_rate': 0.024412101920388406, 'n_estimators': 5000, 'max_depth': 9, 'min_data_in_leaf': 55, 'subsample': 0.5293474651046968, 'colsample_bytree': 0.6591966536674199, 'num_leaves': 256, 'reg_lambda': 66.88385862648975, 'random_strength': 0.010625663387124671, 'early_stopping_rounds': 370, 'max_bin': 42}. Best is trial 0 with value: 0.14438552534799184.\n",
      "[I 2024-05-17 21:30:14,261] Trial 1 finished with value: 0.1447271752131244 and parameters: {'learning_rate': 0.04730739524357821, 'n_estimators': 450, 'max_depth': 4, 'min_data_in_leaf': 49, 'subsample': 0.7423412709661512, 'colsample_bytree': 0.7521570927655419, 'num_leaves': 172, 'reg_lambda': 36.38465636240302, 'random_strength': 9.795904452783349, 'early_stopping_rounds': 310, 'max_bin': 221}. Best is trial 0 with value: 0.14438552534799184.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: number = 0, value = 0.14438552534799184, params = {'learning_rate': 0.024412101920388406, 'n_estimators': 5000, 'max_depth': 9, 'min_data_in_leaf': 55, 'subsample': 0.5293474651046968, 'colsample_bytree': 0.6591966536674199, 'num_leaves': 256, 'reg_lambda': 66.88385862648975, 'random_strength': 0.010625663387124671, 'early_stopping_rounds': 370, 'max_bin': 42}\n"
     ]
    }
   ],
   "source": [
    "if tuned_model_params is None:\n",
    "    tuned_model_params = tune_model_params(\n",
    "                            study_name=Config.MODEL_TYPE + \"_ModelTuning\", \n",
    "                            study_direction=\"minimize\",\n",
    "                            num_trials=Config.NUM_TUNING_TRIALS,\n",
    "                            model_name=Config.MODEL_TYPE,\n",
    "                            df_train=df_train_onehot,\n",
    "                            feature_cols=feature_cols,\n",
    "                            metric=Config.METRIC,\n",
    "                            target_col_name=Config.TARGET_COL_NAME,\n",
    "                            single_fold=Config.TUNE_ON_SINGLE_FOLD,\n",
    "                            num_folds=Config.NUM_FOLDS\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {**params_static, **tuned_model_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training CatBoost\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'colsample_bytree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20629/3408612018.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fold_metrics_model = tt.train_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m                             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train_onehot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL_TYPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mfeature_col_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ML/ML_UTILS/train_tabular_utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(df, model_name, model_params, feature_col_names, target_col_name, metric, num_folds, single_fold, persist_model, output_path, transform_target)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mval_preds_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"l2_val_preds\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     fold_metrics_model, df_val_preds = run_training(\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mdf_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ML/ML_UTILS/train_tabular_utils.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model_name, df_train, target_col_name, feature_col_names, metric, num_folds, single_fold, model_params, val_preds_col, suppress_print, transform_target)\u001b[0m\n\u001b[1;32m    183\u001b[0m             )\n\u001b[1;32m    184\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mModelName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCatBoost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             fold_val_metric, fold_model, fold_val_preds = train_fold_xgb_cb(\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             )\n",
      "\u001b[0;32m~/code/ML/ML_UTILS/train_tabular_utils.py\u001b[0m in \u001b[0;36mtrain_fold_xgb_cb\u001b[0;34m(model_name, train_X, train_y, val_X, val_y, model_params, metric, transform_target)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_fold_xgb_cb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mfold_train_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tree_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModelName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCatBoost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ML/ML_UTILS/train_tabular_utils.py\u001b[0m in \u001b[0;36mget_tree_model\u001b[0;34m(model_name, metric, model_params)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModelName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCatBoost\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmetric_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModelName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCatBoost\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmetric_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'colsample_bytree'"
     ]
    }
   ],
   "source": [
    "fold_metrics_model = tt.train_model(\n",
    "                            df = df_train_onehot,\n",
    "                            model_name=Config.MODEL_TYPE,\n",
    "                            model_params = model_params,\n",
    "                            feature_col_names = feature_cols,\n",
    "                            target_col_name = Config.TARGET_COL_NAME,\n",
    "                            metric = Config.METRIC,\n",
    "                            num_folds = Config.NUM_FOLDS,\n",
    "                            single_fold = Config.TRAIN_SINGLE_FOLD,\n",
    "                            persist_model = Config.PERSIST_MODEL,\n",
    "                            output_path = DATA_WRITEPATH,\n",
    "                            transform_target = Config.TRANSFORM_TARGET\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if Config.MODEL_TYPE == enums.ModelName.XGBoost:\n",
    "    xgb.plot_importance(booster=fold_metrics_model[0][1])\n",
    "elif Config.MODEL_TYPE == enums.ModelName.LGBM:\n",
    "    lgbm.plot_importance(fold_metrics_model[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15636/3718973638.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNUM_FOLDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold_metrics_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test_onehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfold_test_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "test_preds = {}\n",
    "for fold in range(Config.NUM_FOLDS):\n",
    "    model = fold_metrics_model[fold][1]    \n",
    "    test_df = df_test_onehot[feature_cols]             \n",
    "    fold_test_preds = model.predict(test_df)    \n",
    "    if Config.TRANSFORM_TARGET:\n",
    "        # Since we have trained on np.log1p(y) instead of y, we need to reverse the transformation to extract the actual predictions\n",
    "        fold_test_preds = np.expm1(fold_test_preds)    \n",
    "    pred_col_name = f\"fold_{fold}_test_preds\"\n",
    "    test_preds[pred_col_name] = fold_test_preds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed prediction for 60411 test rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90615</td>\n",
       "      <td>9.560521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90616</td>\n",
       "      <td>9.761124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90617</td>\n",
       "      <td>9.404902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90618</td>\n",
       "      <td>10.181639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90619</td>\n",
       "      <td>7.744676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      Rings\n",
       "0  90615   9.560521\n",
       "1  90616   9.761124\n",
       "2  90617   9.404902\n",
       "3  90618  10.181639\n",
       "4  90619   7.744676"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_preds = pd.DataFrame(test_preds)\n",
    "test_pred_cols = [f\"fold_{fold}_test_preds\" for fold in range(Config.NUM_FOLDS)]\n",
    "df_test_preds[\"mean_test_pred\"] = df_test_preds[test_pred_cols].mean(axis=1)\n",
    "df_test_preds[\"mean_test_pred_rounded\"] = np.round(df_test_preds[\"mean_test_pred\"]).astype(int)\n",
    "print(f\"Completed prediction for {len(df_test)} test rows\")\n",
    "df_submission = pd.read_csv(SUBMISSION_FILEPATH + 'sample_submission.csv')\n",
    "#df_submission['Rings']= df_test_preds[\"mean_test_pred_rounded\"]\n",
    "df_submission['Rings']= df_test_preds[\"mean_test_pred\"]\n",
    "df_submission.to_csv(DATA_WRITEPATH + f'submission_{Config.MODEL_TYPE}.csv',index=False)\n",
    "df_test_preds.to_csv(DATA_WRITEPATH + 'test_preds.csv',index=False)\n",
    "df_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
