{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import statistics\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.utils import class_weight\n",
    "from functools import partial\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"/home/bk_anupam/code/ML/ML_UTILS/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_tabular_utils as tt\n",
    "import cv_split_utils\n",
    "import enums\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RUN_MODE = \"LOCAL\"\n",
    "    RANDOM_SEED = 42\n",
    "    NUM_FOLDS = 5\n",
    "    TARGET_COL_NAME = \"Target\"        \n",
    "    SCALER = enums.Scaler.StandardScaler\n",
    "    METRIC = enums.Metrics.ACCURACY\n",
    "    # These values are more dynamic   \n",
    "    MODEL_TYPE = enums.ModelName.LogisticRegression\n",
    "    NUM_TUNING_TRIALS = 25\n",
    "    TUNE_ON_SINGLE_FOLD = True\n",
    "    TRAIN_SINGLE_FOLD = False    \n",
    "    PERSIST_MODEL = False\n",
    "    USE_OPENFE_FEATURES = True\n",
    "    CREATE_MANUAL_FEATURES = False\n",
    "    USE_ORIGINAL_DATA = True\n",
    "    NUM_CLASSES = 3\n",
    "\n",
    "COLS_TO_LEAVE = [\"id\", \"Target\", \"kfold\"]\n",
    "CPU_COUNT = os.cpu_count()\n",
    "\n",
    "DATA_READPATH = \"./data/\"\n",
    "DATA_WRITEPATH = \"./output/\"\n",
    "SUBMISSION_FILEPATH = DATA_READPATH\n",
    "if Config.RUN_MODE == \"KAGGLE\":    \n",
    "    DATA_READPATH = \"/kaggle/input/playground-series-s4e6/\"\n",
    "    if Config.USE_OPENFE_FEATURES:\n",
    "        DATA_READPATH = \"/kaggle/input/ps4e6-openfe/\"\n",
    "    SUBMISSION_FILEPATH = \"/kaggle/input/playground-series-s4e6/\"\n",
    "    DATA_WRITEPATH = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch original dataset \n",
    "predict_students_dropout_and_academic_success = fetch_ucirepo(id=697) \n",
    "df_train_orig = predict_students_dropout_and_academic_success.data.features \n",
    "df_train_orig[Config.TARGET_COL_NAME] = predict_students_dropout_and_academic_success.data.targets[Config.TARGET_COL_NAME]\n",
    "# rename column 'Marital Status' to 'Marital status'\n",
    "df_train_orig = df_train_orig.rename(columns={'Marital Status': 'Marital status'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no missing values in original data\n",
    "na_orig = df_train_orig.isna().sum()\n",
    "na_orig.loc[na_orig > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using generated openfe features on both train and original data\n"
     ]
    }
   ],
   "source": [
    "if Config.USE_OPENFE_FEATURES and not Config.USE_ORIGINAL_DATA:\n",
    "    print(\"using generated openfe features only on train data\")\n",
    "    df_train = pd.read_csv(DATA_READPATH + \"train_openfe.csv\")    \n",
    "    df_test = pd.read_csv(DATA_READPATH + \"test_openfe.csv\")\n",
    "elif Config.USE_OPENFE_FEATURES and Config.USE_ORIGINAL_DATA:\n",
    "    print(\"using generated openfe features on both train and original data\")\n",
    "    df_train = pd.read_csv(DATA_READPATH + \"train_orig_openfe.csv\")    \n",
    "    df_test = pd.read_csv(DATA_READPATH + \"test_orig_openfe.csv\")\n",
    "else:    \n",
    "    df_train = pd.read_csv(DATA_READPATH + \"train.csv\")\n",
    "    df_train = df_train.drop(\"id\", axis=1)    \n",
    "    df_test = pd.read_csv(DATA_READPATH + \"test.csv\")\n",
    "    df_test = df_test.drop(\"id\", axis=1)\n",
    "    if Config.USE_ORIGINAL_DATA:\n",
    "        # add df_train_orig rows to df_train\n",
    "        df_train = pd.concat([df_train, df_train_orig], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dropout', 'Enrolled', 'Graduate']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoding of target values\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[Config.TARGET_COL_NAME])\n",
    "df_train[Config.TARGET_COL_NAME] = le.transform(df_train[Config.TARGET_COL_NAME])\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00986887 1.71480022 0.7009604 ]\n"
     ]
    }
   ],
   "source": [
    "# Dropout = 0.33, Enrolled = 0.2, Graduate = 0.47\n",
    "# Increase the weight of the minority class for model to focus more on the minority class\n",
    "# calculate class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(df_train.Target), y=df_train.Target)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_static_params = {\n",
    "    enums.ModelName.XGBoost: {\n",
    "        \"objective\": \"multi:softmax\",        \n",
    "        \"seed\": Config.RANDOM_SEED,\n",
    "        \"verbosity\": 0,\n",
    "        \"num_class\": 3,\n",
    "        \"eval_metric\": \"merror\"\n",
    "    },\n",
    "    enums.ModelName.LGBM: {\n",
    "        \"objective\": \"root_mean_squared_error\",\n",
    "        \"metric\": 'rmse',\n",
    "        \"verbosity\": -1,    # <0: fatal, =0: error (warn), =1: info, >1: debug\n",
    "        \"boosting_type\": \"gbdt\"\n",
    "    },\n",
    "    enums.ModelName.CatBoost: {\n",
    "        \"objective\": \"MultiClass\",\n",
    "        \"verbose\": 0,\n",
    "        \"random_seed\": Config.RANDOM_SEED,\n",
    "        \"eval_metric\": \"Accuracy\",\n",
    "        'grow_policy':  'Lossguide',\n",
    "        #'bootstrap_type': 'Poisson',\n",
    "        #'class_weights': class_weights,\n",
    "        'task_type': 'CPU'\n",
    "    },\n",
    "    enums.ModelName.RandomForest: {\n",
    "        \"random_state\": Config.RANDOM_SEED,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For RandomForest\n",
    "#tuned_model_params = {'n_estimators': 1300, 'max_depth': 17, 'min_samples_leaf': 3, 'min_samples_split': 3, 'max_features': 'sqrt'}\n",
    "# For CatBoost\n",
    "# tuned_model_params = {'learning_rate': 0.45126024670762294, 'n_estimators': 3700, 'max_depth': 7, 'min_data_in_leaf': 73, 'colsample_bylevel': 0.8908705634626486, 'num_leaves': 120, 'reg_lambda': 98.46961225632553, 'random_strength': 0.016359736302592447, 'early_stopping_rounds': 210, 'max_bin': 253}\n",
    "# For XGBoost\n",
    "#tuned_model_params = {'n_estimators': 1400, 'learning_rate': 0.10270166896064774, 'max_depth': 30, 'min_child_weight': 7, 'gamma': 4.123490349502186, 'subsample': 0.5067185283456936, 'colsample_bytree': 0.7289930512882908, 'reg_alpha': 0.5971832077526927, 'reg_lambda': 9.433125479981229, 'early_stopping_rounds': 260}\n",
    "\n",
    "tuned_model_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_col_name(cols_list):\n",
    "    processed_cols_list = []\n",
    "    for item in cols_list:\n",
    "        # Remove round brackets but keep the text inside them\n",
    "        item_no_brackets = re.sub(r'[\\(\\)]', '', item)\n",
    "        # Remove single quotes\n",
    "        item_no_quotes = item_no_brackets.replace(\"'\", \"\")\n",
    "        # Replace spaces with underscores\n",
    "        item_processed = item_no_quotes.replace(' ', '_')\n",
    "        # Append to the processed list\n",
    "        processed_cols_list.append(item_processed)\n",
    "    return processed_cols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols_list = df_train.columns.to_list()\n",
    "test_cols_list = df_test.columns.to_list()\n",
    "train_processed_cols_list = process_col_name(train_cols_list)\n",
    "test_processed_cols_list = process_col_name(test_cols_list)\n",
    "df_train.columns = train_processed_cols_list\n",
    "df_test.columns = test_processed_cols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "def create_features(df):\n",
    "    # (Tuition_fees_up_to_date*Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_1\"] = df[\"Tuition_fees_up_to_date\"] * df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # (Curricular_units_1st_sem_approved+Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_2\"] = df[\"Curricular_units_1st_sem_approved\"] + df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # (Curricular_units_2nd_sem_grade*Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_3\"] = df[\"Curricular_units_2nd_sem_grade\"] * df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # (Curricular_units_2nd_sem_grade+Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_4\"] = df[\"Curricular_units_2nd_sem_grade\"] + df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # (Curricular_units_2nd_sem_grade+Scholarship_holder)\n",
    "    df[\"f_5\"] = df[\"Curricular_units_2nd_sem_grade\"] + df[\"Scholarship_holder\"]\n",
    "    # (Curricular_units_1st_sem_grade+Scholarship_holder)\n",
    "    df[\"f_6\"] = df[\"Curricular_units_1st_sem_grade\"] + df[\"Scholarship_holder\"]\n",
    "    # (Curricular_units_2nd_sem_enrolled-Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_7\"] = df[\"Curricular_units_2nd_sem_enrolled\"] - df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # (Curricular_units_1st_sem_enrolled-Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_8\"] = df[\"Curricular_units_1st_sem_enrolled\"] - df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # (Curricular_units_2nd_sem_grade-Curricular_units_1st_sem_evaluations)\n",
    "    df[\"f_9\"] = df[\"Curricular_units_2nd_sem_grade\"] - df[\"Curricular_units_1st_sem_evaluations\"]\n",
    "    # (Curricular_units_1st_sem_grade/Age_at_enrollment)\n",
    "    df[\"f_10\"] = df[\"Curricular_units_1st_sem_grade\"] / df[\"Age_at_enrollment\"]\n",
    "    # (Curricular_units_1st_sem_evaluations-Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_11\"] = df[\"Curricular_units_1st_sem_evaluations\"] - df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # GroupByThenRank(Curricular_units_2nd_sem_approved,Curricular_units_1st_sem_enrolled)    \n",
    "    df[\"f_12\"] = df.groupby('Curricular_units_1st_sem_enrolled')['Curricular_units_2nd_sem_approved'].rank(method=\"dense\", ascending=False)\n",
    "    # GroupByThenRank(Curricular_units_2nd_sem_approved,Mothers_occupation)\n",
    "    df[\"f_13\"] = df.groupby('Mothers_occupation')['Curricular_units_2nd_sem_approved'].rank(method=\"dense\", ascending=False)\n",
    "    # GroupByThenRank(Scholarship_holder,Age_at_enrollment)\n",
    "    df[\"f_14\"] = df.groupby('Age_at_enrollment')['Scholarship_holder'].rank(method=\"dense\", ascending=False)\n",
    "    # GroupByThenRank(Scholarship_holder,Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_15\"] = df.groupby('Curricular_units_2nd_sem_approved')['Scholarship_holder'].rank(method=\"dense\", ascending=False)\n",
    "    # CombineThenFreq(Course,Curricular_units_1st_sem_approved)\n",
    "    df[\"f_16\"] = df.groupby('Course')['Curricular_units_1st_sem_approved'].transform('count')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.CREATE_MANUAL_FEATURES:\n",
    "    df_train = create_features(df_train)\n",
    "    df_test = create_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autoFE_f_1',\n",
       " 'autoFE_f_2',\n",
       " 'autoFE_f_3',\n",
       " 'autoFE_f_5',\n",
       " 'autoFE_f_6',\n",
       " 'autoFE_f_7',\n",
       " 'autoFE_f_10',\n",
       " 'autoFE_f_13',\n",
       " 'autoFE_f_15',\n",
       " 'autoFE_f_16',\n",
       " 'autoFE_f_17',\n",
       " 'autoFE_f_18',\n",
       " 'autoFE_f_19',\n",
       " 'autoFE_f_23',\n",
       " 'autoFE_f_31',\n",
       " 'autoFE_f_37',\n",
       " 'autoFE_f_42',\n",
       " 'autoFE_f_47']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_val = df_train.isna().sum()\n",
    "null_features = na_val.loc[na_val > 0].index.values.tolist()\n",
    "null_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['Marital_status', 'Application_mode', 'Course', 'Daytime/evening_attendance', 'Previous_qualification',\n",
    "    'Nacionality', 'Mothers_qualification', 'Fathers_qualification', 'Mothers_occupation', 'Fathers_occupation', 'Displaced',\n",
    "    'Educational_special_needs', 'Debtor', 'Tuition_fees_up_to_date','Gender', 'Scholarship_holder', 'International']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features = [x for x in df_train.dtypes[df_train.dtypes == \"float\"].index.values if x not in null_features]\n",
    "int_features = [x for x in df_train.dtypes[df_train.dtypes == \"int\"].index.values if x not in COLS_TO_LEAVE+null_features]\n",
    "feature_cols = df_test.columns.to_list()\n",
    "feature_cols_after_fe = [x for x in df_train.columns if x not in COLS_TO_LEAVE+null_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for categorical features find the categories to be used for one hot encoding\n",
    "int_feature_categories = []\n",
    "for int_feature in int_features:\n",
    "    int_feature_categories.append(sorted(df_train[int_feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(feature_cols_after_fe)=68\n",
      "['Marital_status', 'Application_mode', 'Application_order', 'Course', 'Daytime/evening_attendance', 'Previous_qualification', 'Previous_qualification_grade', 'Nacionality', 'Mothers_qualification', 'Fathers_qualification', 'Mothers_occupation', 'Fathers_occupation', 'Admission_grade', 'Displaced', 'Educational_special_needs', 'Debtor', 'Tuition_fees_up_to_date', 'Gender', 'Scholarship_holder', 'Age_at_enrollment', 'International', 'Curricular_units_1st_sem_credited', 'Curricular_units_1st_sem_enrolled', 'Curricular_units_1st_sem_evaluations', 'Curricular_units_1st_sem_approved', 'Curricular_units_1st_sem_grade', 'Curricular_units_1st_sem_without_evaluations', 'Curricular_units_2nd_sem_credited', 'Curricular_units_2nd_sem_enrolled', 'Curricular_units_2nd_sem_evaluations', 'Curricular_units_2nd_sem_approved', 'Curricular_units_2nd_sem_grade', 'Curricular_units_2nd_sem_without_evaluations', 'Unemployment_rate', 'Inflation_rate', 'GDP', 'autoFE_f_0', 'autoFE_f_4', 'autoFE_f_8', 'autoFE_f_9', 'autoFE_f_11', 'autoFE_f_12', 'autoFE_f_14', 'autoFE_f_20', 'autoFE_f_21', 'autoFE_f_22', 'autoFE_f_24', 'autoFE_f_25', 'autoFE_f_26', 'autoFE_f_27', 'autoFE_f_28', 'autoFE_f_29', 'autoFE_f_30', 'autoFE_f_32', 'autoFE_f_33', 'autoFE_f_34', 'autoFE_f_35', 'autoFE_f_36', 'autoFE_f_38', 'autoFE_f_39', 'autoFE_f_40', 'autoFE_f_41', 'autoFE_f_43', 'autoFE_f_44', 'autoFE_f_45', 'autoFE_f_46', 'autoFE_f_48', 'autoFE_f_49']\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(feature_cols_after_fe)={len(feature_cols_after_fe)}\")\n",
    "print(feature_cols_after_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "preprocessor = None\n",
    "scaler = StandardScaler()\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\", categories=int_feature_categories)\n",
    "if Config.MODEL_TYPE == enums.ModelName.LogisticRegression:\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[                \n",
    "            (\"scaler\", scaler, feature_cols_after_fe),\n",
    "            (\"onehot\", onehot_encoder, int_features),                \n",
    "        ], remainder=\"passthrough\"\n",
    "    )\n",
    "else:\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[                \n",
    "            (\"scaler\", scaler, cont_features)     \n",
    "        ], remainder=\"passthrough\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgb_tuning_params(trial):\n",
    "    params_dynamic = {            \n",
    "            'n_estimators': trial.suggest_int('n_estimators', 1000, 5000, step=100),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-2, 1.0, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 32),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1, 200),\n",
    "            'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 100, 500, step=20)\n",
    "        }\n",
    "    return {**model_static_params[enums.ModelName.XGBoost], **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catboost_tuning_params(trial):\n",
    "    params_dynamic = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 5000, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 16),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),\n",
    "        #'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        # comment colsample_bylevel for GPU training\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 256, step=4),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "        'random_strength': trial.suggest_loguniform('random_strength', 0.01, 10),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 500, step=20),\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255)\n",
    "    }\n",
    "    return {**model_static_params[enums.ModelName.CatBoost], **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_tuning_params(trial, model_name):\n",
    "    if model_name == enums.ModelName.LogisticRegression:\n",
    "        penalty = ['l1', 'l2']\n",
    "        return {        \n",
    "            \"C\": trial.suggest_loguniform(\"C\", 1e-3, 100),\n",
    "            \"penalty\": trial.suggest_categorical(\"penalty\", penalty)\n",
    "        }    \n",
    "    if model_name == enums.ModelName.RandomForest:\n",
    "        return {        \n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 3000, step=100),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 10, 30),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 2, 16),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 16),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"log2\", \"sqrt\", None])\n",
    "        }\n",
    "    if model_name == enums.ModelName.CatBoost:\n",
    "        return get_catboost_tuning_params(trial)\n",
    "    if model_name == enums.ModelName.XGBoost:\n",
    "        return get_xgb_tuning_params(trial)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparams_tuning_objective(trial, model_name, preprocessor, df,  \n",
    "                                 feature_cols, metric, target_col_name, single_fold=False, num_folds=5):               \n",
    "    model_params = get_model_tuning_params(trial, model_name)    \n",
    "    fold_metrics_model, _, _ = tt.train_and_validate(\n",
    "                                        model_name=model_name,\n",
    "                                        model_params=model_params,\n",
    "                                        preprocessor=preprocessor,\n",
    "                                        df=df,\n",
    "                                        feature_cols=feature_cols,\n",
    "                                        target_col_name=target_col_name,\n",
    "                                        metric=metric,\n",
    "                                        single_fold=single_fold,\n",
    "                                        num_folds=num_folds,\n",
    "                                        suppress_print=True,\n",
    "                                        num_classes=Config.NUM_CLASSES\n",
    "                                    )\n",
    "    fold_metrics = [x[0] for x in fold_metrics_model]\n",
    "    mean_metric = statistics.mean(fold_metrics)                \n",
    "    return mean_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model_params(study_name, study_direction, num_trials, model_name, \n",
    "                      preprocessor, df,  feature_cols, metric, target_col_name, \n",
    "                      single_fold=False, num_folds=5):\n",
    "    model_params_tuning_obj_partial = partial(\n",
    "        hyperparams_tuning_objective,\n",
    "        model_name=model_name,        \n",
    "        preprocessor=preprocessor,        \n",
    "        df=df,\n",
    "        feature_cols=feature_cols,\n",
    "        metric=metric,\n",
    "        target_col_name=target_col_name,\n",
    "        single_fold=single_fold,\n",
    "        num_folds=num_folds\n",
    "    )\n",
    "    study = optuna.create_study(direction=study_direction, study_name=study_name)\n",
    "    study.optimize(model_params_tuning_obj_partial, n_trials=num_trials)\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"Best trial: number = {best_trial.number}, value = {best_trial.value}, params = {best_trial.params}\")\n",
    "    return best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = cv_split_utils.strat_kfold_dataframe(df_train, \n",
    "                                                target_col_name=Config.TARGET_COL_NAME, \n",
    "                                                random_state=Config.RANDOM_SEED, \n",
    "                                                num_folds=Config.NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 12:13:25,277] A new study created in memory with name: LogisticRegression_ModelTuning\n",
      "[I 2024-06-15 12:13:43,311] Trial 0 finished with value: 0.8309345852121811 and parameters: {'C': 38.49119721953264, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:14:00,842] Trial 1 finished with value: 0.8309345852121811 and parameters: {'C': 0.2301410457243783, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:14:14,818] Trial 2 finished with value: 0.8309345852121811 and parameters: {'C': 23.37062917268853, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:14:29,520] Trial 3 finished with value: 0.8309345852121811 and parameters: {'C': 0.03386765488470402, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:14:41,116] Trial 4 finished with value: 0.8309345852121811 and parameters: {'C': 17.65068974894247, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:14:53,453] Trial 5 finished with value: 0.8309345852121811 and parameters: {'C': 0.5481802186126948, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:15:12,561] Trial 6 finished with value: 0.8309345852121811 and parameters: {'C': 0.013531056180790323, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:15:27,637] Trial 7 finished with value: 0.8309345852121811 and parameters: {'C': 69.55535346404109, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:15:42,383] Trial 8 finished with value: 0.8309345852121811 and parameters: {'C': 0.020166989008641445, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:15:55,173] Trial 9 finished with value: 0.8309345852121811 and parameters: {'C': 0.19312816953674125, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:16:07,976] Trial 10 finished with value: 0.8309345852121811 and parameters: {'C': 2.1730618165497964, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:16:20,239] Trial 11 finished with value: 0.8309345852121811 and parameters: {'C': 0.0012255369231713538, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:16:34,705] Trial 12 finished with value: 0.8309345852121811 and parameters: {'C': 2.8247357003256788, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:16:49,399] Trial 13 finished with value: 0.8309345852121811 and parameters: {'C': 0.19860184916960105, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:17:02,418] Trial 14 finished with value: 0.8309345852121811 and parameters: {'C': 2.0324530079294894, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:17:14,960] Trial 15 finished with value: 0.8309345852121811 and parameters: {'C': 7.845822896503926, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:17:33,390] Trial 16 finished with value: 0.8309345852121811 and parameters: {'C': 81.02437587899907, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:17:49,461] Trial 17 finished with value: 0.8309345852121811 and parameters: {'C': 0.06670544218328973, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:18:06,137] Trial 18 finished with value: 0.8309345852121811 and parameters: {'C': 0.5103172541640276, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:18:18,375] Trial 19 finished with value: 0.8309345852121811 and parameters: {'C': 0.003750797889034548, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:18:35,391] Trial 20 finished with value: 0.8309345852121811 and parameters: {'C': 0.0941243719067049, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:18:48,011] Trial 21 finished with value: 0.8309345852121811 and parameters: {'C': 14.679801762463981, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:18:59,975] Trial 22 finished with value: 0.8309345852121811 and parameters: {'C': 37.233836260192604, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:19:13,181] Trial 23 finished with value: 0.8309345852121811 and parameters: {'C': 5.929548772835682, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:19:25,665] Trial 24 finished with value: 0.8309345852121811 and parameters: {'C': 1.0402765350003143, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: number = 0, value = 0.8309345852121811, params = {'C': 38.49119721953264, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "if tuned_model_params is None:\n",
    "    #df = df_train.sample(frac=0.1, random_state=Config.RANDOM_SEED)\n",
    "    tuned_model_params = tune_model_params(\n",
    "                            study_name=Config.MODEL_TYPE + \"_ModelTuning\", \n",
    "                            study_direction=\"maximize\",\n",
    "                            num_trials=Config.NUM_TUNING_TRIALS,\n",
    "                            model_name=Config.MODEL_TYPE,\n",
    "                            preprocessor=preprocessor,\n",
    "                            df=df_train,\n",
    "                            feature_cols=feature_cols_after_fe,\n",
    "                            metric=Config.METRIC,\n",
    "                            target_col_name=Config.TARGET_COL_NAME,\n",
    "                            single_fold=Config.TUNE_ON_SINGLE_FOLD,\n",
    "                            num_folds=Config.NUM_FOLDS\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = None\n",
    "params_static = model_static_params.get(Config.MODEL_TYPE)\n",
    "if params_static is not None and tuned_model_params is not None:\n",
    "    model_params = {**model_static_params[Config.MODEL_TYPE], **tuned_model_params}\n",
    "else:\n",
    "    model_params = tuned_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - LogisticRegression - ACCURACY : 0.8309345852121811\n",
      "Fold 1 - LogisticRegression - ACCURACY : 0.8261782691951325\n",
      "Fold 2 - LogisticRegression - ACCURACY : 0.8254880158141833\n",
      "Fold 3 - LogisticRegression - ACCURACY : 0.825240919199407\n",
      "Fold 4 - LogisticRegression - ACCURACY : 0.8284531751914999\n",
      "LogisticRegression metric=ACCURACY CV score = 0.8272590249808505\n",
      "LogisticRegression Mean ACCURACY = 0.8272589929224807, std = 0.0021593052223561264\n",
      "CPU times: user 8min, sys: 4min 52s, total: 12min 53s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fold_metrics_model, df_oof_preds, preprocessor = tt.train_and_validate(\n",
    "        model_name=Config.MODEL_TYPE,\n",
    "        model_params=model_params,\n",
    "        preprocessor=preprocessor,\n",
    "        df=df_train,\n",
    "        feature_cols=feature_cols_after_fe,\n",
    "        target_col_name=Config.TARGET_COL_NAME,\n",
    "        metric=Config.METRIC,\n",
    "        single_fold=Config.TRAIN_SINGLE_FOLD,\n",
    "        num_folds=Config.NUM_FOLDS,\n",
    "        suppress_print=False,\n",
    "        num_classes=Config.NUM_CLASSES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agg_confusion_matrix(fold_metrics_model, preprocessor, df_train, feature_cols, target_col_name, num_folds=5):\n",
    "    cm = []\n",
    "    for fold in range(Config.NUM_FOLDS):\n",
    "        df_train_fold, df_val_fold = tt.get_fold_df(df_train, fold)\n",
    "        train_X, train_y, val_X, val_y = tt.get_train_val_nparray(df_train_fold, df_val_fold, feature_cols, target_col_name)\n",
    "        if preprocessor is not None:\n",
    "            val_X = preprocessor.transform(val_X)\n",
    "        val_preds = fold_metrics_model[fold][1].predict(val_X)\n",
    "        cm.append(confusion_matrix(val_y, val_preds))\n",
    "    # sum the individual confusion matrices\n",
    "    agg_cm = np.sum(cm, axis=0)\n",
    "    return agg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agg_cm = get_agg_confusion_matrix(fold_metrics_model, preprocessor, df_train, \n",
    "                                  feature_cols=feature_cols_after_fe, \n",
    "                                  target_col_name=Config.TARGET_COL_NAME, \n",
    "                                  num_folds=Config.NUM_FOLDS)\n",
    "# Display confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=agg_cm, display_labels=le.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.89      0.83      0.86     26717\n",
      "    Enrolled       0.65      0.59      0.62     15734\n",
      "    Graduate       0.85      0.92      0.88     38491\n",
      "\n",
      "    accuracy                           0.83     80942\n",
      "   macro avg       0.80      0.78      0.79     80942\n",
      "weighted avg       0.82      0.83      0.82     80942\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_oof_preds.Target.values, df_oof_preds.oof_preds.values, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation data predictions to df_val_preds_LogisticRegression.csv\n"
     ]
    }
   ],
   "source": [
    "tt.persist(\n",
    "    model_name=Config.MODEL_TYPE, \n",
    "    fold_metrics_model=fold_metrics_model, \n",
    "    df_oof_preds=df_oof_preds, \n",
    "    persist_model=Config.PERSIST_MODEL, \n",
    "    output_path=DATA_WRITEPATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_X shape: (51012, 619)\n",
      "test_preds_proba shape: (51012, 3)\n",
      "test_preds shape: (51012,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76518</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76519</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76520</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76521</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76522</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    Target\n",
       "0  76518   Dropout\n",
       "1  76519  Graduate\n",
       "2  76520  Graduate\n",
       "3  76521  Enrolled\n",
       "4  76522  Enrolled"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_proba, test_preds = tt.get_test_preds_clf(fold_metrics_model, df_test, feature_cols_after_fe, \n",
    "                                                     preprocessor=preprocessor, num_folds=Config.NUM_FOLDS)\n",
    "# convert test_preds to string using labelencoder\n",
    "test_preds_final = le.inverse_transform(test_preds)\n",
    "df_test_preds = pd.DataFrame()\n",
    "for i in range(Config.NUM_CLASSES):\n",
    "    df_test_preds[f\"test_preds_proba_{i}\"] = test_preds_proba[:, i]\n",
    "df_test_preds[\"test_preds\"] = test_preds\n",
    "df_test_preds.to_csv(DATA_WRITEPATH + f'df_test_preds_{Config.MODEL_TYPE}.csv',index=False)\n",
    "df_submission = pd.read_csv(SUBMISSION_FILEPATH + 'sample_submission.csv')\n",
    "df_submission[Config.TARGET_COL_NAME]= test_preds_final\n",
    "df_submission.to_csv(DATA_WRITEPATH + f'submission_{Config.MODEL_TYPE}.csv',index=False)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract the part after '__' (vectorized for speed)\n",
    "def extract_after_delimiter(text):\n",
    "    return text.split(\"__\", 1)[1] if len(text.split(\"__\")) > 1 else text\n",
    "\n",
    "features = preprocessor.get_feature_names_out()\n",
    "# Apply the function to the feature names using lambda\n",
    "features = list(map(extract_after_delimiter, features))\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, features):\n",
    "    df_feature_imp = pd.DataFrame()\n",
    "    df_feature_imp[\"f_name\"] = features\n",
    "    df_feature_imp[\"f_imp\"] = model.feature_importances_\n",
    "    df_feature_imp = df_feature_imp.sort_values(by=\"f_imp\", ascending=False)\n",
    "    return df_feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.MODEL_TYPE in [enums.ModelName.CatBoost, enums.ModelName.LGBM, enums.ModelName.XGBoost, \n",
    "                         enums.ModelName.RandomForest]:\n",
    "    df_feature_imp = get_feature_importance(fold_metrics_model[0][1], features)\n",
    "    df_feature_imp.to_csv(DATA_WRITEPATH + f\"{Config.MODEL_TYPE}_feature_imp_orig_openfe.csv\", index=False)\n",
    "    data_utils.plot_feature_importance(df_feature_imp, fig_size=(18, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# fs_model = RandomForestClassifier(**model_params)\n",
    "# sfs = SequentialFeatureSelector(model, n_features_to_select=50, scoring=\"accuracy\")\n",
    "# sfs.fit(df_train[feature_cols_after_fe], df_train[Config.TARGET_COL_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # performing feature selection by removing bottom 8 features leads to an improvment in cv score for catboost\n",
    "# # from 0.82996 to 0.83129. Forward feature selection algorithm might help to improve cv score further\n",
    "# df_feature_imp = df_feature_imp.head(60)\n",
    "# feature_cols_new = df_feature_imp.f_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cont_features1 = [x for x in df_train[feature_cols_new].dtypes[df_train.dtypes == \"float\"].index.values if x not in null_features]\n",
    "# scaler1 = StandardScaler()\n",
    "# preprocessor1 = ColumnTransformer(\n",
    "#     transformers=[                \n",
    "#         (\"scaler\", scaler1, cont_features1),        \n",
    "#     ], remainder=\"passthrough\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold_metrics_model1, df_oof_preds1, preprocessor1 = tt.train_and_validate(\n",
    "#         model_name=Config.MODEL_TYPE,\n",
    "#         model_params=model_params,\n",
    "#         preprocessor=preprocessor1,\n",
    "#         df=df_train,\n",
    "#         feature_cols=feature_cols_new,\n",
    "#         target_col_name=Config.TARGET_COL_NAME,\n",
    "#         metric=Config.METRIC,\n",
    "#         single_fold=Config.TRAIN_SINGLE_FOLD,\n",
    "#         num_folds=Config.NUM_FOLDS,\n",
    "#         suppress_print=False,\n",
    "#         num_classes=Config.NUM_CLASSES\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt.persist(\n",
    "#     model_name=Config.MODEL_TYPE, \n",
    "#     fold_metrics_model=fold_metrics_model1, \n",
    "#     df_oof_preds=df_oof_preds1, \n",
    "#     persist_model=Config.PERSIST_MODEL, \n",
    "#     output_path=DATA_WRITEPATH\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_preds_proba1, test_preds1 = tt.get_test_preds_clf(fold_metrics_model1, df_test, feature_cols_new, \n",
    "#                                                      preprocessor=preprocessor1, num_folds=Config.NUM_FOLDS)\n",
    "# # convert test_preds to string using labelencoder\n",
    "# test_preds_final1 = le.inverse_transform(test_preds1)\n",
    "# df_test_preds1 = pd.DataFrame()\n",
    "# for i in range(Config.NUM_CLASSES):\n",
    "#     df_test_preds1[f\"test_preds_proba_{i}\"] = test_preds_proba1[:, i]\n",
    "# df_test_preds1[\"test_preds\"] = test_preds1\n",
    "# df_test_preds1.to_csv(DATA_WRITEPATH + f'df_test_preds_{Config.MODEL_TYPE}.csv',index=False)\n",
    "# df_submission1 = pd.read_csv(SUBMISSION_FILEPATH + 'sample_submission.csv')\n",
    "# df_submission1[Config.TARGET_COL_NAME] = test_preds_final1\n",
    "# df_submission1.to_csv(DATA_WRITEPATH + f'submission_{Config.MODEL_TYPE}.csv',index=False)\n",
    "# df_submission1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
