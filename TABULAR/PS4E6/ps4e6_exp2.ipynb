{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import statistics\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.utils import class_weight\n",
    "from functools import partial\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"/home/bk_anupam/code/ML/ML_UTILS/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_tabular_utils as tt\n",
    "import cv_split_utils\n",
    "import enums\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RUN_MODE = \"LOCAL\"\n",
    "    RANDOM_SEED = 42\n",
    "    NUM_FOLDS = 5\n",
    "    TARGET_COL_NAME = \"Target\"        \n",
    "    SCALER = enums.Scaler.StandardScaler\n",
    "    METRIC = enums.Metrics.ACCURACY\n",
    "    # These values are more dynamic   \n",
    "    MODEL_TYPE = enums.ModelName.LogisticRegression\n",
    "    NUM_TUNING_TRIALS = 25\n",
    "    TUNE_ON_SINGLE_FOLD = True\n",
    "    TRAIN_SINGLE_FOLD = False    \n",
    "    PERSIST_MODEL = False\n",
    "    USE_OPENFE_FEATURES = True\n",
    "    CREATE_MANUAL_FEATURES = False\n",
    "    USE_ORIGINAL_DATA = True\n",
    "    NUM_CLASSES = 3\n",
    "\n",
    "COLS_TO_LEAVE = [\"id\", \"Target\", \"kfold\"]\n",
    "CPU_COUNT = os.cpu_count()\n",
    "\n",
    "DATA_READPATH = \"./data/\"\n",
    "DATA_WRITEPATH = \"./output/\"\n",
    "SUBMISSION_FILEPATH = DATA_READPATH\n",
    "if Config.RUN_MODE == \"KAGGLE\":    \n",
    "    DATA_READPATH = \"/kaggle/input/playground-series-s4e6/\"\n",
    "    if Config.USE_OPENFE_FEATURES:\n",
    "        DATA_READPATH = \"/kaggle/input/ps4e6-openfe/\"\n",
    "    SUBMISSION_FILEPATH = \"/kaggle/input/playground-series-s4e6/\"\n",
    "    DATA_WRITEPATH = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch original dataset \n",
    "predict_students_dropout_and_academic_success = fetch_ucirepo(id=697) \n",
    "df_train_orig = predict_students_dropout_and_academic_success.data.features \n",
    "df_train_orig[Config.TARGET_COL_NAME] = predict_students_dropout_and_academic_success.data.targets[Config.TARGET_COL_NAME]\n",
    "# rename column 'Marital Status' to 'Marital status'\n",
    "df_train_orig = df_train_orig.rename(columns={'Marital Status': 'Marital status'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no missing values in original data\n",
    "na_orig = df_train_orig.isna().sum()\n",
    "na_orig.loc[na_orig > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using generated openfe features on both train and original data\n"
     ]
    }
   ],
   "source": [
    "if Config.USE_OPENFE_FEATURES and not Config.USE_ORIGINAL_DATA:\n",
    "    print(\"using generated openfe features only on train data\")\n",
    "    df_train = pd.read_csv(DATA_READPATH + \"train_openfe.csv\")    \n",
    "    df_test = pd.read_csv(DATA_READPATH + \"test_openfe.csv\")\n",
    "elif Config.USE_OPENFE_FEATURES and Config.USE_ORIGINAL_DATA:\n",
    "    print(\"using generated openfe features on both train and original data\")\n",
    "    df_train = pd.read_csv(DATA_READPATH + \"train_orig_openfe.csv\")    \n",
    "    df_test = pd.read_csv(DATA_READPATH + \"test_orig_openfe.csv\")\n",
    "else:    \n",
    "    df_train = pd.read_csv(DATA_READPATH + \"train.csv\")\n",
    "    df_train = df_train.drop(\"id\", axis=1)    \n",
    "    df_test = pd.read_csv(DATA_READPATH + \"test.csv\")\n",
    "    df_test = df_test.drop(\"id\", axis=1)\n",
    "    if Config.USE_ORIGINAL_DATA:\n",
    "        # add df_train_orig rows to df_train\n",
    "        df_train = pd.concat([df_train, df_train_orig], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dropout', 'Enrolled', 'Graduate']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoding of target values\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train[Config.TARGET_COL_NAME])\n",
    "df_train[Config.TARGET_COL_NAME] = le.transform(df_train[Config.TARGET_COL_NAME])\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00986887 1.71480022 0.7009604 ]\n"
     ]
    }
   ],
   "source": [
    "# Dropout = 0.33, Enrolled = 0.2, Graduate = 0.47\n",
    "# Increase the weight of the minority class for model to focus more on the minority class\n",
    "# calculate class weights\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(df_train.Target), y=df_train.Target)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_static_params = {\n",
    "    enums.ModelName.XGBoost: {\n",
    "        \"objective\": \"multi:softmax\",        \n",
    "        \"seed\": Config.RANDOM_SEED,\n",
    "        \"verbosity\": 0,\n",
    "        \"num_class\": 3,\n",
    "        \"eval_metric\": \"merror\"\n",
    "    },\n",
    "    enums.ModelName.LGBM: {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"metric\": 'multi_error',\n",
    "        \"verbosity\": -1,    # <0: fatal, =0: error (warn), =1: info, >1: debug\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_class\": 3,\n",
    "    },\n",
    "    enums.ModelName.CatBoost: {\n",
    "        \"objective\": \"MultiClass\",\n",
    "        \"verbose\": 0,\n",
    "        \"random_seed\": Config.RANDOM_SEED,\n",
    "        \"eval_metric\": \"Accuracy\",\n",
    "        'grow_policy':  'Lossguide',\n",
    "        #'bootstrap_type': 'Poisson',\n",
    "        #'class_weights': class_weights,\n",
    "        'task_type': 'CPU'\n",
    "    },\n",
    "    enums.ModelName.RandomForest: {\n",
    "        \"random_state\": Config.RANDOM_SEED,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For RandomForest\n",
    "#tuned_model_params = {'n_estimators': 1300, 'max_depth': 17, 'min_samples_leaf': 3, 'min_samples_split': 3, 'max_features': 'sqrt'}\n",
    "# For CatBoost\n",
    "# tuned_model_params = {'learning_rate': 0.45126024670762294, 'n_estimators': 3700, 'max_depth': 7, 'min_data_in_leaf': 73, 'colsample_bylevel': 0.8908705634626486, 'num_leaves': 120, 'reg_lambda': 98.46961225632553, 'random_strength': 0.016359736302592447, 'early_stopping_rounds': 210, 'max_bin': 253}\n",
    "# For XGBoost\n",
    "#tuned_model_params = {'n_estimators': 1400, 'learning_rate': 0.10270166896064774, 'max_depth': 30, 'min_child_weight': 7, 'gamma': 4.123490349502186, 'subsample': 0.5067185283456936, 'colsample_bytree': 0.7289930512882908, 'reg_alpha': 0.5971832077526927, 'reg_lambda': 9.433125479981229, 'early_stopping_rounds': 260}\n",
    "\n",
    "tuned_model_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_col_name(cols_list):\n",
    "    processed_cols_list = []\n",
    "    for item in cols_list:\n",
    "        # Remove round brackets but keep the text inside them\n",
    "        item_no_brackets = re.sub(r'[\\(\\)]', '', item)\n",
    "        # Remove single quotes\n",
    "        item_no_quotes = item_no_brackets.replace(\"'\", \"\")\n",
    "        # Replace spaces with underscores\n",
    "        item_processed = item_no_quotes.replace(' ', '_')\n",
    "        # Append to the processed list\n",
    "        processed_cols_list.append(item_processed)\n",
    "    return processed_cols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols_list = df_train.columns.to_list()\n",
    "test_cols_list = df_test.columns.to_list()\n",
    "train_processed_cols_list = process_col_name(train_cols_list)\n",
    "test_processed_cols_list = process_col_name(test_cols_list)\n",
    "df_train.columns = train_processed_cols_list\n",
    "df_test.columns = test_processed_cols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "def create_features(df):\n",
    "    # (Tuition_fees_up_to_date*Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_1\"] = df[\"Tuition_fees_up_to_date\"] * df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # (Curricular_units_1st_sem_approved+Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_2\"] = df[\"Curricular_units_1st_sem_approved\"] + df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # (Curricular_units_2nd_sem_grade*Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_3\"] = df[\"Curricular_units_2nd_sem_grade\"] * df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # (Curricular_units_2nd_sem_grade+Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_4\"] = df[\"Curricular_units_2nd_sem_grade\"] + df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # (Curricular_units_2nd_sem_grade+Scholarship_holder)\n",
    "    df[\"f_5\"] = df[\"Curricular_units_2nd_sem_grade\"] + df[\"Scholarship_holder\"]\n",
    "    # (Curricular_units_1st_sem_grade+Scholarship_holder)\n",
    "    df[\"f_6\"] = df[\"Curricular_units_1st_sem_grade\"] + df[\"Scholarship_holder\"]\n",
    "    # (Curricular_units_2nd_sem_enrolled-Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_7\"] = df[\"Curricular_units_2nd_sem_enrolled\"] - df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # (Curricular_units_1st_sem_enrolled-Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_8\"] = df[\"Curricular_units_1st_sem_enrolled\"] - df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # (Curricular_units_2nd_sem_grade-Curricular_units_1st_sem_evaluations)\n",
    "    df[\"f_9\"] = df[\"Curricular_units_2nd_sem_grade\"] - df[\"Curricular_units_1st_sem_evaluations\"]\n",
    "    # (Curricular_units_1st_sem_grade/Age_at_enrollment)\n",
    "    df[\"f_10\"] = df[\"Curricular_units_1st_sem_grade\"] / df[\"Age_at_enrollment\"]\n",
    "    # (Curricular_units_1st_sem_evaluations-Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_11\"] = df[\"Curricular_units_1st_sem_evaluations\"] - df[\"Curricular_units_2nd_sem_approved\"]\n",
    "    # GroupByThenRank(Curricular_units_2nd_sem_approved,Curricular_units_1st_sem_enrolled)    \n",
    "    df[\"f_12\"] = df.groupby('Curricular_units_1st_sem_enrolled')['Curricular_units_2nd_sem_approved'].rank(method=\"dense\", ascending=False)\n",
    "    # GroupByThenRank(Curricular_units_2nd_sem_approved,Mothers_occupation)\n",
    "    df[\"f_13\"] = df.groupby('Mothers_occupation')['Curricular_units_2nd_sem_approved'].rank(method=\"dense\", ascending=False)\n",
    "    # GroupByThenRank(Scholarship_holder,Age_at_enrollment)\n",
    "    df[\"f_14\"] = df.groupby('Age_at_enrollment')['Scholarship_holder'].rank(method=\"dense\", ascending=False)\n",
    "    # GroupByThenRank(Scholarship_holder,Curricular_units_2nd_sem_approved)\n",
    "    df[\"f_15\"] = df.groupby('Curricular_units_2nd_sem_approved')['Scholarship_holder'].rank(method=\"dense\", ascending=False)\n",
    "    # CombineThenFreq(Course,Curricular_units_1st_sem_approved)\n",
    "    df[\"f_16\"] = df.groupby('Course')['Curricular_units_1st_sem_approved'].transform('count')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.CREATE_MANUAL_FEATURES:\n",
    "    df_train = create_features(df_train)\n",
    "    df_test = create_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autoFE_f_1',\n",
       " 'autoFE_f_2',\n",
       " 'autoFE_f_3',\n",
       " 'autoFE_f_5',\n",
       " 'autoFE_f_6',\n",
       " 'autoFE_f_7',\n",
       " 'autoFE_f_10',\n",
       " 'autoFE_f_13',\n",
       " 'autoFE_f_15',\n",
       " 'autoFE_f_16',\n",
       " 'autoFE_f_17',\n",
       " 'autoFE_f_18',\n",
       " 'autoFE_f_19',\n",
       " 'autoFE_f_23',\n",
       " 'autoFE_f_31',\n",
       " 'autoFE_f_37',\n",
       " 'autoFE_f_42',\n",
       " 'autoFE_f_47']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_val = df_train.isna().sum()\n",
    "null_features = na_val.loc[na_val > 0].index.values.tolist()\n",
    "null_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['Marital_status', 'Application_mode', 'Course', 'Daytime/evening_attendance', 'Previous_qualification',\n",
    "    'Nacionality', 'Mothers_qualification', 'Fathers_qualification', 'Mothers_occupation', 'Fathers_occupation', 'Displaced',\n",
    "    'Educational_special_needs', 'Debtor', 'Tuition_fees_up_to_date','Gender', 'Scholarship_holder', 'International']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features = [x for x in df_train.dtypes[df_train.dtypes == \"float\"].index.values if x not in null_features]\n",
    "int_features = [x for x in df_train.dtypes[df_train.dtypes == \"int\"].index.values if x not in COLS_TO_LEAVE+null_features]\n",
    "feature_cols = df_test.columns.to_list()\n",
    "feature_cols_after_fe = [x for x in df_train.columns if x not in COLS_TO_LEAVE+null_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for categorical features find the categories to be used for one hot encoding\n",
    "int_feature_categories = []\n",
    "for int_feature in int_features:\n",
    "    int_feature_categories.append(sorted(df_train[int_feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(feature_cols_after_fe)=68\n",
      "['Marital_status', 'Application_mode', 'Application_order', 'Course', 'Daytime/evening_attendance', 'Previous_qualification', 'Previous_qualification_grade', 'Nacionality', 'Mothers_qualification', 'Fathers_qualification', 'Mothers_occupation', 'Fathers_occupation', 'Admission_grade', 'Displaced', 'Educational_special_needs', 'Debtor', 'Tuition_fees_up_to_date', 'Gender', 'Scholarship_holder', 'Age_at_enrollment', 'International', 'Curricular_units_1st_sem_credited', 'Curricular_units_1st_sem_enrolled', 'Curricular_units_1st_sem_evaluations', 'Curricular_units_1st_sem_approved', 'Curricular_units_1st_sem_grade', 'Curricular_units_1st_sem_without_evaluations', 'Curricular_units_2nd_sem_credited', 'Curricular_units_2nd_sem_enrolled', 'Curricular_units_2nd_sem_evaluations', 'Curricular_units_2nd_sem_approved', 'Curricular_units_2nd_sem_grade', 'Curricular_units_2nd_sem_without_evaluations', 'Unemployment_rate', 'Inflation_rate', 'GDP', 'autoFE_f_0', 'autoFE_f_4', 'autoFE_f_8', 'autoFE_f_9', 'autoFE_f_11', 'autoFE_f_12', 'autoFE_f_14', 'autoFE_f_20', 'autoFE_f_21', 'autoFE_f_22', 'autoFE_f_24', 'autoFE_f_25', 'autoFE_f_26', 'autoFE_f_27', 'autoFE_f_28', 'autoFE_f_29', 'autoFE_f_30', 'autoFE_f_32', 'autoFE_f_33', 'autoFE_f_34', 'autoFE_f_35', 'autoFE_f_36', 'autoFE_f_38', 'autoFE_f_39', 'autoFE_f_40', 'autoFE_f_41', 'autoFE_f_43', 'autoFE_f_44', 'autoFE_f_45', 'autoFE_f_46', 'autoFE_f_48', 'autoFE_f_49']\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(feature_cols_after_fe)={len(feature_cols_after_fe)}\")\n",
    "print(feature_cols_after_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "preprocessor = None\n",
    "scaler = StandardScaler()\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\", categories=int_feature_categories)\n",
    "if Config.MODEL_TYPE == enums.ModelName.LogisticRegression:\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[                \n",
    "            (\"scaler\", scaler, feature_cols_after_fe),\n",
    "            (\"onehot\", onehot_encoder, int_features),                \n",
    "        ], remainder=\"passthrough\"\n",
    "    )\n",
    "else:\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[                \n",
    "            (\"scaler\", scaler, cont_features)     \n",
    "        ], remainder=\"passthrough\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgbm_tuning_params(trial):    \n",
    "    params_dynamic = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-2, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 5000, step=100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 20),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 256, step=4),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 200),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 500, step=20)\n",
    "    }\n",
    "    return {**model_static_params[enums.ModelName.LGBM], **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgb_tuning_params(trial):\n",
    "    params_dynamic = {            \n",
    "            'n_estimators': trial.suggest_int('n_estimators', 1000, 5000, step=100),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-2, 1.0, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 32),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1, 200),\n",
    "            'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 100, 500, step=20)\n",
    "        }\n",
    "    return {**model_static_params[enums.ModelName.XGBoost], **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catboost_tuning_params(trial):\n",
    "    params_dynamic = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 5000, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 16),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),\n",
    "        #'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        # comment colsample_bylevel for GPU training\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 256, step=4),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "        'random_strength': trial.suggest_loguniform('random_strength', 0.01, 10),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 500, step=20),\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255)\n",
    "    }\n",
    "    return {**model_static_params[enums.ModelName.CatBoost], **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_tuning_params(trial, model_name):\n",
    "    if model_name == enums.ModelName.LogisticRegression:\n",
    "        penalty = ['l1', 'l2']\n",
    "        return {        \n",
    "            \"C\": trial.suggest_loguniform(\"C\", 1e-3, 100),\n",
    "            \"penalty\": trial.suggest_categorical(\"penalty\", penalty)\n",
    "        }    \n",
    "    if model_name == enums.ModelName.RandomForest:\n",
    "        return {        \n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 3000, step=100),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 10, 30),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 2, 16),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 16),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"log2\", \"sqrt\", None])\n",
    "        }\n",
    "    if model_name == enums.ModelName.CatBoost:\n",
    "        return get_catboost_tuning_params(trial)\n",
    "    if model_name == enums.ModelName.XGBoost:\n",
    "        return get_xgb_tuning_params(trial) \n",
    "    if model_name == enums.ModelName.LGBM:\n",
    "        return get_lgbm_tuning_params(trial)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparams_tuning_objective(trial, model_name, preprocessor, df,  \n",
    "                                 feature_cols, metric, target_col_name, single_fold=False, num_folds=5):               \n",
    "    model_params = get_model_tuning_params(trial, model_name)    \n",
    "    fold_metrics_model, _, _ = tt.train_and_validate(\n",
    "                                        model_name=model_name,\n",
    "                                        model_params=model_params,\n",
    "                                        preprocessor=preprocessor,\n",
    "                                        df=df,\n",
    "                                        feature_cols=feature_cols,\n",
    "                                        target_col_name=target_col_name,\n",
    "                                        metric=metric,\n",
    "                                        single_fold=single_fold,\n",
    "                                        num_folds=num_folds,\n",
    "                                        suppress_print=True,\n",
    "                                        num_classes=Config.NUM_CLASSES\n",
    "                                    )\n",
    "    fold_metrics = [x[0] for x in fold_metrics_model]\n",
    "    mean_metric = statistics.mean(fold_metrics)                \n",
    "    return mean_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model_params(study_name, study_direction, num_trials, model_name, \n",
    "                      preprocessor, df,  feature_cols, metric, target_col_name, \n",
    "                      single_fold=False, num_folds=5):\n",
    "    model_params_tuning_obj_partial = partial(\n",
    "        hyperparams_tuning_objective,\n",
    "        model_name=model_name,        \n",
    "        preprocessor=preprocessor,        \n",
    "        df=df,\n",
    "        feature_cols=feature_cols,\n",
    "        metric=metric,\n",
    "        target_col_name=target_col_name,\n",
    "        single_fold=single_fold,\n",
    "        num_folds=num_folds\n",
    "    )\n",
    "    study = optuna.create_study(direction=study_direction, study_name=study_name)\n",
    "    study.optimize(model_params_tuning_obj_partial, n_trials=num_trials)\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"Best trial: number = {best_trial.number}, value = {best_trial.value}, params = {best_trial.params}\")\n",
    "    return best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = cv_split_utils.strat_kfold_dataframe(df_train, \n",
    "                                                target_col_name=Config.TARGET_COL_NAME, \n",
    "                                                random_state=Config.RANDOM_SEED, \n",
    "                                                num_folds=Config.NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 12:13:25,277] A new study created in memory with name: LogisticRegression_ModelTuning\n",
      "[I 2024-06-15 12:13:43,311] Trial 0 finished with value: 0.8309345852121811 and parameters: {'C': 38.49119721953264, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:14:00,842] Trial 1 finished with value: 0.8309345852121811 and parameters: {'C': 0.2301410457243783, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:14:14,818] Trial 2 finished with value: 0.8309345852121811 and parameters: {'C': 23.37062917268853, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:14:29,520] Trial 3 finished with value: 0.8309345852121811 and parameters: {'C': 0.03386765488470402, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:14:41,116] Trial 4 finished with value: 0.8309345852121811 and parameters: {'C': 17.65068974894247, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:14:53,453] Trial 5 finished with value: 0.8309345852121811 and parameters: {'C': 0.5481802186126948, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:15:12,561] Trial 6 finished with value: 0.8309345852121811 and parameters: {'C': 0.013531056180790323, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:15:27,637] Trial 7 finished with value: 0.8309345852121811 and parameters: {'C': 69.55535346404109, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:15:42,383] Trial 8 finished with value: 0.8309345852121811 and parameters: {'C': 0.020166989008641445, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:15:55,173] Trial 9 finished with value: 0.8309345852121811 and parameters: {'C': 0.19312816953674125, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:16:07,976] Trial 10 finished with value: 0.8309345852121811 and parameters: {'C': 2.1730618165497964, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:16:20,239] Trial 11 finished with value: 0.8309345852121811 and parameters: {'C': 0.0012255369231713538, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:16:34,705] Trial 12 finished with value: 0.8309345852121811 and parameters: {'C': 2.8247357003256788, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:16:49,399] Trial 13 finished with value: 0.8309345852121811 and parameters: {'C': 0.19860184916960105, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:17:02,418] Trial 14 finished with value: 0.8309345852121811 and parameters: {'C': 2.0324530079294894, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:17:14,960] Trial 15 finished with value: 0.8309345852121811 and parameters: {'C': 7.845822896503926, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:17:33,390] Trial 16 finished with value: 0.8309345852121811 and parameters: {'C': 81.02437587899907, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:17:49,461] Trial 17 finished with value: 0.8309345852121811 and parameters: {'C': 0.06670544218328973, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:18:06,137] Trial 18 finished with value: 0.8309345852121811 and parameters: {'C': 0.5103172541640276, 'penalty': 'l1'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:18:18,375] Trial 19 finished with value: 0.8309345852121811 and parameters: {'C': 0.003750797889034548, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:18:35,391] Trial 20 finished with value: 0.8309345852121811 and parameters: {'C': 0.0941243719067049, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:18:48,011] Trial 21 finished with value: 0.8309345852121811 and parameters: {'C': 14.679801762463981, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:18:59,975] Trial 22 finished with value: 0.8309345852121811 and parameters: {'C': 37.233836260192604, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:19:13,181] Trial 23 finished with value: 0.8309345852121811 and parameters: {'C': 5.929548772835682, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n",
      "[I 2024-06-15 12:19:25,665] Trial 24 finished with value: 0.8309345852121811 and parameters: {'C': 1.0402765350003143, 'penalty': 'l2'}. Best is trial 0 with value: 0.8309345852121811.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: number = 0, value = 0.8309345852121811, params = {'C': 38.49119721953264, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "if tuned_model_params is None:\n",
    "    #df = df_train.sample(frac=0.1, random_state=Config.RANDOM_SEED)\n",
    "    tuned_model_params = tune_model_params(\n",
    "                            study_name=Config.MODEL_TYPE + \"_ModelTuning\", \n",
    "                            study_direction=\"maximize\",\n",
    "                            num_trials=Config.NUM_TUNING_TRIALS,\n",
    "                            model_name=Config.MODEL_TYPE,\n",
    "                            preprocessor=preprocessor,\n",
    "                            df=df_train,\n",
    "                            feature_cols=feature_cols_after_fe,\n",
    "                            metric=Config.METRIC,\n",
    "                            target_col_name=Config.TARGET_COL_NAME,\n",
    "                            single_fold=Config.TUNE_ON_SINGLE_FOLD,\n",
    "                            num_folds=Config.NUM_FOLDS\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = None\n",
    "params_static = model_static_params.get(Config.MODEL_TYPE)\n",
    "if params_static is not None and tuned_model_params is not None:\n",
    "    model_params = {**model_static_params[Config.MODEL_TYPE], **tuned_model_params}\n",
    "else:\n",
    "    model_params = tuned_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - LogisticRegression - ACCURACY : 0.8309345852121811\n",
      "Fold 1 - LogisticRegression - ACCURACY : 0.8261782691951325\n",
      "Fold 2 - LogisticRegression - ACCURACY : 0.8254880158141833\n",
      "Fold 3 - LogisticRegression - ACCURACY : 0.825240919199407\n",
      "Fold 4 - LogisticRegression - ACCURACY : 0.8284531751914999\n",
      "LogisticRegression metric=ACCURACY CV score = 0.8272590249808505\n",
      "LogisticRegression Mean ACCURACY = 0.8272589929224807, std = 0.0021593052223561264\n",
      "CPU times: user 8min, sys: 4min 52s, total: 12min 53s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fold_metrics_model, df_oof_preds, preprocessor = tt.train_and_validate(\n",
    "        model_name=Config.MODEL_TYPE,\n",
    "        model_params=model_params,\n",
    "        preprocessor=preprocessor,\n",
    "        df=df_train,\n",
    "        feature_cols=feature_cols_after_fe,\n",
    "        target_col_name=Config.TARGET_COL_NAME,\n",
    "        metric=Config.METRIC,\n",
    "        single_fold=Config.TRAIN_SINGLE_FOLD,\n",
    "        num_folds=Config.NUM_FOLDS,\n",
    "        suppress_print=False,\n",
    "        num_classes=Config.NUM_CLASSES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def get_model_stats(model_name):\n",
    "    target_classes = np.array([\"Dropout\", \"Enrolled\", \"Graduate\"])    \n",
    "    oof_cols = [f\"oof_preds_proba_{i}\" for i in range(Config.NUM_CLASSES)]\n",
    "    model_preds_proba = df_oof_preds[oof_cols].to_numpy()\n",
    "    model_preds = np.argmax(model_preds_proba, axis=1)\n",
    "    model_accuracy = accuracy_score(df_oof_preds[Config.TARGET_COL_NAME], model_preds)\n",
    "    model_f1 = f1_score(df_oof_preds[Config.TARGET_COL_NAME], model_preds, average='macro')\n",
    "    print(f\"{model_name} OOF Accuracy: {model_accuracy}\")\n",
    "    print(f\"{model_name} OOF F1 Score: {model_f1}\")\n",
    "    model_cm = confusion_matrix(df_oof_preds[Config.TARGET_COL_NAME], model_preds)\n",
    "    print(classification_report(df_oof_preds[Config.TARGET_COL_NAME].values, model_preds, target_names=target_classes))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=model_cm, display_labels=target_classes)\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression OOF Accuracy: 0.8272590249808505\n",
      "LogisticRegression OOF F1 Score: 0.7879466063211309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.89      0.83      0.86     26717\n",
      "    Enrolled       0.65      0.59      0.62     15734\n",
      "    Graduate       0.85      0.92      0.88     38491\n",
      "\n",
      "    accuracy                           0.83     80942\n",
      "   macro avg       0.80      0.78      0.79     80942\n",
      "weighted avg       0.82      0.83      0.82     80942\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_model_stats(Config.MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation data predictions to df_val_preds_LogisticRegression.csv\n"
     ]
    }
   ],
   "source": [
    "tt.persist(\n",
    "    model_name=Config.MODEL_TYPE, \n",
    "    fold_metrics_model=fold_metrics_model, \n",
    "    df_oof_preds=df_oof_preds, \n",
    "    persist_model=Config.PERSIST_MODEL, \n",
    "    output_path=DATA_WRITEPATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_X shape: (51012, 619)\n",
      "test_preds_proba shape: (51012, 3)\n",
      "test_preds shape: (51012,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76518</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76519</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76520</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76521</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76522</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    Target\n",
       "0  76518   Dropout\n",
       "1  76519  Graduate\n",
       "2  76520  Graduate\n",
       "3  76521  Enrolled\n",
       "4  76522  Enrolled"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_proba, test_preds = tt.get_test_preds_clf(fold_metrics_model, df_test, feature_cols_after_fe, \n",
    "                                                     preprocessor=preprocessor, num_folds=Config.NUM_FOLDS)\n",
    "# convert test_preds to string using labelencoder\n",
    "test_preds_final = le.inverse_transform(test_preds)\n",
    "df_test_preds = pd.DataFrame()\n",
    "for i in range(Config.NUM_CLASSES):\n",
    "    df_test_preds[f\"test_preds_proba_{i}\"] = test_preds_proba[:, i]\n",
    "df_test_preds[\"test_preds\"] = test_preds\n",
    "df_test_preds.to_csv(DATA_WRITEPATH + f'df_test_preds_{Config.MODEL_TYPE}.csv',index=False)\n",
    "df_submission = pd.read_csv(SUBMISSION_FILEPATH + 'sample_submission.csv')\n",
    "df_submission[Config.TARGET_COL_NAME]= test_preds_final\n",
    "df_submission.to_csv(DATA_WRITEPATH + f'submission_{Config.MODEL_TYPE}.csv',index=False)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to extract the part after '__' (vectorized for speed)\n",
    "def extract_after_delimiter(text):\n",
    "    return text.split(\"__\", 1)[1] if len(text.split(\"__\")) > 1 else text\n",
    "\n",
    "features = preprocessor.get_feature_names_out()\n",
    "# Apply the function to the feature names using lambda\n",
    "features = list(map(extract_after_delimiter, features))\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, features):\n",
    "    df_feature_imp = pd.DataFrame()\n",
    "    df_feature_imp[\"f_name\"] = features\n",
    "    df_feature_imp[\"f_imp\"] = model.feature_importances_\n",
    "    df_feature_imp = df_feature_imp.sort_values(by=\"f_imp\", ascending=False)\n",
    "    return df_feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Config.MODEL_TYPE in [enums.ModelName.CatBoost, enums.ModelName.LGBM, enums.ModelName.XGBoost, \n",
    "                         enums.ModelName.RandomForest]:\n",
    "    df_feature_imp = get_feature_importance(fold_metrics_model[0][1], features)\n",
    "    df_feature_imp.to_csv(DATA_WRITEPATH + f\"{Config.MODEL_TYPE}_feature_imp_orig_openfe.csv\", index=False)\n",
    "    data_utils.plot_feature_importance(df_feature_imp, fig_size=(18, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# fs_model = RandomForestClassifier(**model_params)\n",
    "# sfs = SequentialFeatureSelector(model, n_features_to_select=50, scoring=\"accuracy\")\n",
    "# sfs.fit(df_train[feature_cols_after_fe], df_train[Config.TARGET_COL_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # performing feature selection by removing bottom 8 features leads to an improvment in cv score for catboost\n",
    "# # from 0.82996 to 0.83129. Forward feature selection algorithm might help to improve cv score further\n",
    "# df_feature_imp = df_feature_imp.head(60)\n",
    "# feature_cols_new = df_feature_imp.f_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cont_features1 = [x for x in df_train[feature_cols_new].dtypes[df_train.dtypes == \"float\"].index.values if x not in null_features]\n",
    "# scaler1 = StandardScaler()\n",
    "# preprocessor1 = ColumnTransformer(\n",
    "#     transformers=[                \n",
    "#         (\"scaler\", scaler1, cont_features1),        \n",
    "#     ], remainder=\"passthrough\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold_metrics_model1, df_oof_preds1, preprocessor1 = tt.train_and_validate(\n",
    "#         model_name=Config.MODEL_TYPE,\n",
    "#         model_params=model_params,\n",
    "#         preprocessor=preprocessor1,\n",
    "#         df=df_train,\n",
    "#         feature_cols=feature_cols_new,\n",
    "#         target_col_name=Config.TARGET_COL_NAME,\n",
    "#         metric=Config.METRIC,\n",
    "#         single_fold=Config.TRAIN_SINGLE_FOLD,\n",
    "#         num_folds=Config.NUM_FOLDS,\n",
    "#         suppress_print=False,\n",
    "#         num_classes=Config.NUM_CLASSES\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tt.persist(\n",
    "#     model_name=Config.MODEL_TYPE, \n",
    "#     fold_metrics_model=fold_metrics_model1, \n",
    "#     df_oof_preds=df_oof_preds1, \n",
    "#     persist_model=Config.PERSIST_MODEL, \n",
    "#     output_path=DATA_WRITEPATH\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_preds_proba1, test_preds1 = tt.get_test_preds_clf(fold_metrics_model1, df_test, feature_cols_new, \n",
    "#                                                      preprocessor=preprocessor1, num_folds=Config.NUM_FOLDS)\n",
    "# # convert test_preds to string using labelencoder\n",
    "# test_preds_final1 = le.inverse_transform(test_preds1)\n",
    "# df_test_preds1 = pd.DataFrame()\n",
    "# for i in range(Config.NUM_CLASSES):\n",
    "#     df_test_preds1[f\"test_preds_proba_{i}\"] = test_preds_proba1[:, i]\n",
    "# df_test_preds1[\"test_preds\"] = test_preds1\n",
    "# df_test_preds1.to_csv(DATA_WRITEPATH + f'df_test_preds_{Config.MODEL_TYPE}.csv',index=False)\n",
    "# df_submission1 = pd.read_csv(SUBMISSION_FILEPATH + 'sample_submission.csv')\n",
    "# df_submission1[Config.TARGET_COL_NAME] = test_preds_final1\n",
    "# df_submission1.to_csv(DATA_WRITEPATH + f'submission_{Config.MODEL_TYPE}.csv',index=False)\n",
    "# df_submission1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
