{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, f1_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.optimize import minimize\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"/home/bk_anupam/code/ML/ML_UTILS/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_tabular_utils as tt\n",
    "import cv_split_utils\n",
    "import enums\n",
    "from enums import ModelName, Metrics\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RUN_MODE = \"LOCAL\"\n",
    "    RANDOM_SEED = 1\n",
    "    NUM_FOLDS = 5\n",
    "    MODEL_TYPE = enums.ModelName.L2_Ridge\n",
    "    TARGET_COL_NAME = \"Target\"            \n",
    "    METRIC = enums.Metrics.ACCURACY\n",
    "    TRAIN_SINGLE_FOLD = False\n",
    "    NUM_CLASSES = 3        \n",
    "\n",
    "COLS_TO_LEAVE = [\"id\", \"Target\", \"kfold\"]\n",
    "CPU_COUNT = os.cpu_count()\n",
    "\n",
    "DATA_READPATH = \"./data/\"\n",
    "BASE_MODELS_PATH = \"./output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CatBoost1', 'CatBoost2', 'XGBoost1', 'LightGBM1', 'LightGBM2', 'LightGBM3', 'RandomForest1', 'LogisticRegression1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CatBoost1_preds_proba_0',\n",
       " 'CatBoost1_preds_proba_1',\n",
       " 'CatBoost1_preds_proba_2',\n",
       " 'CatBoost2_preds_proba_0',\n",
       " 'CatBoost2_preds_proba_1',\n",
       " 'CatBoost2_preds_proba_2',\n",
       " 'XGBoost1_preds_proba_0',\n",
       " 'XGBoost1_preds_proba_1',\n",
       " 'XGBoost1_preds_proba_2',\n",
       " 'LightGBM1_preds_proba_0',\n",
       " 'LightGBM1_preds_proba_1',\n",
       " 'LightGBM1_preds_proba_2',\n",
       " 'LightGBM2_preds_proba_0',\n",
       " 'LightGBM2_preds_proba_1',\n",
       " 'LightGBM2_preds_proba_2',\n",
       " 'LightGBM3_preds_proba_0',\n",
       " 'LightGBM3_preds_proba_1',\n",
       " 'LightGBM3_preds_proba_2',\n",
       " 'RandomForest1_preds_proba_0',\n",
       " 'RandomForest1_preds_proba_1',\n",
       " 'RandomForest1_preds_proba_2',\n",
       " 'LogisticRegression1_preds_proba_0',\n",
       " 'LogisticRegression1_preds_proba_1',\n",
       " 'LogisticRegression1_preds_proba_2']"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key is model type and value is number of trained models for that type to be used in ensemble\n",
    "models = {\n",
    "    ModelName.CatBoost: 2,\n",
    "    ModelName.XGBoost: 1,\n",
    "    ModelName.LGBM: 3,\n",
    "    ModelName.RandomForest: 1,\n",
    "    ModelName.LogisticRegression: 1\n",
    "}\n",
    "\n",
    "# base model prediction column names (both for oof predictions and test predictions) are the same as model names\n",
    "base_model_names = [f\"{key}{i+1}\" for key, value in models.items() for i in range(value) ]\n",
    "pred_cols = [f\"{model_name}_preds_proba_{i}\" for model_name in base_model_names for i in range(Config.NUM_CLASSES)]\n",
    "print(base_model_names)\n",
    "pred_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary for class labels\n",
    "target_class_mapping = {0: \"Dropout\", 1: \"Enrolled\", 2: \"Graduate\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv(DATA_READPATH + \"sample_submission.csv\")\n",
    "df_oof_preds = pd.DataFrame()\n",
    "df_test_preds = pd.DataFrame()\n",
    "# load the OOF csv for each model\n",
    "for model_name in base_model_names:\n",
    "    df_model_oof = pd.read_csv(f\"{BASE_MODELS_PATH}df_val_preds_{model_name}.csv\")\n",
    "    df_model_test_preds = pd.read_csv(f\"{BASE_MODELS_PATH}df_test_preds_{model_name}.csv\")\n",
    "    for i in range(Config.NUM_CLASSES):\n",
    "        df_oof_preds[f\"{model_name}_preds_proba_{i}\"] = df_model_oof[f\"oof_preds_proba_{i}\"]\n",
    "        df_test_preds[f\"{model_name}_preds_proba_{i}\"] = df_model_test_preds[f\"test_preds_proba_{i}\"]\n",
    "    df_oof_preds[f\"{model_name}_preds\"] = df_model_oof[\"oof_preds\"]\n",
    "    df_test_preds[f\"{model_name}_preds\"] = df_model_test_preds[\"test_preds\"]\n",
    "df_oof_preds[Config.TARGET_COL_NAME] = df_model_oof[Config.TARGET_COL_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CatBoost1_preds_proba_0</th>\n",
       "      <th>CatBoost1_preds_proba_1</th>\n",
       "      <th>CatBoost1_preds_proba_2</th>\n",
       "      <th>CatBoost1_preds</th>\n",
       "      <th>CatBoost2_preds_proba_0</th>\n",
       "      <th>CatBoost2_preds_proba_1</th>\n",
       "      <th>CatBoost2_preds_proba_2</th>\n",
       "      <th>CatBoost2_preds</th>\n",
       "      <th>XGBoost1_preds_proba_0</th>\n",
       "      <th>XGBoost1_preds_proba_1</th>\n",
       "      <th>...</th>\n",
       "      <th>LightGBM3_preds</th>\n",
       "      <th>RandomForest1_preds_proba_0</th>\n",
       "      <th>RandomForest1_preds_proba_1</th>\n",
       "      <th>RandomForest1_preds_proba_2</th>\n",
       "      <th>RandomForest1_preds</th>\n",
       "      <th>LogisticRegression1_preds_proba_0</th>\n",
       "      <th>LogisticRegression1_preds_proba_1</th>\n",
       "      <th>LogisticRegression1_preds_proba_2</th>\n",
       "      <th>LogisticRegression1_preds</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007950</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>0.985428</td>\n",
       "      <td>2</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.965664</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>0.009251</td>\n",
       "      <td>0.977768</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009403</td>\n",
       "      <td>0.008871</td>\n",
       "      <td>0.981726</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026453</td>\n",
       "      <td>0.020980</td>\n",
       "      <td>0.952566</td>\n",
       "      <td>2</td>\n",
       "      <td>0.033137</td>\n",
       "      <td>0.018453</td>\n",
       "      <td>0.948410</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028486</td>\n",
       "      <td>0.033435</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015810</td>\n",
       "      <td>0.018992</td>\n",
       "      <td>0.965198</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028541</td>\n",
       "      <td>0.058379</td>\n",
       "      <td>0.913080</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061289</td>\n",
       "      <td>0.621982</td>\n",
       "      <td>0.316728</td>\n",
       "      <td>1</td>\n",
       "      <td>0.056843</td>\n",
       "      <td>0.788141</td>\n",
       "      <td>0.155016</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069910</td>\n",
       "      <td>0.755106</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.108698</td>\n",
       "      <td>0.641300</td>\n",
       "      <td>0.250002</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077363</td>\n",
       "      <td>0.567161</td>\n",
       "      <td>0.355477</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.221125</td>\n",
       "      <td>0.618871</td>\n",
       "      <td>0.160004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127717</td>\n",
       "      <td>0.775832</td>\n",
       "      <td>0.096452</td>\n",
       "      <td>1</td>\n",
       "      <td>0.290566</td>\n",
       "      <td>0.487754</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201231</td>\n",
       "      <td>0.586526</td>\n",
       "      <td>0.212242</td>\n",
       "      <td>1</td>\n",
       "      <td>0.294388</td>\n",
       "      <td>0.574046</td>\n",
       "      <td>0.131566</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036233</td>\n",
       "      <td>0.597098</td>\n",
       "      <td>0.366669</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067244</td>\n",
       "      <td>0.587030</td>\n",
       "      <td>0.345726</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079016</td>\n",
       "      <td>0.634216</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084981</td>\n",
       "      <td>0.657020</td>\n",
       "      <td>0.257999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085206</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.364769</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CatBoost1_preds_proba_0  CatBoost1_preds_proba_1  CatBoost1_preds_proba_2  \\\n",
       "0                 0.007950                 0.006622                 0.985428   \n",
       "1                 0.026453                 0.020980                 0.952566   \n",
       "2                 0.061289                 0.621982                 0.316728   \n",
       "3                 0.221125                 0.618871                 0.160004   \n",
       "4                 0.036233                 0.597098                 0.366669   \n",
       "\n",
       "   CatBoost1_preds  CatBoost2_preds_proba_0  CatBoost2_preds_proba_1  \\\n",
       "0                2                 0.022356                 0.011980   \n",
       "1                2                 0.033137                 0.018453   \n",
       "2                1                 0.056843                 0.788141   \n",
       "3                1                 0.127717                 0.775832   \n",
       "4                1                 0.067244                 0.587030   \n",
       "\n",
       "   CatBoost2_preds_proba_2  CatBoost2_preds  XGBoost1_preds_proba_0  \\\n",
       "0                 0.965664                2                0.012317   \n",
       "1                 0.948410                2                0.028486   \n",
       "2                 0.155016                1                0.069910   \n",
       "3                 0.096452                1                0.290566   \n",
       "4                 0.345726                1                0.079016   \n",
       "\n",
       "   XGBoost1_preds_proba_1  ...  LightGBM3_preds  RandomForest1_preds_proba_0  \\\n",
       "0                0.010887  ...                2                     0.012981   \n",
       "1                0.033435  ...                2                     0.015810   \n",
       "2                0.755106  ...                1                     0.108698   \n",
       "3                0.487754  ...                1                     0.201231   \n",
       "4                0.634216  ...                1                     0.084981   \n",
       "\n",
       "   RandomForest1_preds_proba_1  RandomForest1_preds_proba_2  \\\n",
       "0                     0.009251                     0.977768   \n",
       "1                     0.018992                     0.965198   \n",
       "2                     0.641300                     0.250002   \n",
       "3                     0.586526                     0.212242   \n",
       "4                     0.657020                     0.257999   \n",
       "\n",
       "   RandomForest1_preds  LogisticRegression1_preds_proba_0  \\\n",
       "0                    2                           0.009403   \n",
       "1                    2                           0.028541   \n",
       "2                    1                           0.077363   \n",
       "3                    1                           0.294388   \n",
       "4                    1                           0.085206   \n",
       "\n",
       "   LogisticRegression1_preds_proba_1  LogisticRegression1_preds_proba_2  \\\n",
       "0                           0.008871                           0.981726   \n",
       "1                           0.058379                           0.913080   \n",
       "2                           0.567161                           0.355477   \n",
       "3                           0.574046                           0.131566   \n",
       "4                           0.550025                           0.364769   \n",
       "\n",
       "   LogisticRegression1_preds  Target  \n",
       "0                          2       2  \n",
       "1                          2       2  \n",
       "2                          1       1  \n",
       "3                          1       1  \n",
       "4                          1       1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oof_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CatBoost1_preds_proba_0</th>\n",
       "      <th>CatBoost1_preds_proba_1</th>\n",
       "      <th>CatBoost1_preds_proba_2</th>\n",
       "      <th>CatBoost1_preds</th>\n",
       "      <th>CatBoost2_preds_proba_0</th>\n",
       "      <th>CatBoost2_preds_proba_1</th>\n",
       "      <th>CatBoost2_preds_proba_2</th>\n",
       "      <th>CatBoost2_preds</th>\n",
       "      <th>XGBoost1_preds_proba_0</th>\n",
       "      <th>XGBoost1_preds_proba_1</th>\n",
       "      <th>...</th>\n",
       "      <th>LightGBM3_preds_proba_2</th>\n",
       "      <th>LightGBM3_preds</th>\n",
       "      <th>RandomForest1_preds_proba_0</th>\n",
       "      <th>RandomForest1_preds_proba_1</th>\n",
       "      <th>RandomForest1_preds_proba_2</th>\n",
       "      <th>RandomForest1_preds</th>\n",
       "      <th>LogisticRegression1_preds_proba_0</th>\n",
       "      <th>LogisticRegression1_preds_proba_1</th>\n",
       "      <th>LogisticRegression1_preds_proba_2</th>\n",
       "      <th>LogisticRegression1_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.990005</td>\n",
       "      <td>0.007855</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990935</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988320</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.943398</td>\n",
       "      <td>0.055907</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998771</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.013780</td>\n",
       "      <td>0.979988</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.011460</td>\n",
       "      <td>0.983416</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.018430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985934</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>0.015484</td>\n",
       "      <td>0.973292</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.015403</td>\n",
       "      <td>0.980157</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037894</td>\n",
       "      <td>0.251453</td>\n",
       "      <td>0.710653</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>2</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.237019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705896</td>\n",
       "      <td>2</td>\n",
       "      <td>0.057225</td>\n",
       "      <td>0.248017</td>\n",
       "      <td>0.694758</td>\n",
       "      <td>2</td>\n",
       "      <td>0.024246</td>\n",
       "      <td>0.222237</td>\n",
       "      <td>0.753517</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183586</td>\n",
       "      <td>0.225122</td>\n",
       "      <td>0.591291</td>\n",
       "      <td>2</td>\n",
       "      <td>0.292535</td>\n",
       "      <td>0.237487</td>\n",
       "      <td>0.469978</td>\n",
       "      <td>2</td>\n",
       "      <td>0.172196</td>\n",
       "      <td>0.458779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511860</td>\n",
       "      <td>2</td>\n",
       "      <td>0.259611</td>\n",
       "      <td>0.341803</td>\n",
       "      <td>0.398587</td>\n",
       "      <td>2</td>\n",
       "      <td>0.191071</td>\n",
       "      <td>0.414999</td>\n",
       "      <td>0.393930</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305291</td>\n",
       "      <td>0.652540</td>\n",
       "      <td>0.042170</td>\n",
       "      <td>1</td>\n",
       "      <td>0.249726</td>\n",
       "      <td>0.712745</td>\n",
       "      <td>0.037528</td>\n",
       "      <td>1</td>\n",
       "      <td>0.345187</td>\n",
       "      <td>0.619451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026932</td>\n",
       "      <td>1</td>\n",
       "      <td>0.365442</td>\n",
       "      <td>0.573522</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>1</td>\n",
       "      <td>0.264618</td>\n",
       "      <td>0.712037</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CatBoost1_preds_proba_0  CatBoost1_preds_proba_1  CatBoost1_preds_proba_2  \\\n",
       "0                 0.990005                 0.007855                 0.002140   \n",
       "1                 0.006233                 0.013780                 0.979988   \n",
       "2                 0.037894                 0.251453                 0.710653   \n",
       "3                 0.183586                 0.225122                 0.591291   \n",
       "4                 0.305291                 0.652540                 0.042170   \n",
       "\n",
       "   CatBoost1_preds  CatBoost2_preds_proba_0  CatBoost2_preds_proba_1  \\\n",
       "0                0                 0.990935                 0.007390   \n",
       "1                2                 0.005124                 0.011460   \n",
       "2                2                 0.034800                 0.246753   \n",
       "3                2                 0.292535                 0.237487   \n",
       "4                1                 0.249726                 0.712745   \n",
       "\n",
       "   CatBoost2_preds_proba_2  CatBoost2_preds  XGBoost1_preds_proba_0  \\\n",
       "0                 0.001675                0                0.988320   \n",
       "1                 0.983416                2                0.007958   \n",
       "2                 0.718447                2                0.039474   \n",
       "3                 0.469978                2                0.172196   \n",
       "4                 0.037528                1                0.345187   \n",
       "\n",
       "   XGBoost1_preds_proba_1  ...  LightGBM3_preds_proba_2  LightGBM3_preds  \\\n",
       "0                0.008497  ...                 0.003250                0   \n",
       "1                0.018430  ...                 0.985934                2   \n",
       "2                0.237019  ...                 0.705896                2   \n",
       "3                0.458779  ...                 0.511860                2   \n",
       "4                0.619451  ...                 0.026932                1   \n",
       "\n",
       "   RandomForest1_preds_proba_0  RandomForest1_preds_proba_1  \\\n",
       "0                     0.943398                     0.055907   \n",
       "1                     0.011224                     0.015484   \n",
       "2                     0.057225                     0.248017   \n",
       "3                     0.259611                     0.341803   \n",
       "4                     0.365442                     0.573522   \n",
       "\n",
       "   RandomForest1_preds_proba_2  RandomForest1_preds  \\\n",
       "0                     0.000696                    0   \n",
       "1                     0.973292                    2   \n",
       "2                     0.694758                    2   \n",
       "3                     0.398587                    2   \n",
       "4                     0.061035                    1   \n",
       "\n",
       "   LogisticRegression1_preds_proba_0  LogisticRegression1_preds_proba_1  \\\n",
       "0                           0.998771                           0.001033   \n",
       "1                           0.004440                           0.015403   \n",
       "2                           0.024246                           0.222237   \n",
       "3                           0.191071                           0.414999   \n",
       "4                           0.264618                           0.712037   \n",
       "\n",
       "   LogisticRegression1_preds_proba_2  LogisticRegression1_preds  \n",
       "0                           0.000197                          0  \n",
       "1                           0.980157                          2  \n",
       "2                           0.753517                          2  \n",
       "3                           0.393930                          1  \n",
       "4                           0.023345                          1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_oof_preds_oh.columns)=49\n",
      "len(df_test_preds_oh.columns)=48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CatBoost1_preds_proba_0</th>\n",
       "      <th>CatBoost1_preds_proba_1</th>\n",
       "      <th>CatBoost1_preds_proba_2</th>\n",
       "      <th>CatBoost2_preds_proba_0</th>\n",
       "      <th>CatBoost2_preds_proba_1</th>\n",
       "      <th>CatBoost2_preds_proba_2</th>\n",
       "      <th>XGBoost1_preds_proba_0</th>\n",
       "      <th>XGBoost1_preds_proba_1</th>\n",
       "      <th>XGBoost1_preds_proba_2</th>\n",
       "      <th>LightGBM1_preds_proba_0</th>\n",
       "      <th>...</th>\n",
       "      <th>LightGBM2_preds_2</th>\n",
       "      <th>LightGBM3_preds_0</th>\n",
       "      <th>LightGBM3_preds_1</th>\n",
       "      <th>LightGBM3_preds_2</th>\n",
       "      <th>RandomForest1_preds_0</th>\n",
       "      <th>RandomForest1_preds_1</th>\n",
       "      <th>RandomForest1_preds_2</th>\n",
       "      <th>LogisticRegression1_preds_0</th>\n",
       "      <th>LogisticRegression1_preds_1</th>\n",
       "      <th>LogisticRegression1_preds_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007950</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>0.985428</td>\n",
       "      <td>0.022356</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.965664</td>\n",
       "      <td>0.012317</td>\n",
       "      <td>0.010887</td>\n",
       "      <td>0.976796</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026453</td>\n",
       "      <td>0.020980</td>\n",
       "      <td>0.952566</td>\n",
       "      <td>0.033137</td>\n",
       "      <td>0.018453</td>\n",
       "      <td>0.948410</td>\n",
       "      <td>0.028486</td>\n",
       "      <td>0.033435</td>\n",
       "      <td>0.938079</td>\n",
       "      <td>0.017919</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061289</td>\n",
       "      <td>0.621982</td>\n",
       "      <td>0.316728</td>\n",
       "      <td>0.056843</td>\n",
       "      <td>0.788141</td>\n",
       "      <td>0.155016</td>\n",
       "      <td>0.069910</td>\n",
       "      <td>0.755106</td>\n",
       "      <td>0.174984</td>\n",
       "      <td>0.063957</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.221125</td>\n",
       "      <td>0.618871</td>\n",
       "      <td>0.160004</td>\n",
       "      <td>0.127717</td>\n",
       "      <td>0.775832</td>\n",
       "      <td>0.096452</td>\n",
       "      <td>0.290566</td>\n",
       "      <td>0.487754</td>\n",
       "      <td>0.221679</td>\n",
       "      <td>0.255624</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036233</td>\n",
       "      <td>0.597098</td>\n",
       "      <td>0.366669</td>\n",
       "      <td>0.067244</td>\n",
       "      <td>0.587030</td>\n",
       "      <td>0.345726</td>\n",
       "      <td>0.079016</td>\n",
       "      <td>0.634216</td>\n",
       "      <td>0.286768</td>\n",
       "      <td>0.056027</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80937</th>\n",
       "      <td>0.036075</td>\n",
       "      <td>0.308273</td>\n",
       "      <td>0.655652</td>\n",
       "      <td>0.047995</td>\n",
       "      <td>0.188656</td>\n",
       "      <td>0.763349</td>\n",
       "      <td>0.032097</td>\n",
       "      <td>0.178526</td>\n",
       "      <td>0.789377</td>\n",
       "      <td>0.026845</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80938</th>\n",
       "      <td>0.922093</td>\n",
       "      <td>0.074259</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.932880</td>\n",
       "      <td>0.062857</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.932984</td>\n",
       "      <td>0.062578</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.913297</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80939</th>\n",
       "      <td>0.811618</td>\n",
       "      <td>0.086122</td>\n",
       "      <td>0.102260</td>\n",
       "      <td>0.834393</td>\n",
       "      <td>0.061904</td>\n",
       "      <td>0.103703</td>\n",
       "      <td>0.802689</td>\n",
       "      <td>0.078314</td>\n",
       "      <td>0.118998</td>\n",
       "      <td>0.763602</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80940</th>\n",
       "      <td>0.019115</td>\n",
       "      <td>0.052649</td>\n",
       "      <td>0.928236</td>\n",
       "      <td>0.012856</td>\n",
       "      <td>0.037921</td>\n",
       "      <td>0.949223</td>\n",
       "      <td>0.022524</td>\n",
       "      <td>0.075918</td>\n",
       "      <td>0.901558</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80941</th>\n",
       "      <td>0.011839</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.978362</td>\n",
       "      <td>0.014414</td>\n",
       "      <td>0.012597</td>\n",
       "      <td>0.972988</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.972740</td>\n",
       "      <td>0.012864</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80942 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CatBoost1_preds_proba_0  CatBoost1_preds_proba_1  \\\n",
       "0                     0.007950                 0.006622   \n",
       "1                     0.026453                 0.020980   \n",
       "2                     0.061289                 0.621982   \n",
       "3                     0.221125                 0.618871   \n",
       "4                     0.036233                 0.597098   \n",
       "...                        ...                      ...   \n",
       "80937                 0.036075                 0.308273   \n",
       "80938                 0.922093                 0.074259   \n",
       "80939                 0.811618                 0.086122   \n",
       "80940                 0.019115                 0.052649   \n",
       "80941                 0.011839                 0.009798   \n",
       "\n",
       "       CatBoost1_preds_proba_2  CatBoost2_preds_proba_0  \\\n",
       "0                     0.985428                 0.022356   \n",
       "1                     0.952566                 0.033137   \n",
       "2                     0.316728                 0.056843   \n",
       "3                     0.160004                 0.127717   \n",
       "4                     0.366669                 0.067244   \n",
       "...                        ...                      ...   \n",
       "80937                 0.655652                 0.047995   \n",
       "80938                 0.003648                 0.932880   \n",
       "80939                 0.102260                 0.834393   \n",
       "80940                 0.928236                 0.012856   \n",
       "80941                 0.978362                 0.014414   \n",
       "\n",
       "       CatBoost2_preds_proba_1  CatBoost2_preds_proba_2  \\\n",
       "0                     0.011980                 0.965664   \n",
       "1                     0.018453                 0.948410   \n",
       "2                     0.788141                 0.155016   \n",
       "3                     0.775832                 0.096452   \n",
       "4                     0.587030                 0.345726   \n",
       "...                        ...                      ...   \n",
       "80937                 0.188656                 0.763349   \n",
       "80938                 0.062857                 0.004263   \n",
       "80939                 0.061904                 0.103703   \n",
       "80940                 0.037921                 0.949223   \n",
       "80941                 0.012597                 0.972988   \n",
       "\n",
       "       XGBoost1_preds_proba_0  XGBoost1_preds_proba_1  XGBoost1_preds_proba_2  \\\n",
       "0                    0.012317                0.010887                0.976796   \n",
       "1                    0.028486                0.033435                0.938079   \n",
       "2                    0.069910                0.755106                0.174984   \n",
       "3                    0.290566                0.487754                0.221679   \n",
       "4                    0.079016                0.634216                0.286768   \n",
       "...                       ...                     ...                     ...   \n",
       "80937                0.032097                0.178526                0.789377   \n",
       "80938                0.932984                0.062578                0.004439   \n",
       "80939                0.802689                0.078314                0.118998   \n",
       "80940                0.022524                0.075918                0.901558   \n",
       "80941                0.014790                0.012470                0.972740   \n",
       "\n",
       "       LightGBM1_preds_proba_0  ...  LightGBM2_preds_2  LightGBM3_preds_0  \\\n",
       "0                     0.006000  ...               True              False   \n",
       "1                     0.017919  ...               True              False   \n",
       "2                     0.063957  ...              False              False   \n",
       "3                     0.255624  ...              False              False   \n",
       "4                     0.056027  ...              False              False   \n",
       "...                        ...  ...                ...                ...   \n",
       "80937                 0.026845  ...               True              False   \n",
       "80938                 0.913297  ...              False               True   \n",
       "80939                 0.763602  ...              False               True   \n",
       "80940                 0.016446  ...               True              False   \n",
       "80941                 0.012864  ...               True              False   \n",
       "\n",
       "       LightGBM3_preds_1  LightGBM3_preds_2  RandomForest1_preds_0  \\\n",
       "0                  False               True                  False   \n",
       "1                  False               True                  False   \n",
       "2                   True              False                  False   \n",
       "3                   True              False                  False   \n",
       "4                   True              False                  False   \n",
       "...                  ...                ...                    ...   \n",
       "80937              False               True                  False   \n",
       "80938              False              False                   True   \n",
       "80939              False              False                   True   \n",
       "80940              False               True                  False   \n",
       "80941              False               True                  False   \n",
       "\n",
       "       RandomForest1_preds_1  RandomForest1_preds_2  \\\n",
       "0                      False                   True   \n",
       "1                      False                   True   \n",
       "2                       True                  False   \n",
       "3                       True                  False   \n",
       "4                       True                  False   \n",
       "...                      ...                    ...   \n",
       "80937                  False                   True   \n",
       "80938                  False                  False   \n",
       "80939                  False                  False   \n",
       "80940                  False                   True   \n",
       "80941                  False                   True   \n",
       "\n",
       "       LogisticRegression1_preds_0  LogisticRegression1_preds_1  \\\n",
       "0                            False                        False   \n",
       "1                            False                        False   \n",
       "2                            False                         True   \n",
       "3                            False                         True   \n",
       "4                            False                         True   \n",
       "...                            ...                          ...   \n",
       "80937                        False                        False   \n",
       "80938                         True                        False   \n",
       "80939                         True                        False   \n",
       "80940                        False                        False   \n",
       "80941                        False                        False   \n",
       "\n",
       "       LogisticRegression1_preds_2  \n",
       "0                             True  \n",
       "1                             True  \n",
       "2                            False  \n",
       "3                            False  \n",
       "4                            False  \n",
       "...                            ...  \n",
       "80937                         True  \n",
       "80938                        False  \n",
       "80939                        False  \n",
       "80940                         True  \n",
       "80941                         True  \n",
       "\n",
       "[80942 rows x 49 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred_cols = [f\"{model_name}_preds\" for model_name in base_model_names]\n",
    "df_oof_preds_oh = pd.get_dummies(df_oof_preds, columns=model_pred_cols)\n",
    "df_test_preds_oh = pd.get_dummies(df_test_preds, columns=model_pred_cols)\n",
    "print(f\"len(df_oof_preds_oh.columns)={len(df_oof_preds_oh.columns)}\")\n",
    "print(f\"len(df_test_preds_oh.columns)={len(df_test_preds_oh.columns)}\")\n",
    "df_oof_preds_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_ensemble_preds_oh.shape = (80942, 3)\n",
      "CatBoost1 OOF Accuracy: 0.8299646660571768\n",
      "CatBoost1 OOF F1 Score: 0.7914330180500443\n",
      "CatBoost2 OOF Accuracy: 0.8312989548071459\n",
      "CatBoost2 OOF F1 Score: 0.793024497379379\n",
      "XGBoost1 OOF Accuracy: 0.830755355686788\n",
      "XGBoost1 OOF F1 Score: 0.7929256045680542\n",
      "LightGBM1 OOF Accuracy: 0.8335598329668158\n",
      "LightGBM1 OOF F1 Score: 0.7961193643046242\n",
      "LightGBM2 OOF Accuracy: 0.8331891972029354\n",
      "LightGBM2 OOF F1 Score: 0.7956540778457443\n",
      "LightGBM3 OOF Accuracy: 0.8335598329668158\n",
      "LightGBM3 OOF F1 Score: 0.7960547851284927\n",
      "RandomForest1 OOF Accuracy: 0.8260729905364335\n",
      "RandomForest1 OOF F1 Score: 0.7864036981068873\n",
      "LogisticRegression1 OOF Accuracy: 0.8272590249808505\n",
      "LogisticRegression1 OOF F1 Score: 0.7879466063211309\n",
      "Ensemble Accuracy (Hard Voting): 0.833473351288577\n",
      "Ensemble F1 Score (Hard Voting): 0.7960678482551414\n"
     ]
    }
   ],
   "source": [
    "# number of columns is same as number of classes which is same as one hot encoding of any one model's predictions  \n",
    "model_pred_cols_oh = [f\"{base_model_names[0]}_preds_{i}\" for i in range(Config.NUM_CLASSES)]\n",
    "# for voting ensembling we need one hot encoding of predictions to count the votes of each class\n",
    "voting_ensemble_preds_oh = np.zeros_like(df_oof_preds_oh[model_pred_cols_oh].to_numpy(), dtype=\"int\")\n",
    "test_voting_ensemble_preds_oh = np.zeros_like(df_test_preds_oh[model_pred_cols_oh].to_numpy(), dtype=\"int\")\n",
    "print(f\"voting_ensemble_preds_oh.shape = {voting_ensemble_preds_oh.shape}\")\n",
    "# Assuming you have the true target labels for the out-of-fold data\n",
    "target = df_oof_preds[Config.TARGET_COL_NAME]\n",
    "for model in base_model_names:\n",
    "    model_pred_cols_oh = [f\"{model}_preds_{i}\" for i in range(Config.NUM_CLASSES)]\n",
    "    model_preds_oh = df_oof_preds_oh[model_pred_cols_oh].to_numpy()\n",
    "    test_model_preds_oh = df_test_preds_oh[model_pred_cols_oh].to_numpy()\n",
    "    voting_ensemble_preds_oh += model_preds_oh\n",
    "    test_voting_ensemble_preds_oh += test_model_preds_oh\n",
    "    model_preds = df_oof_preds[f\"{model}_preds\"]\n",
    "    model_accuracy = accuracy_score(target, model_preds)\n",
    "    model_f1 = f1_score(target, model_preds, average='macro')\n",
    "    print(f\"{model} OOF Accuracy: {model_accuracy}\")\n",
    "    print(f\"{model} OOF F1 Score: {model_f1}\")\n",
    "\n",
    "# Get the class with the most votes for each data point\n",
    "voting_ensemble_preds = np.argmax(voting_ensemble_preds_oh, axis=1)\n",
    "# Calculate accuracy score of the ensemble on the out-of-fold data\n",
    "ensemble_accuracy = accuracy_score(target, voting_ensemble_preds)\n",
    "ensemble_f1 = f1_score(target, voting_ensemble_preds, average='macro')\n",
    "print(f\"Voting Ensemble Accuracy (Hard Voting): {ensemble_accuracy}\")\n",
    "print(f\"Voting Ensemble F1 Score (Hard Voting): {ensemble_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_func(weights, oof_preds, target):\n",
    "    # weighted_preds is the final weighted probability of each target class\n",
    "    weighted_preds = np.zeros((oof_preds.shape[0], 3))  # Corrected initialization\n",
    "    # weights sequence length is equal to number of base models\n",
    "    for i in range(len(weights)):\n",
    "        # for each base model class probabilites are multiplied with corresponding model weight and added to weighted_preds\n",
    "        weighted_preds += weights[i] * oof_preds[:, i*3:(i+1)*3]\n",
    "    # argmax of weighted_preds gives final prediction        \n",
    "    final_preds = np.argmax(weighted_preds, axis=1)\n",
    "    accuracy = accuracy_score(target, final_preds)\n",
    "    print(f\"Weights: {weights}, Accuracy: {accuracy}\")  # Debug output\n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start by giving equal weight to each model\n",
    "n_models = len(pred_cols) // Config.NUM_CLASSES\n",
    "initial_weights = np.ones(n_models) / n_models\n",
    "initial_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125], Accuracy: 0.8325096983024882\n",
      "Weights: [0.13125 0.125   0.125   0.125   0.125   0.125   0.125   0.125  ], Accuracy: 0.8324849892515629\n",
      "Weights: [0.125   0.13125 0.125   0.125   0.125   0.125   0.125   0.125  ], Accuracy: 0.8325714709298015\n",
      "Weights: [0.125   0.125   0.13125 0.125   0.125   0.125   0.125   0.125  ], Accuracy: 0.8325467618788762\n",
      "Weights: [0.125   0.125   0.125   0.13125 0.125   0.125   0.125   0.125  ], Accuracy: 0.8325096983024882\n",
      "Weights: [0.125   0.125   0.125   0.125   0.13125 0.125   0.125   0.125  ], Accuracy: 0.8324973437770256\n",
      "Weights: [0.125   0.125   0.125   0.125   0.125   0.13125 0.125   0.125  ], Accuracy: 0.8324849892515629\n",
      "Weights: [0.125   0.125   0.125   0.125   0.125   0.125   0.13125 0.125  ], Accuracy: 0.8324973437770256\n",
      "Weights: [0.125   0.125   0.125   0.125   0.125   0.125   0.125   0.13125], Accuracy: 0.8326208890316523\n",
      "Weights: [0.1265625 0.1265625 0.1265625 0.1265625 0.1265625 0.11875   0.1265625\n",
      " 0.1265625], Accuracy: 0.8325344073534136\n",
      "Weights: [0.11914062 0.12695312 0.12695312 0.12695312 0.12695312 0.1234375\n",
      " 0.12695312 0.12695312], Accuracy: 0.8325838254552642\n",
      "Weights: [0.12392578 0.12744141 0.12744141 0.12744141 0.12744141 0.12304688\n",
      " 0.11962891 0.12744141], Accuracy: 0.8325467618788762\n",
      "Weights: [0.12365723 0.12805176 0.12805176 0.12805176 0.12023926 0.12255859\n",
      " 0.12453613 0.12805176], Accuracy: 0.8325714709298015\n",
      "Weights: [0.12332153 0.1288147  0.1288147  0.1210022  0.12529907 0.12194824\n",
      " 0.12442017 0.1288147 ], Accuracy: 0.832596179980727\n",
      "Weights: [0.12290192 0.12976837 0.12976837 0.12625275 0.12537384 0.1211853\n",
      " 0.12427521 0.12976837], Accuracy: 0.8325838254552642\n",
      "Weights: [0.12042427 0.12900734 0.12900734 0.12461281 0.12351418 0.12804413\n",
      " 0.12214088 0.12900734], Accuracy: 0.832596179980727\n",
      "Weights: [0.12218561 0.12851992 0.12851992 0.12302675 0.12165346 0.12499657\n",
      " 0.12970247 0.12851992], Accuracy: 0.8325344073534136\n",
      "Weights: [0.12349074 0.12771103 0.12771103 0.12633774 0.12599442 0.1235343\n",
      " 0.1221473  0.12771103], Accuracy: 0.8325467618788762\n",
      "Weights: [0.12416077 0.12690735 0.12690735 0.1230011  0.12514954 0.12347412\n",
      " 0.12471008 0.13003235], Accuracy: 0.832596179980727\n",
      "Weights: [0.12271214 0.12700367 0.12700367 0.1248064  0.12425709 0.12652206\n",
      " 0.12357044 0.13012867], Accuracy: 0.8325591164043389\n",
      "Weights: [0.12207031 0.12597656 0.12597656 0.12597656 0.12597656 0.12421875\n",
      " 0.12597656 0.12910156], Accuracy: 0.8325838254552642\n",
      "Weights: [0.12395096 0.12738419 0.12738419 0.12562637 0.12518692 0.12309265\n",
      " 0.1246376  0.13050919], Accuracy: 0.8326085345061897\n",
      "Weights: [0.125    0.128125 0.125    0.125    0.125    0.125    0.125    0.128125], Accuracy: 0.8325838254552642\n",
      "Weights: [0.12432861 0.12652588 0.12652588 0.12652588 0.12261963 0.1237793\n",
      " 0.12476807 0.12965088], Accuracy: 0.8325714709298015\n",
      "Weights: [0.125    0.125    0.128125 0.125    0.125    0.125    0.125    0.128125], Accuracy: 0.8325344073534136\n",
      "Weights: [0.12446289 0.1262207  0.1262207  0.1262207  0.1262207  0.12402344\n",
      " 0.12231445 0.1293457 ], Accuracy: 0.8325220528279509\n",
      "Weights: [0.12359281 0.12675996 0.12675996 0.12401338 0.12332673 0.12499828\n",
      " 0.12735124 0.12988496], Accuracy: 0.832596179980727\n",
      "Weights: [0.1227039  0.12842065 0.1245144  0.12498742 0.12412912 0.12402129\n",
      " 0.1252535  0.13154565], Accuracy: 0.832596179980727\n",
      "Weights: [0.1249897  0.12677123 0.12501341 0.12522627 0.12484004 0.12187403\n",
      " 0.12710382 0.12989623], Accuracy: 0.8325714709298015\n",
      "Weights: [0.12442031 0.12682934 0.12551098 0.12512131 0.1246943  0.12303604\n",
      " 0.12622048 0.12995434], Accuracy: 0.8325838254552642\n",
      "Weights: [0.12339615 0.12732488 0.12523748 0.12315566 0.12699616 0.12443099\n",
      " 0.1262693  0.13044988], Accuracy: 0.832596179980727\n",
      "Weights: [0.12304841 0.12714531 0.12618401 0.12406882 0.12549696 0.12552298\n",
      " 0.12482909 0.13027031], Accuracy: 0.832596179980727\n",
      "Weights: [0.12198083 0.12560472 0.12699099 0.12395733 0.1253155  0.12368977\n",
      " 0.12600684 0.13263597], Accuracy: 0.8326085345061897\n",
      "Weights: [0.12488814 0.1276602  0.12626803 0.12247596 0.12417367 0.12433877\n",
      " 0.12503785 0.13254301], Accuracy: 0.8326085345061897\n",
      "Weights: [0.12436997 0.12662018 0.12608159 0.12398549 0.12432245 0.12273849\n",
      " 0.12623751 0.13194244], Accuracy: 0.8326208890316523\n",
      "Weights: [0.12426569 0.12626443 0.12723915 0.1251061  0.12215482 0.12340736\n",
      " 0.12478936 0.13213601], Accuracy: 0.832596179980727\n",
      "Weights: [0.12361354 0.12705977 0.1257379  0.12364327 0.12578583 0.12417508\n",
      " 0.12589931 0.13087141], Accuracy: 0.832596179980727\n",
      "Weights: [0.12468499 0.12581009 0.1255408  0.12449274 0.12466122 0.12386924\n",
      " 0.12561875 0.13159622], Accuracy: 0.8326085345061897\n",
      "Weights: [0.12447548 0.12619209 0.12619209 0.12531319 0.12509346 0.12404633\n",
      " 0.1248188  0.13087959], Accuracy: 0.832596179980727\n",
      "Weights: [0.12349041 0.12530236 0.12599549 0.12447866 0.12515775 0.12434488\n",
      " 0.12550342 0.13194299], Accuracy: 0.8326085345061897\n",
      "Weights: [0.12494407 0.1263301  0.12563401 0.12373798 0.12458683 0.12466939\n",
      " 0.12501893 0.13189651], Accuracy: 0.8326085345061897\n",
      "Weights: [0.12458038 0.12595367 0.12595367 0.12400055 0.12507477 0.12423706\n",
      " 0.12485504 0.13064117], Accuracy: 0.832596179980727\n",
      "Weights: [0.1242964  0.12587998 0.12587998 0.12450669 0.12416337 0.12499914\n",
      " 0.12617562 0.13056748], Accuracy: 0.832596179980727\n",
      "Weights: [0.12385195 0.12671033 0.1247572  0.12499371 0.12456456 0.12451065\n",
      " 0.12512675 0.13139783], Accuracy: 0.832596179980727\n",
      "Weights: [0.12419807 0.12616244 0.12511874 0.12407783 0.12599808 0.12471549\n",
      " 0.12563465 0.13084994], Accuracy: 0.832596179980727\n",
      "Weights: [0.12463285 0.12563222 0.12611957 0.12505305 0.12357741 0.12420368\n",
      " 0.12489468 0.13169301], Accuracy: 0.8326208890316523\n",
      "Weights: [0.1251742  0.1248148  0.1268217  0.124152   0.12476414 0.12433178\n",
      " 0.12534456 0.13121892], Accuracy: 0.8326085345061897\n",
      "Weights: [0.12494919 0.12537886 0.12593436 0.12455036 0.12531553 0.12367645\n",
      " 0.12408793 0.13221212], Accuracy: 0.8326208890316523\n",
      "Weights: [0.12475741 0.12516146 0.12585583 0.12519395 0.12446432 0.12429838\n",
      " 0.12521673 0.13253116], Accuracy: 0.8326208890316523\n",
      "Weights: [0.1249328  0.12466538 0.12553335 0.1238515  0.12428834 0.12455212\n",
      " 0.12535245 0.13270564], Accuracy: 0.832633243557115\n",
      "Weights: [0.12516146 0.12390202 0.12520398 0.12312065 0.12388578 0.12480502\n",
      " 0.12561927 0.13361866], Accuracy: 0.832633243557115\n",
      "Weights: [0.12417373 0.12600531 0.12458165 0.12493756 0.12449871 0.12432175\n",
      " 0.12482866 0.132738  ], Accuracy: 0.8326208890316523\n",
      "Weights: [0.12421128 0.12440882 0.12550625 0.12565148 0.12465399 0.12389724\n",
      " 0.12510673 0.13227078], Accuracy: 0.8326085345061897\n",
      "Weights: [0.12476087 0.12584978 0.12560207 0.12421635 0.12460362 0.12447635\n",
      " 0.12504088 0.13199007], Accuracy: 0.8326208890316523\n",
      "Weights: [0.12598255 0.12557341 0.12504641 0.12484521 0.12394454 0.12425461\n",
      " 0.1245066  0.13223607], Accuracy: 0.8326208890316523\n",
      "Weights: [0.12511236 0.12500651 0.12537752 0.12491925 0.12426189 0.12482659\n",
      " 0.12411322 0.1327428 ], Accuracy: 0.8326208890316523\n",
      "Weights: [0.12500552 0.12520741 0.12541834 0.12481262 0.12436173 0.12458725\n",
      " 0.12448961 0.13245615], Accuracy: 0.8326208890316523\n",
      "Weights: [0.12479183 0.12560919 0.12549998 0.12459937 0.12456139 0.12410858\n",
      " 0.12524237 0.13188287], Accuracy: 0.8326208890316523\n",
      "Weights: [0.1249521  0.12530785 0.12543875 0.12475931 0.12441164 0.12446759\n",
      " 0.1246778  0.13231283], Accuracy: 0.8326208890316523\n",
      "Weights: [0.1249664  0.12483269 0.12526667 0.12442575 0.12464417 0.12477606\n",
      " 0.12517622 0.13197782], Accuracy: 0.832633243557115\n",
      "Weights: [0.12478282 0.1251488  0.12582646 0.12445228 0.12393288 0.1243779\n",
      " 0.12512356 0.13219932], Accuracy: 0.8326208890316523\n",
      "Weights: [0.124941   0.12502212 0.12573385 0.12420093 0.12480194 0.12411429\n",
      " 0.12472019 0.13245888], Accuracy: 0.8326208890316523\n",
      "Weights: [0.12484511 0.12491342 0.12569459 0.12452272 0.12437633 0.12442525\n",
      " 0.12528459 0.1326184 ], Accuracy: 0.832633243557115\n",
      "Weights: [0.12455327 0.12533534 0.1250575  0.12439453 0.12439353 0.12443694\n",
      " 0.12509055 0.13272182], Accuracy: 0.832633243557115\n",
      "Weights: [0.12484684 0.12525758 0.12556771 0.12403393 0.12444598 0.12451424\n",
      " 0.12519666 0.13234786], Accuracy: 0.8326208890316523\n",
      "Weights: [0.12545767 0.12511939 0.12528988 0.12434836 0.12411644 0.12440337\n",
      " 0.12492952 0.13247085], Accuracy: 0.832633243557115\n",
      "Weights: [0.12496916 0.12493639 0.12547584 0.12433206 0.12432503 0.12456969\n",
      " 0.12492103 0.1325809 ], Accuracy: 0.832633243557115\n",
      "Weights: [0.12501522 0.1247358  0.12540183 0.1245981  0.12427368 0.12439967\n",
      " 0.12495287 0.13258555], Accuracy: 0.832633243557115\n",
      "Weights: [0.12493962 0.12489969 0.12515268 0.1245304  0.12378566 0.12487096\n",
      " 0.12548751 0.13250619], Accuracy: 0.832633243557115\n",
      "Weights: [0.12513699 0.12471073 0.12489163 0.12429858 0.12461792 0.12473061\n",
      " 0.12517512 0.13284247], Accuracy: 0.832633243557115\n",
      "Weights: [0.12504845 0.12482025 0.12512533 0.124337   0.12444666 0.12464244\n",
      " 0.12516223 0.13268168], Accuracy: 0.832633243557115\n",
      "Weights: [0.12487136 0.12503928 0.12559275 0.12441385 0.12410414 0.12446608\n",
      " 0.12513645 0.13236011], Accuracy: 0.832633243557115\n",
      "Weights: [0.12500418 0.124875   0.12524219 0.12435621 0.12436103 0.12459835\n",
      " 0.12515579 0.13260129], Accuracy: 0.832633243557115\n",
      "Weights: [0.1249496  0.12474903 0.12540001 0.12413862 0.12446626 0.12466409\n",
      " 0.12526434 0.13234173], Accuracy: 0.832633243557115\n",
      "Weights: [0.12488895 0.1247894  0.12561397 0.12418711 0.12433234 0.12448869\n",
      " 0.12531852 0.13266202], Accuracy: 0.832633243557115\n",
      "Weights: [0.12474303 0.12500036 0.12529542 0.12412301 0.12434093 0.12449453\n",
      " 0.1252215  0.13271373], Accuracy: 0.832633243557115\n",
      "Weights: [0.12519524 0.12489239 0.12541162 0.12409993 0.12420239 0.12447775\n",
      " 0.12514099 0.13258825], Accuracy: 0.832633243557115\n",
      "Weights: [0.12495098 0.12480088 0.1255046  0.12409178 0.12430669 0.12456091\n",
      " 0.12513674 0.13264327], Accuracy: 0.832633243557115\n",
      "Weights: [0.12497401 0.12470059 0.12546759 0.1242248  0.12428101 0.1244759\n",
      " 0.12515266 0.13264559], Accuracy: 0.832633243557115\n",
      "Weights: [0.12493621 0.12478253 0.12534301 0.12419095 0.124037   0.12471154\n",
      " 0.12541998 0.13260592], Accuracy: 0.832633243557115\n",
      "Weights: [0.12499062 0.12474281 0.12532934 0.12409425 0.1243675  0.12459728\n",
      " 0.12525734 0.13269366], Accuracy: 0.832633243557115\n",
      "Weights: [0.12490208 0.12485233 0.12556305 0.12413267 0.12419624 0.1245091\n",
      " 0.12524445 0.13253287], Accuracy: 0.832633243557115\n",
      "Weights: [0.12496849 0.12477019 0.12538777 0.12410386 0.12432469 0.12457524\n",
      " 0.12525412 0.13265346], Accuracy: 0.832633243557115\n",
      "Weights: [0.1249412  0.12470721 0.12546668 0.12399506 0.1243773  0.12460811\n",
      " 0.12530839 0.13252368], Accuracy: 0.832633243557115\n",
      "Weights: [0.12491088 0.12472739 0.12557366 0.1240193  0.12431034 0.12452041\n",
      " 0.12533548 0.13268383], Accuracy: 0.832633243557115\n",
      "Weights: [0.12483792 0.12483287 0.12541439 0.12398726 0.12431464 0.12452333\n",
      " 0.12528697 0.13270968], Accuracy: 0.832633243557115\n",
      "Weights: [0.12506402 0.12477888 0.12547248 0.12397571 0.12424537 0.12451493\n",
      " 0.12524672 0.13264694], Accuracy: 0.832633243557115\n",
      "Weights: [0.12494189 0.12473313 0.12551897 0.12397164 0.12429752 0.12455652\n",
      " 0.12524459 0.13267445], Accuracy: 0.832633243557115\n",
      "Weights: [0.12495341 0.12468298 0.12550047 0.12403815 0.12428468 0.12451401\n",
      " 0.12525255 0.13267562], Accuracy: 0.832633243557115\n",
      "Weights: [0.1249345  0.12472395 0.12543818 0.12402122 0.12416267 0.12463183\n",
      " 0.12538621 0.13265578], Accuracy: 0.832633243557115\n",
      "Weights: [0.12496171 0.12470409 0.12543135 0.12397287 0.12432792 0.1245747\n",
      " 0.12530489 0.13269965], Accuracy: 0.832633243557115\n",
      "Weights: [0.12491744 0.12475885 0.1255482  0.12399209 0.12424229 0.12453061\n",
      " 0.12529845 0.13261926], Accuracy: 0.832633243557115\n",
      "Weights: [0.12495064 0.12471778 0.12546056 0.12397768 0.12430651 0.12456368\n",
      " 0.12530328 0.13267955], Accuracy: 0.832633243557115\n",
      "Weights: [0.124937   0.12468629 0.12550002 0.12392328 0.12433282 0.12458012\n",
      " 0.12533042 0.13261466], Accuracy: 0.832633243557115\n",
      "Weights: [0.12492184 0.12469638 0.12555351 0.1239354  0.12429934 0.12453626\n",
      " 0.12534397 0.13269473], Accuracy: 0.832633243557115\n",
      "Weights: [0.12488536 0.12474912 0.12547387 0.12391938 0.12430149 0.12453773\n",
      " 0.12531971 0.13270766], Accuracy: 0.832633243557115\n",
      "Weights: [0.12499841 0.12472213 0.12550292 0.12391361 0.12426685 0.12453353\n",
      " 0.12529958 0.13267629], Accuracy: 0.832633243557115\n",
      "Weights: [0.12493735 0.12469925 0.12552616 0.12391157 0.12429293 0.12455432\n",
      " 0.12529852 0.13269005], Accuracy: 0.832633243557115\n",
      "Weights: [0.1249431  0.12467418 0.12551691 0.12394482 0.12428651 0.12453307\n",
      " 0.1253025  0.13269063], Accuracy: 0.832633243557115\n",
      "Weights: [0.12493365 0.12469467 0.12548577 0.12393636 0.12422551 0.12459198\n",
      " 0.12536933 0.13268071], Accuracy: 0.832633243557115\n",
      "Weights: [0.12494726 0.12468474 0.12548235 0.12391219 0.12430813 0.12456341\n",
      " 0.12532867 0.13270264], Accuracy: 0.832633243557115\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# We want to find the set of weights that maximizes the accuracy. We start with the initial weights.\n",
    "target = df_oof_preds[Config.TARGET_COL_NAME]\n",
    "res = minimize(acc_func, initial_weights, args=(df_oof_preds[pred_cols].to_numpy(), target), method='Nelder-Mead')\n",
    "model_weights = res[\"x\"]\n",
    "acc = res[\"fun\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Model Weights: [0.12420229 0.12393644 0.12479933 0.12312732 0.12356161 0.12382384\n",
      " 0.12461949 0.13192968]\n",
      "Optimal Accuracy: -0.832633243557115\n"
     ]
    }
   ],
   "source": [
    "model_weights_normalized = model_weights / np.sum(model_weights)\n",
    "print(\"Optimal Model Weights:\", model_weights_normalized)\n",
    "print(\"Optimal Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_test_preds_proba(test_preds, model_weights):\n",
    "    weighted_test_preds_proba = np.zeros((test_preds.shape[0], 3))\n",
    "    for i in range(len(model_weights)):\n",
    "        weighted_test_preds_proba += model_weights[i] * test_preds[:, i*3:(i+1)*3]\n",
    "    return weighted_test_preds_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    26494\n",
       "0    15371\n",
       "1     9147\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_test_preds_proba = get_weighted_test_preds_proba(df_test_preds[pred_cols].to_numpy(), model_weights_normalized)\n",
    "ensemble_test_preds = pd.Series(np.argmax(weighted_test_preds_proba, axis=1))\n",
    "ensemble_test_preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    41495\n",
       "0    24898\n",
       "1    14549\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_ensemble_preds= pd.Series(np.argmax(voting_ensemble_preds_oh, axis=1))\n",
    "test_voting_ensemble_preds = pd.Series(np.argmax(test_voting_ensemble_preds_oh, axis=1))\n",
    "voting_ensemble_preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graduate    26494\n",
       "Dropout     15371\n",
       "Enrolled     9147\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace class labels with corresponding strings using map\n",
    "ensemble_test_preds = ensemble_test_preds.map(target_class_mapping)\n",
    "ensemble_test_preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graduate    26364\n",
       "Dropout     15486\n",
       "Enrolled     9162\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_voting_ensemble_preds = test_voting_ensemble_preds.map(target_class_mapping)\n",
    "test_voting_ensemble_preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGBM3_preds\n",
       "Graduate    26443\n",
       "Dropout     15480\n",
       "Enrolled     9089\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"LightGBM3\"\n",
    "model_test_preds = df_test_preds[f\"{model_name}_preds\"].map(target_class_mapping)\n",
    "model_test_preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76518</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76519</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76520</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76521</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76522</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    Target\n",
       "0  76518   Dropout\n",
       "1  76519  Graduate\n",
       "2  76520  Graduate\n",
       "3  76521  Graduate\n",
       "4  76522  Enrolled"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission[Config.TARGET_COL_NAME] = ensemble_test_preds\n",
    "df_submission.to_csv(BASE_MODELS_PATH + f'submission_ensemble.csv',index=False)\n",
    "df_submission.to_csv(BASE_MODELS_PATH + f'submission_voting_ensemble.csv',index=False)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = np.array([\"Dropout\", \"Enrolled\", \"Graduate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble OOF Accuracy: 0.832633243557115\n",
      "Ensemble OOF F1 Score: 0.7948526384100228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.90      0.83      0.86     26717\n",
      "    Enrolled       0.66      0.61      0.63     15734\n",
      "    Graduate       0.85      0.93      0.89     38491\n",
      "\n",
      "    accuracy                           0.83     80942\n",
      "   macro avg       0.80      0.79      0.79     80942\n",
      "weighted avg       0.83      0.83      0.83     80942\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted_oof_preds_proba = get_weighted_test_preds_proba(df_oof_preds[pred_cols].to_numpy(), model_weights_normalized)\n",
    "weighted_oof_preds = np.argmax(weighted_oof_preds_proba, axis=1)\n",
    "weighted_oof_accuracy = accuracy_score(df_oof_preds[Config.TARGET_COL_NAME], weighted_oof_preds)\n",
    "ensemble_f1_score = f1_score(df_oof_preds[Config.TARGET_COL_NAME], weighted_oof_preds, average='macro')\n",
    "print(f\"Weighted Ensemble OOF Accuracy: {weighted_oof_accuracy}\")\n",
    "print(f\"Weighted Ensemble OOF F1 Score: {ensemble_f1_score}\")\n",
    "ensemble_cm = confusion_matrix(df_oof_preds[Config.TARGET_COL_NAME], weighted_oof_preds)\n",
    "print(classification_report(df_oof_preds[Config.TARGET_COL_NAME].values, weighted_oof_preds, target_names=target_classes))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=ensemble_cm, display_labels=target_classes)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_stats(model_name):    \n",
    "    model_cols = [f\"{model_name}_preds_proba_{i}\" for i in range(Config.NUM_CLASSES)]\n",
    "    model_preds_proba = df_oof_preds[model_cols].to_numpy()\n",
    "    model_preds = np.argmax(model_preds_proba, axis=1)\n",
    "    model_accuracy = accuracy_score(df_oof_preds[Config.TARGET_COL_NAME], model_preds)\n",
    "    model_f1 = f1_score(df_oof_preds[Config.TARGET_COL_NAME], model_preds, average='macro')\n",
    "    print(f\"{model_name} OOF Accuracy: {model_accuracy}\")\n",
    "    print(f\"{model_name} OOF F1 Score: {model_f1}\")\n",
    "    model_cm = confusion_matrix(df_oof_preds[Config.TARGET_COL_NAME], model_preds)\n",
    "    print(classification_report(df_oof_preds[Config.TARGET_COL_NAME].values, model_preds, target_names=target_classes))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=model_cm, display_labels=target_classes)\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM3 OOF Accuracy: 0.8335598329668158\n",
      "LightGBM3 OOF F1 Score: 0.7960547851284927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Dropout       0.90      0.84      0.87     26717\n",
      "    Enrolled       0.66      0.61      0.63     15734\n",
      "    Graduate       0.86      0.92      0.89     38491\n",
      "\n",
      "    accuracy                           0.83     80942\n",
      "   macro avg       0.80      0.79      0.80     80942\n",
      "weighted avg       0.83      0.83      0.83     80942\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_model_stats(\"LightGBM3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
