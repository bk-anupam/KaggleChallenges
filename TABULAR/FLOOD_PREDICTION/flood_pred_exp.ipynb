{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q openfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import statistics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, SplineTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import clone\n",
    "from functools import partial\n",
    "from joblib import dump\n",
    "from scipy.stats import skew, kurtosis\n",
    "from openfe import OpenFE, transform\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"/home/bk_anupam/code/ML/ML_UTILS/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_tabular_utils as tt\n",
    "import cv_split_utils\n",
    "import enums\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RUN_MODE = \"LOCAL\"\n",
    "    RANDOM_SEED = 1\n",
    "    NUM_FOLDS = 5\n",
    "    TARGET_COL_NAME = \"FloodProbability\"        \n",
    "    SCALER = enums.Scaler.StandardScaler\n",
    "    METRIC = enums.Metrics.R2\n",
    "    # These values are more dynamic   \n",
    "    MODEL_TYPE = enums.ModelName.Ridge    \n",
    "    NUM_TUNING_TRIALS = 2\n",
    "    TUNE_ON_SINGLE_FOLD = True\n",
    "    TRAIN_SINGLE_FOLD = False\n",
    "    GENERATE_AUTO_FEATURES = False\n",
    "    PERSIST_MODEL = False\n",
    "    TRANSFORM_TARGET = False\n",
    "\n",
    "COLS_TO_LEAVE = [\"FloodProbability\", \"kfold\"]\n",
    "CPU_COUNT = os.cpu_count()\n",
    "\n",
    "DATA_READPATH = \"./data/\"\n",
    "DATA_WRITEPATH = \"./output/\"\n",
    "SUBMISSION_FILEPATH = DATA_READPATH\n",
    "if Config.RUN_MODE == \"KAGGLE\":\n",
    "    # If we are not generating features, we are using already generated features\n",
    "    if Config.GENERATE_AUTO_FEATURES:\n",
    "        DATA_READPATH = \"/kaggle/input/playground-series-s4e5/\"\n",
    "        SUBMISSION_FILEPATH = DATA_READPATH\n",
    "    else:\n",
    "        DATA_READPATH = \"/kaggle/input/playground-series-s4e5/\"\n",
    "        SUBMISSION_FILEPATH = \"/kaggle/input/playground-series-s4e5/\"\n",
    "    DATA_WRITEPATH = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_static_params = {\n",
    "    enums.ModelName.XGBoost: {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"seed\": Config.RANDOM_SEED,\n",
    "        \"verbosity\": 0,\n",
    "    },\n",
    "    enums.ModelName.LGBM: {\n",
    "        \"objective\": \"root_mean_squared_error\",\n",
    "        \"metric\": 'rmse',\n",
    "        \"verbosity\": -1,    # <0: fatal, =0: error (warn), =1: info, >1: debug\n",
    "        \"boosting_type\": \"gbdt\"\n",
    "    },\n",
    "    enums.ModelName.CatBoost: {\n",
    "        \"objective\": \"RMSE\",\n",
    "        \"verbose\": 0,\n",
    "        \"random_seed\": Config.RANDOM_SEED,\n",
    "        \"eval_metric\": \"RMSE\",\n",
    "        'grow_policy':  'Lossguide',\n",
    "        'bootstrap_type': 'Poisson',\n",
    "        'task_type': 'GPU'\n",
    "    },\n",
    "    enums.ModelName.RandomForest: {\n",
    "        \"random_state\": Config.RANDOM_SEED,\n",
    "        \"n_jobs\": -1\n",
    "    },\n",
    "    enums.ModelName.Ridge: {\n",
    "        \"random_state\": Config.RANDOM_SEED\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train dataset locally from data folder\n",
    "df_train = pd.read_csv(DATA_READPATH + \"train.csv\", index_col='id')\n",
    "# import test dataset locally from data folder\n",
    "df_test = pd.read_csv(DATA_READPATH + \"test.csv\", index_col='id')\n",
    "# keep a copy of original train and test data for later use\n",
    "# df_train_orig = df_train.copy()\n",
    "# df_test_orig = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_for_fe = df_test.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute skewness and kurtosis for each row\n",
    "def compute_skew_kurtosis(matrix):\n",
    "    skewness = skew(matrix, axis=1)\n",
    "    kurt = kurtosis(matrix, axis=1)\n",
    "    return skewness, kurt\n",
    "\n",
    "def create_features(df, feature_cols):\n",
    "    # Create a new feature by summing all features\n",
    "    df[\"f_sum\"] = df[feature_cols].sum(axis=1)\n",
    "    # Create a new feature by taking mean of all features\n",
    "    df[\"f_mean\"] = df[feature_cols].mean(axis=1)\n",
    "    df[\"f_median\"] = df[feature_cols].median(axis=1)\n",
    "    # standard deviation\n",
    "    df['f_std'] = df[feature_cols].std(axis=1)\n",
    "    # min and max\n",
    "    df['f_min'] = df[feature_cols].min(axis=1)\n",
    "    df['f_max'] = df[feature_cols].max(axis=1)\n",
    "    # Compute skewness and kurtosis\n",
    "    skewness, kurt = compute_skew_kurtosis(df[feature_cols].values)\n",
    "    df['f_skew'] = skewness\n",
    "    df['f_kurtosis'] = kurt    \n",
    "    # Quantiles\n",
    "    quantiles = [0.25, 0.5, 0.75]\n",
    "    for q in quantiles:\n",
    "        df[f'f_quantile_{int(q*100)}'] = df[feature_cols].quantile(q=q, axis=1)        \n",
    "    # sorted features\n",
    "    sorted_features = [f\"sort_{i}\" for i in np.arange(len(feature_cols))]\n",
    "    df[sorted_features] = np.sort(df[feature_cols], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = create_features(df_train, feature_cols_for_fe)\n",
    "df_test = create_features(df_test, feature_cols_for_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>Encroachments</th>\n",
       "      <th>...</th>\n",
       "      <th>f_mean</th>\n",
       "      <th>f_median</th>\n",
       "      <th>f_std</th>\n",
       "      <th>f_min</th>\n",
       "      <th>f_max</th>\n",
       "      <th>f_skew</th>\n",
       "      <th>f_kurtosis</th>\n",
       "      <th>f_quantile_25</th>\n",
       "      <th>f_quantile_50</th>\n",
       "      <th>f_quantile_75</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.750188</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.533028</td>\n",
       "      <td>-0.685939</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.296450</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.136973</td>\n",
       "      <td>-0.560579</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.95</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.932411</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.376816</td>\n",
       "      <td>-0.855085</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>5.20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.641565</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.111328</td>\n",
       "      <td>-0.738770</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.500877</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.233825</td>\n",
       "      <td>-0.993012</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "id                                                                         \n",
       "0                  5                   8                5              8   \n",
       "1                  6                   7                4              4   \n",
       "2                  6                   5                6              7   \n",
       "3                  3                   4                6              5   \n",
       "4                  5                   3                2              6   \n",
       "\n",
       "    Urbanization  ClimateChange  DamsQuality  Siltation  \\\n",
       "id                                                        \n",
       "0              6              4            4          3   \n",
       "1              8              8            3          5   \n",
       "2              3              7            1          5   \n",
       "3              4              8            4          7   \n",
       "4              4              4            3          3   \n",
       "\n",
       "    AgriculturalPractices  Encroachments  ...  f_mean  f_median     f_std  \\\n",
       "id                                        ...                               \n",
       "0                       3              4  ...    4.70       4.5  1.750188   \n",
       "1                       4              6  ...    4.70       4.0  2.296450   \n",
       "2                       4              5  ...    4.95       5.0  1.932411   \n",
       "3                       6              8  ...    5.20       5.0  1.641565   \n",
       "4                       3              3  ...    3.60       3.0  1.500877   \n",
       "\n",
       "    f_min  f_max    f_skew  f_kurtosis  f_quantile_25  f_quantile_50  \\\n",
       "id                                                                     \n",
       "0       2      8  0.533028   -0.685939           3.00            4.5   \n",
       "1       0      9  0.136973   -0.560579           3.00            4.0   \n",
       "2       1      8 -0.376816   -0.855085           3.00            5.0   \n",
       "3       2      8  0.111328   -0.738770           4.00            5.0   \n",
       "4       1      6  0.233825   -0.993012           2.75            3.0   \n",
       "\n",
       "    f_quantile_75  \n",
       "id                 \n",
       "0            5.25  \n",
       "1            6.25  \n",
       "2            6.25  \n",
       "3            6.25  \n",
       "4            5.00  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(feature_cols)=31\n"
     ]
    }
   ],
   "source": [
    "feature_cols= [x for x in df_train.columns.to_list() if x not in COLS_TO_LEAVE]\n",
    "print(f\"len(feature_cols)={len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "polynomial_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "spline_transformer = SplineTransformer(n_knots=5, degree=3, include_bias=False)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[        \n",
    "        #(\"poly\", polynomial_features, feature_cols),\n",
    "        (\"scaler\", scaler, feature_cols),\n",
    "        (\"onehot\", onehot_encoder, ['f_sum']),        \n",
    "    ], remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model_name, model, df, feature_cols, target_col_name, metric, n_repeat=1, single_fold=False, num_folds=5):    \n",
    "    df = cv_split_utils.kfold_dataframe(df, random_state=Config.RANDOM_SEED, num_folds=Config.NUM_FOLDS)\n",
    "    df_oof_preds = pd.DataFrame()\n",
    "    fold_metrics_model = []\n",
    "    for fold in range(num_folds):\n",
    "        fold_model = clone(model)\n",
    "        df_train_fold, df_val_fold = tt.get_fold_df(df, fold)\n",
    "        train_X, train_y, val_X, val_y = tt.get_train_val_nparray(df_train_fold, df_val_fold, feature_cols, target_col_name)\n",
    "        fold_model.fit(train_X, train_y)\n",
    "        val_y_pred = fold_model.predict(val_X)\n",
    "        fold_val_metric = tt.get_eval_metric(metric, val_y, val_y_pred)\n",
    "        print(f\"Fold {fold} - {model_name} - {metric} : {fold_val_metric}\")\n",
    "        df_fold_val_preds = df_val_fold[['kfold', target_col_name]]\n",
    "        df_fold_val_preds['oof_preds'] = val_y_pred\n",
    "        df_oof_preds = pd.concat([df_oof_preds, df_fold_val_preds], axis=0)\n",
    "        fold_metrics_model.append((fold_val_metric, fold_model))\n",
    "        if single_fold:\n",
    "            break\n",
    "    cv = tt.get_eval_metric(metric, df_oof_preds[target_col_name], df_oof_preds['oof_preds'] )\n",
    "    print(f\"{model_name} metric={metric} CV score = {cv}\")\n",
    "    metrics = [item[0] for item in fold_metrics_model]\n",
    "    mean_metric, std_metric = tt.get_metric_stats(metrics)    \n",
    "    print(f\"{model_name} Mean {metric} = {mean_metric}, std = {std_metric}\")        \n",
    "    return fold_metrics_model, df_oof_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgbm_tuning_params(trial):    \n",
    "    params_dynamic = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=25),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 20),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 256, step=4),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 500, step=20)\n",
    "    }\n",
    "    return {**model_static_params[enums.ModelName.LGBM], **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catboost_tuning_params(trial):\n",
    "    params_dynamic = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 5000, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 16),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        # comment colsample_bylevel for GPU training\n",
    "        #'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 256, step=4),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "        'random_strength': trial.suggest_loguniform('random_strength', 0.01, 10),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 500, step=20),\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255)\n",
    "    }\n",
    "    return {**model_static_params[enums.ModelName.CatBoost], **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgb_tuning_params(trial):\n",
    "    params_dynamic = {            \n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 5000, step=100),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 32),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "            'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 100, 500, step=20)\n",
    "        }\n",
    "    return {**model_static_params[enums.ModelName.XGBoost], **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_tuning_params(trial, model_name):\n",
    "    if model_name == enums.ModelName.Ridge:\n",
    "        return {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-4, 1e4, log=True)\n",
    "        }\n",
    "    if model_name == enums.ModelName.Lasso:\n",
    "        return {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-4, 1e4, log=True)\n",
    "        }\n",
    "    if model_name == enums.ModelName.RandomForest:\n",
    "        return {        \n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 3000, step=100),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 10, 30),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 2, 16),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 16),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"log2\", \"sqrt\", None])\n",
    "        }\n",
    "    if model_name == enums.ModelName.CatBoost:\n",
    "        return get_catboost_tuning_params(trial)\n",
    "    if model_name == enums.ModelName.LGBM:\n",
    "        return get_lgbm_tuning_params(trial)\n",
    "    if model_name == enums.ModelName.XGBoost:\n",
    "        return get_xgb_tuning_params(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparams_tuning_objective(trial, model_name, preprocessor, df_train,  \n",
    "                                 feature_cols, metric, target_col_name, single_fold=False, num_folds=5):               \n",
    "    model_params = get_model_tuning_params(trial, model_name)\n",
    "    model = tt.get_model(model_name=model_name, params=model_params, metric=metric)\n",
    "    if preprocessor is not None:\n",
    "        model = make_pipeline(preprocessor, model)\n",
    "    fold_metrics_model, df_val_preds = train_and_validate(\n",
    "                                        model_name=model_name,\n",
    "                                        model=model,\n",
    "                                        df=df_train,\n",
    "                                        feature_cols=feature_cols,\n",
    "                                        target_col_name=target_col_name,\n",
    "                                        metric=metric,\n",
    "                                        single_fold=single_fold,\n",
    "                                        num_folds=num_folds\n",
    "                                    )\n",
    "    fold_metrics = [x[0] for x in fold_metrics_model]\n",
    "    mean_metric = statistics.mean(fold_metrics)                \n",
    "    return mean_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model_params(study_name, study_direction, num_trials, model_name, preprocessor,\n",
    "                      df_train,  feature_cols, metric, target_col_name, \n",
    "                      single_fold=False, num_folds=5):\n",
    "    model_params_tuning_obj_partial = partial(\n",
    "        hyperparams_tuning_objective,\n",
    "        model_name=model_name,\n",
    "        preprocessor=preprocessor,        \n",
    "        df_train=df_train,\n",
    "        feature_cols=feature_cols,\n",
    "        metric=metric,\n",
    "        target_col_name=target_col_name,\n",
    "        single_fold=single_fold,\n",
    "        num_folds=num_folds\n",
    "    )\n",
    "    study = optuna.create_study(direction=study_direction, study_name=study_name)\n",
    "    study.optimize(model_params_tuning_obj_partial, n_trials=num_trials)\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"Best trial: number = {best_trial.number}, value = {best_trial.value}, params = {best_trial.params}\")\n",
    "    return best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-31 19:11:17,292] A new study created in memory with name: Ridge_ModelTuning\n",
      "[I 2024-05-31 19:11:24,110] Trial 0 finished with value: 0.865830794470718 and parameters: {'alpha': 11.305059973897613}. Best is trial 0 with value: 0.865830794470718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Ridge - R2 : 0.865830794470718\n",
      "Ridge metric=R2 CV score = 0.865830794470718\n",
      "Ridge Mean R2 = 0.865830794470718, std = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-31 19:11:34,504] Trial 1 finished with value: 0.8644737715286331 and parameters: {'alpha': 1740.0928698270993}. Best is trial 0 with value: 0.865830794470718.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Ridge - R2 : 0.8644737715286331\n",
      "Ridge metric=R2 CV score = 0.8644737715286331\n",
      "Ridge Mean R2 = 0.8644737715286331, std = 0.0\n",
      "Best trial: number = 0, value = 0.865830794470718, params = {'alpha': 11.305059973897613}\n"
     ]
    }
   ],
   "source": [
    "if tuned_model_params is None:\n",
    "    tuned_model_params = tune_model_params(\n",
    "                            study_name=Config.MODEL_TYPE + \"_ModelTuning\", \n",
    "                            study_direction=\"maximize\",\n",
    "                            num_trials=Config.NUM_TUNING_TRIALS,\n",
    "                            model_name=Config.MODEL_TYPE,\n",
    "                            preprocessor=preprocessor,\n",
    "                            df_train=df_train.sample(frac=0.1),\n",
    "                            feature_cols=feature_cols,\n",
    "                            metric=Config.METRIC,\n",
    "                            target_col_name=Config.TARGET_COL_NAME,\n",
    "                            single_fold=Config.TUNE_ON_SINGLE_FOLD,\n",
    "                            num_folds=Config.NUM_FOLDS\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = None\n",
    "params_static = model_static_params.get(Config.MODEL_TYPE)\n",
    "if params_static is not None and tuned_model_params is not None:\n",
    "    model_params = {**model_static_params[Config.MODEL_TYPE], **tuned_model_params}\n",
    "else:\n",
    "    model_params = tuned_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_params = model_static_params.get(Config.MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tt.get_model(model_name=Config.MODEL_TYPE, params=model_params, metric=Config.METRIC)\n",
    "model_pipeline = make_pipeline(preprocessor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist(model_name, fold_metrics_model, df_oof_preds, persist_model=False, output_path=\"\"):    \n",
    "    fold_models = [item[1] for item in fold_metrics_model]    \n",
    "    if persist_model:\n",
    "        for index, model in enumerate(fold_models):\n",
    "            fold_model_name = output_path + f\"{model_name}_{index}.joblib\"        \n",
    "            dump(model, fold_model_name)\n",
    "            print(f\"saved {fold_model_name}\")    \n",
    "    df_oof_preds.to_csv(output_path + f\"df_val_preds_{model_name}.csv\")\n",
    "    print(f\"Saved validation data predictions to df_val_preds_{model_name}.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Ridge - R2 : 0.865830794470718\n",
      "Fold 1 - Ridge - R2 : 0.866118455601935\n",
      "Fold 2 - Ridge - R2 : 0.8656391248908174\n",
      "Fold 3 - Ridge - R2 : 0.8658288329839805\n",
      "Fold 4 - Ridge - R2 : 0.8661879207998384\n",
      "Ridge metric=R2 CV score = 0.865921317765004\n",
      "Ridge Mean R2 = 0.8659210257494578, std = 0.00020313581581711044\n",
      "Saved validation data predictions to df_val_preds_Ridge.csv\n"
     ]
    }
   ],
   "source": [
    "fold_metrics_model, df_oof_preds = train_and_validate(\n",
    "                                        model_name=Config.MODEL_TYPE,\n",
    "                                        model=model_pipeline,\n",
    "                                        df=df_train,\n",
    "                                        feature_cols=feature_cols,\n",
    "                                        target_col_name=Config.TARGET_COL_NAME,\n",
    "                                        metric=Config.METRIC,\n",
    "                                        single_fold=Config.TRAIN_SINGLE_FOLD,\n",
    "                                        num_folds=Config.NUM_FOLDS\n",
    "                                    )\n",
    "\n",
    "persist(\n",
    "        model_name=Config.MODEL_TYPE, \n",
    "        fold_metrics_model=fold_metrics_model, \n",
    "        df_oof_preds=df_oof_preds, \n",
    "        persist_model=Config.PERSIST_MODEL, \n",
    "        output_path=DATA_WRITEPATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed prediction for 745305 test rows\n"
     ]
    }
   ],
   "source": [
    "# For each fold, get the test predictions using corresponding fold model\n",
    "df_fold_test_preds = tt.get_fold_test_preds(\n",
    "                        fold_metrics_model,\n",
    "                        df_test = df_test,\n",
    "                        feature_cols = feature_cols,\n",
    "                        num_folds = Config.NUM_FOLDS,\n",
    "                    )\n",
    "fold_metrics = [item[0] for item in fold_metrics_model]\n",
    "# Since for RMSLE metric lower is better, we take the inverse of fold metric value to get its weight    \n",
    "fold_weights = 1 / np.array(fold_metrics)\n",
    "# normalize the fold weights\n",
    "fold_weights = fold_weights / np.sum(fold_weights)\n",
    "# Combine fold predictions using simple averaging    \n",
    "df_fold_test_preds[\"test_preds\"] = tt.combine_fold_test_preds(df_fold_test_preds, fold_weights=None)\n",
    "print(f\"Completed prediction for {len(df_test)} test rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1117957</td>\n",
       "      <td>0.577364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117958</td>\n",
       "      <td>0.452056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1117959</td>\n",
       "      <td>0.451743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1117960</td>\n",
       "      <td>0.472565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117961</td>\n",
       "      <td>0.472270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  FloodProbability\n",
       "0  1117957          0.577364\n",
       "1  1117958          0.452056\n",
       "2  1117959          0.451743\n",
       "3  1117960          0.472565\n",
       "4  1117961          0.472270"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = pd.read_csv(SUBMISSION_FILEPATH + 'sample_submission.csv')\n",
    "df_submission[Config.TARGET_COL_NAME]= df_fold_test_preds[\"test_preds\"]\n",
    "df_submission.to_csv(DATA_WRITEPATH + f'submission_{Config.MODEL_TYPE}.csv',index=False)\n",
    "df_fold_test_preds.to_csv(DATA_WRITEPATH + f'{Config.MODEL_TYPE}_test_preds.csv',index=False)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.metrics import r2_score\n",
    "# from colorama import Fore, Style\n",
    "\n",
    "\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# SINGLE_FOLD = True\n",
    "\n",
    "# def cross_validate(model, train, label, features=feature_cols, n_repeats=1):\n",
    "#     \"\"\"Compute out-of-fold and test predictions for a given model.\n",
    "    \n",
    "#     Out-of-fold and test predictions are stored in the global variables\n",
    "#     oof and test_pred, respectively.\n",
    "    \n",
    "#     If n_repeats > 1, the model is trained several times with different seeds.\n",
    "#     \"\"\"\n",
    "#     start_time = datetime.datetime.now()\n",
    "#     scores = []\n",
    "#     oof_preds = np.full_like(train.FloodProbability, np.nan, dtype=float)\n",
    "#     for fold, (idx_tr, idx_va) in enumerate(kf.split(train)):\n",
    "#         X_tr = train.iloc[idx_tr][features]\n",
    "#         X_va = train.iloc[idx_va][features]\n",
    "#         y_tr = train.iloc[idx_tr].FloodProbability\n",
    "#         y_va = train.iloc[idx_va].FloodProbability\n",
    "        \n",
    "#         y_pred = np.zeros_like(y_va, dtype=float)\n",
    "#         for i in range(n_repeats):\n",
    "#             m = clone(model)\n",
    "#             if n_repeats > 1:\n",
    "#                 mm = m\n",
    "#                 if isinstance(mm, Pipeline):\n",
    "#                     mm = mm[-1]\n",
    "#                 mm.set_params(random_state=i)\n",
    "#             m.fit(X_tr, y_tr)\n",
    "#             y_pred += m.predict(X_va)\n",
    "#         y_pred /= n_repeats                \n",
    "#         score = r2_score(y_va, y_pred)\n",
    "#         print(f\"# Fold {fold}: R2={score:.5f}\")\n",
    "#         scores.append(score)\n",
    "#         oof_preds[idx_va] = y_pred\n",
    "#         if Config.TRAIN_SINGLE_FOLD: break\n",
    "            \n",
    "#     elapsed_time = datetime.datetime.now() - start_time\n",
    "#     print(f\"{Fore.GREEN}# Overall: {np.array(scores).mean():.5f} {label}\"\n",
    "#           f\"{' single fold' if SINGLE_FOLD else ''}\"\n",
    "#           f\"   {int(np.round(elapsed_time.total_seconds() / 60))} min{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_validate(model_pipeline, df_train, \"Ridge\", features=feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# r2_score(df_train.FloodProbability, (df_train[feature_cols_for_fe].sum(axis=1) * 0.0056) - 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
