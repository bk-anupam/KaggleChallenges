{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q openfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import statistics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures, SplineTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import clone\n",
    "from functools import partial\n",
    "from joblib import dump\n",
    "from scipy.stats import skew, kurtosis\n",
    "from openfe import OpenFE, transform\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"/home/bk_anupam/code/ML/ML_UTILS/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_tabular_utils as tt\n",
    "import cv_split_utils\n",
    "import enums\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RUN_MODE = \"LOCAL\"\n",
    "    RANDOM_SEED = 1\n",
    "    NUM_FOLDS = 5\n",
    "    TARGET_COL_NAME = \"FloodProbability\"        \n",
    "    SCALER = enums.Scaler.StandardScaler\n",
    "    METRIC = enums.Metrics.R2\n",
    "    # These values are more dynamic   \n",
    "    MODEL_TYPE = enums.ModelName.Ridge    \n",
    "    NUM_TUNING_TRIALS = 2\n",
    "    TUNE_ON_SINGLE_FOLD = True\n",
    "    TRAIN_SINGLE_FOLD = False\n",
    "    GENERATE_AUTO_FEATURES = False\n",
    "    PERSIST_MODEL = False\n",
    "    TRANSFORM_TARGET = False\n",
    "\n",
    "COLS_TO_LEAVE = [\"FloodProbability\", \"kfold\"]\n",
    "CPU_COUNT = os.cpu_count()\n",
    "\n",
    "DATA_READPATH = \"./data/\"\n",
    "DATA_WRITEPATH = \"./output/\"\n",
    "SUBMISSION_FILEPATH = DATA_READPATH\n",
    "if Config.RUN_MODE == \"KAGGLE\":\n",
    "    # If we are not generating features, we are using already generated features\n",
    "    if Config.GENERATE_AUTO_FEATURES:\n",
    "        DATA_READPATH = \"/kaggle/input/playground-series-s4e5/\"\n",
    "        SUBMISSION_FILEPATH = DATA_READPATH\n",
    "    else:\n",
    "        DATA_READPATH = \"/kaggle/input/playground-series-s4e5/\"\n",
    "        SUBMISSION_FILEPATH = \"/kaggle/input/playground-series-s4e5/\"\n",
    "    DATA_WRITEPATH = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_static_params = {\n",
    "    enums.ModelName.XGBoost: {\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"seed\": Config.RANDOM_SEED,\n",
    "        \"verbosity\": 0,\n",
    "    },\n",
    "    enums.ModelName.LGBM: {\n",
    "        \"objective\": \"root_mean_squared_error\",\n",
    "        \"metric\": 'rmse',\n",
    "        \"verbosity\": -1,    # <0: fatal, =0: error (warn), =1: info, >1: debug\n",
    "        \"boosting_type\": \"gbdt\"\n",
    "    },\n",
    "    enums.ModelName.CatBoost: {\n",
    "        \"objective\": \"RMSE\",\n",
    "        \"verbose\": 0,\n",
    "        \"random_seed\": Config.RANDOM_SEED,\n",
    "        \"eval_metric\": \"RMSE\",\n",
    "        'grow_policy':  'Lossguide',\n",
    "        'bootstrap_type': 'Poisson',\n",
    "        'task_type': 'GPU'\n",
    "    },\n",
    "    enums.ModelName.RandomForest: {\n",
    "        \"random_state\": Config.RANDOM_SEED,\n",
    "        \"n_jobs\": -1\n",
    "    },\n",
    "    enums.ModelName.Ridge: {\n",
    "        \"random_state\": Config.RANDOM_SEED\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train dataset locally from data folder\n",
    "df_train = pd.read_csv(DATA_READPATH + \"train.csv\", index_col='id')\n",
    "# import test dataset locally from data folder\n",
    "df_test = pd.read_csv(DATA_READPATH + \"test.csv\", index_col='id')\n",
    "# keep a copy of original train and test data for later use\n",
    "# df_train_orig = df_train.copy()\n",
    "# df_test_orig = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols_for_fe = df_test.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute skewness and kurtosis for each row\n",
    "def compute_skew_kurtosis(matrix):\n",
    "    skewness = skew(matrix, axis=1)\n",
    "    kurt = kurtosis(matrix, axis=1)\n",
    "    return skewness, kurt\n",
    "\n",
    "def create_features(df, feature_cols):\n",
    "    # Create a new feature by summing all features\n",
    "    df[\"f_sum\"] = df[feature_cols].sum(axis=1)\n",
    "    # Create a new feature by taking mean of all features\n",
    "    df[\"f_mean\"] = df[feature_cols].mean(axis=1)\n",
    "    df[\"f_median\"] = df[feature_cols].median(axis=1)\n",
    "    # standard deviation\n",
    "    df['f_std'] = df[feature_cols].std(axis=1)\n",
    "    # min and max\n",
    "    df['f_min'] = df[feature_cols].min(axis=1)\n",
    "    df['f_max'] = df[feature_cols].max(axis=1)\n",
    "    # Compute skewness and kurtosis\n",
    "    skewness, kurt = compute_skew_kurtosis(df[feature_cols].values)\n",
    "    df['f_skew'] = skewness\n",
    "    df['f_kurtosis'] = kurt    \n",
    "    # Quantiles\n",
    "    quantiles = [0.25, 0.5, 0.75]\n",
    "    for q in quantiles:\n",
    "        df[f'f_quantile_{int(q*100)}'] = df[feature_cols].quantile(q=q, axis=1)        \n",
    "    # sorted features\n",
    "    sorted_features = [f\"sort_{i}\" for i in np.arange(len(feature_cols))]\n",
    "    df[sorted_features] = np.sort(df[feature_cols], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = create_features(df_train, feature_cols_for_fe)\n",
    "df_test = create_features(df_test, feature_cols_for_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MonsoonIntensity</th>\n",
       "      <th>TopographyDrainage</th>\n",
       "      <th>RiverManagement</th>\n",
       "      <th>Deforestation</th>\n",
       "      <th>Urbanization</th>\n",
       "      <th>ClimateChange</th>\n",
       "      <th>DamsQuality</th>\n",
       "      <th>Siltation</th>\n",
       "      <th>AgriculturalPractices</th>\n",
       "      <th>Encroachments</th>\n",
       "      <th>...</th>\n",
       "      <th>sort_10</th>\n",
       "      <th>sort_11</th>\n",
       "      <th>sort_12</th>\n",
       "      <th>sort_13</th>\n",
       "      <th>sort_14</th>\n",
       "      <th>sort_15</th>\n",
       "      <th>sort_16</th>\n",
       "      <th>sort_17</th>\n",
       "      <th>sort_18</th>\n",
       "      <th>sort_19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
       "id                                                                         \n",
       "0                  5                   8                5              8   \n",
       "1                  6                   7                4              4   \n",
       "2                  6                   5                6              7   \n",
       "3                  3                   4                6              5   \n",
       "4                  5                   3                2              6   \n",
       "\n",
       "    Urbanization  ClimateChange  DamsQuality  Siltation  \\\n",
       "id                                                        \n",
       "0              6              4            4          3   \n",
       "1              8              8            3          5   \n",
       "2              3              7            1          5   \n",
       "3              4              8            4          7   \n",
       "4              4              4            3          3   \n",
       "\n",
       "    AgriculturalPractices  Encroachments  ...  sort_10  sort_11  sort_12  \\\n",
       "id                                        ...                              \n",
       "0                       3              4  ...        5        5        5   \n",
       "1                       4              6  ...        4        5        5   \n",
       "2                       4              5  ...        5        6        6   \n",
       "3                       6              8  ...        5        5        6   \n",
       "4                       3              3  ...        3        4        4   \n",
       "\n",
       "    sort_13  sort_14  sort_15  sort_16  sort_17  sort_18  sort_19  \n",
       "id                                                                 \n",
       "0         5        5        6        7        7        8        8  \n",
       "1         6        6        7        7        8        8        9  \n",
       "2         6        6        7        7        7        7        8  \n",
       "3         6        6        7        7        7        8        8  \n",
       "4         4        5        5        5        6        6        6  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(feature_cols)=51\n"
     ]
    }
   ],
   "source": [
    "feature_cols= [x for x in df_train.columns.to_list() if x not in COLS_TO_LEAVE]\n",
    "print(f\"len(feature_cols)={len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# get the unique values of f_sum from both df_test and df_train and combine them\n",
    "f_sum_categories = list(set(df_test['f_sum'].unique().tolist() + df_train['f_sum'].unique().tolist()))\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\", categories=[f_sum_categories])\n",
    "polynomial_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "spline_transformer = SplineTransformer(n_knots=5, degree=3, include_bias=False)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[        \n",
    "        #(\"poly\", polynomial_features, feature_cols),\n",
    "        (\"scaler\", scaler, feature_cols),\n",
    "        (\"onehot\", onehot_encoder, ['f_sum']),        \n",
    "    ], remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lgbm_tuning_params(trial):    \n",
    "    params_dynamic = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 2000, step=25),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 20),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 256, step=4),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 500, step=20)\n",
    "    }\n",
    "    return {**model_static_params[enums.ModelName.LGBM], **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catboost_tuning_params(trial):\n",
    "    params_dynamic = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 5000, step=50),\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 16),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "        # comment colsample_bylevel for GPU training\n",
    "        #'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 4, 256, step=4),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "        'random_strength': trial.suggest_loguniform('random_strength', 0.01, 10),\n",
    "        'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 50, 500, step=20),\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255)\n",
    "    }\n",
    "    return {**model_static_params[enums.ModelName.CatBoost], **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgb_tuning_params(trial):\n",
    "    params_dynamic = {            \n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 5000, step=100),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1.0, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 32),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1, 100),\n",
    "            'early_stopping_rounds': trial.suggest_int('early_stopping_rounds', 100, 500, step=20)\n",
    "        }\n",
    "    return {**model_static_params[enums.ModelName.XGBoost], **params_dynamic}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_tuning_params(trial, model_name):\n",
    "    if model_name == enums.ModelName.Ridge:\n",
    "        return {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-4, 1e4, log=True)\n",
    "        }\n",
    "    if model_name == enums.ModelName.Lasso:\n",
    "        return {\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-4, 1e4, log=True)\n",
    "        }\n",
    "    if model_name == enums.ModelName.RandomForest:\n",
    "        return {        \n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 400, 3000, step=100),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 10, 30),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 2, 16),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 16),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"log2\", \"sqrt\", None])\n",
    "        }\n",
    "    if model_name == enums.ModelName.CatBoost:\n",
    "        return get_catboost_tuning_params(trial)\n",
    "    if model_name == enums.ModelName.LGBM:\n",
    "        return get_lgbm_tuning_params(trial)\n",
    "    if model_name == enums.ModelName.XGBoost:\n",
    "        return get_xgb_tuning_params(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparams_tuning_objective(trial, model_name, preprocessor, df,  \n",
    "                                 feature_cols, metric, target_col_name, single_fold=False, num_folds=5):               \n",
    "    model_params = get_model_tuning_params(trial, model_name)    \n",
    "    fold_metrics_model, _, _ = tt.train_and_validate(\n",
    "                                        model_name=model_name,\n",
    "                                        model_params=model_params,\n",
    "                                        preprocessor=preprocessor,\n",
    "                                        df=df,\n",
    "                                        feature_cols=feature_cols,\n",
    "                                        target_col_name=target_col_name,\n",
    "                                        metric=metric,\n",
    "                                        single_fold=single_fold,\n",
    "                                        num_folds=num_folds\n",
    "                                    )\n",
    "    fold_metrics = [x[0] for x in fold_metrics_model]\n",
    "    mean_metric = statistics.mean(fold_metrics)                \n",
    "    return mean_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model_params(study_name, study_direction, num_trials, model_name, \n",
    "                      preprocessor, df,  feature_cols, metric, target_col_name, \n",
    "                      single_fold=False, num_folds=5):\n",
    "    model_params_tuning_obj_partial = partial(\n",
    "        hyperparams_tuning_objective,\n",
    "        model_name=model_name,        \n",
    "        preprocessor=preprocessor,        \n",
    "        df=df,\n",
    "        feature_cols=feature_cols,\n",
    "        metric=metric,\n",
    "        target_col_name=target_col_name,\n",
    "        single_fold=single_fold,\n",
    "        num_folds=num_folds\n",
    "    )\n",
    "    study = optuna.create_study(direction=study_direction, study_name=study_name)\n",
    "    study.optimize(model_params_tuning_obj_partial, n_trials=num_trials)\n",
    "    best_trial = study.best_trial\n",
    "    print(f\"Best trial: number = {best_trial.number}, value = {best_trial.value}, params = {best_trial.params}\")\n",
    "    return best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = cv_split_utils.kfold_dataframe(df_train, random_state=Config.RANDOM_SEED, num_folds=Config.NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-02 10:50:47,220] A new study created in memory with name: Ridge_ModelTuning\n",
      "[I 2024-06-02 10:50:52,234] Trial 0 finished with value: 0.8663109683842131 and parameters: {'alpha': 0.2161908864251729}. Best is trial 0 with value: 0.8663109683842131.\n",
      "[I 2024-06-02 10:50:56,415] Trial 1 finished with value: 0.8663092804578628 and parameters: {'alpha': 5.42130302074444}. Best is trial 0 with value: 0.8663109683842131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: number = 0, value = 0.8663109683842131, params = {'alpha': 0.2161908864251729}\n"
     ]
    }
   ],
   "source": [
    "if tuned_model_params is None:\n",
    "    #df = df_train.sample(frac=0.1, random_state=Config.RANDOM_SEED)\n",
    "    tuned_model_params = tune_model_params(\n",
    "                            study_name=Config.MODEL_TYPE + \"_ModelTuning\", \n",
    "                            study_direction=\"maximize\",\n",
    "                            num_trials=Config.NUM_TUNING_TRIALS,\n",
    "                            model_name=Config.MODEL_TYPE,\n",
    "                            preprocessor=preprocessor,\n",
    "                            df=df_train,\n",
    "                            feature_cols=feature_cols,\n",
    "                            metric=Config.METRIC,\n",
    "                            target_col_name=Config.TARGET_COL_NAME,\n",
    "                            single_fold=Config.TUNE_ON_SINGLE_FOLD,\n",
    "                            num_folds=Config.NUM_FOLDS\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = None\n",
    "params_static = model_static_params.get(Config.MODEL_TYPE)\n",
    "if params_static is not None and tuned_model_params is not None:\n",
    "    model_params = {**model_static_params[Config.MODEL_TYPE], **tuned_model_params}\n",
    "else:\n",
    "    model_params = tuned_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_metrics_model, df_oof_preds, preprocessor = tt.train_and_validate(\n",
    "        model_name=Config.MODEL_TYPE,\n",
    "        model_params=model_params,\n",
    "        preprocessor=preprocessor,\n",
    "        df=df_train,\n",
    "        feature_cols=feature_cols,\n",
    "        target_col_name=Config.TARGET_COL_NAME,\n",
    "        metric=Config.METRIC,\n",
    "        single_fold=Config.TRAIN_SINGLE_FOLD,\n",
    "        num_folds=Config.NUM_FOLDS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Ridge - R2 : 0.8663109683842131\n",
      "Fold 1 - Ridge - R2 : 0.8655179242641292\n",
      "Fold 2 - Ridge - R2 : 0.8653059675122239\n",
      "Fold 3 - Ridge - R2 : 0.8662265930701474\n",
      "Fold 4 - Ridge - R2 : 0.8664321028086825\n",
      "Ridge metric=R2 CV score = 0.8659591406986992\n",
      "Ridge Mean R2 = 0.8659587112078793, std = 0.0004561387683853116\n",
      "Saved validation data predictions to df_val_preds_Ridge.csv\n"
     ]
    }
   ],
   "source": [
    "tt.get_cv_score(\n",
    "        fold_metrics_model, \n",
    "        model_name=Config.MODEL_TYPE, \n",
    "        metric=Config.METRIC, \n",
    "        df_oof_preds=df_oof_preds, \n",
    "        target_col_name=Config.TARGET_COL_NAME\n",
    ")\n",
    "\n",
    "tt.persist(\n",
    "        model_name=Config.MODEL_TYPE, \n",
    "        fold_metrics_model=fold_metrics_model, \n",
    "        df_oof_preds=df_oof_preds, \n",
    "        persist_model=Config.PERSIST_MODEL, \n",
    "        output_path=DATA_WRITEPATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed prediction for 745305 test rows\n"
     ]
    }
   ],
   "source": [
    "df_fold_test_preds = tt.get_test_preds(fold_metrics_model, df_test, feature_cols, preprocessor=preprocessor, num_folds=Config.NUM_FOLDS)\n",
    "print(f\"Completed prediction for {len(df_test)} test rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1117957</td>\n",
       "      <td>0.577694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117958</td>\n",
       "      <td>0.451447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1117959</td>\n",
       "      <td>0.451814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1117960</td>\n",
       "      <td>0.472121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117961</td>\n",
       "      <td>0.472754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  FloodProbability\n",
       "0  1117957          0.577694\n",
       "1  1117958          0.451447\n",
       "2  1117959          0.451814\n",
       "3  1117960          0.472121\n",
       "4  1117961          0.472754"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = pd.read_csv(SUBMISSION_FILEPATH + 'sample_submission.csv')\n",
    "df_submission[Config.TARGET_COL_NAME]= df_fold_test_preds[\"test_preds\"]\n",
    "df_submission.to_csv(DATA_WRITEPATH + f'submission_{Config.MODEL_TYPE}.csv',index=False)\n",
    "df_fold_test_preds.to_csv(DATA_WRITEPATH + f'{Config.MODEL_TYPE}_test_preds.csv',index=False)\n",
    "df_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
