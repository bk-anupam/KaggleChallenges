{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder #, TargetEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from category_encoders import TargetEncoder\n",
    "# from category_encoders.wrapper import PolynomialWrapper\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelType:\n",
    "    LGBM = \"LGBM\"\n",
    "    XGB = \"XGB\"\n",
    "    RF = \"RF\"\n",
    "    LR = \"LR\"\n",
    "    CATBOOST = \"CATBOOST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    RANDOM_SEED = 42\n",
    "    NUM_FOLDS = 5\n",
    "    TARGET_COL_NAME = \"outcome\"    \n",
    "    EARLY_STOPPING = 500\n",
    "    RESULTS_FILE = \"model_execution_results.pkl\"\n",
    "    MODEL_TYPE = ModelType.RF\n",
    "\n",
    "DATA_PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "df_test = pd.read_csv(DATA_PATH + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>surgery</th>\n",
       "      <th>age</th>\n",
       "      <th>hospital_number</th>\n",
       "      <th>rectal_temp</th>\n",
       "      <th>pulse</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>temp_of_extremities</th>\n",
       "      <th>peripheral_pulse</th>\n",
       "      <th>mucous_membrane</th>\n",
       "      <th>...</th>\n",
       "      <th>total_protein</th>\n",
       "      <th>abdomo_appearance</th>\n",
       "      <th>abdomo_protein</th>\n",
       "      <th>surgical_lesion</th>\n",
       "      <th>lesion_1</th>\n",
       "      <th>lesion_2</th>\n",
       "      <th>lesion_3</th>\n",
       "      <th>cp_data</th>\n",
       "      <th>outcome</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>753</td>\n",
       "      <td>no</td>\n",
       "      <td>adult</td>\n",
       "      <td>535381</td>\n",
       "      <td>39.4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>pale_pink</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>euthanized</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582</td>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>535029</td>\n",
       "      <td>37.5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>cold</td>\n",
       "      <td>normal</td>\n",
       "      <td>bright_pink</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>serosanguious</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>4205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>euthanized</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>548</td>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>529461</td>\n",
       "      <td>38.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>cool</td>\n",
       "      <td>reduced</td>\n",
       "      <td>bright_red</td>\n",
       "      <td>...</td>\n",
       "      <td>8.6</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>4.3</td>\n",
       "      <td>yes</td>\n",
       "      <td>2112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>died</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113</td>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>534157</td>\n",
       "      <td>38.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>cool</td>\n",
       "      <td>reduced</td>\n",
       "      <td>pale_pink</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>serosanguious</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>euthanized</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174</td>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>529777</td>\n",
       "      <td>38.9</td>\n",
       "      <td>40.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>pale_pink</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>clear</td>\n",
       "      <td>5.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>2206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>lived</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id surgery    age  hospital_number  rectal_temp  pulse  respiratory_rate  \\\n",
       "0  753      no  adult           535381         39.4   86.0              21.0   \n",
       "1  582     yes  adult           535029         37.5  112.0              12.0   \n",
       "2  548     yes  adult           529461         38.5   72.0              44.0   \n",
       "3  113     yes  adult           534157         38.4   40.0              16.0   \n",
       "4  174     yes  adult           529777         38.9   40.0              24.0   \n",
       "\n",
       "  temp_of_extremities peripheral_pulse mucous_membrane  ... total_protein  \\\n",
       "0              normal           normal       pale_pink  ...          75.0   \n",
       "1                cold           normal     bright_pink  ...          57.0   \n",
       "2                cool          reduced      bright_red  ...           8.6   \n",
       "3                cool          reduced       pale_pink  ...          77.0   \n",
       "4              normal           normal       pale_pink  ...           6.0   \n",
       "\n",
       "  abdomo_appearance abdomo_protein surgical_lesion lesion_1 lesion_2  \\\n",
       "0            cloudy            2.0             yes     3205        0   \n",
       "1     serosanguious            2.0             yes     4205        0   \n",
       "2            cloudy            4.3             yes     2112        0   \n",
       "3     serosanguious            2.0             yes     2209        0   \n",
       "4             clear            5.4             yes     2206        0   \n",
       "\n",
       "   lesion_3 cp_data     outcome  kfold  \n",
       "0         0      no  euthanized      3  \n",
       "1         0      no  euthanized      0  \n",
       "2         0     yes        died      1  \n",
       "3         0      no  euthanized      3  \n",
       "4         0     yes       lived      1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the training dataframe into kfolds for cross validation. We do this before any processing is done\n",
    "# on the data. We use stratified kfold if the target distribution is unbalanced\n",
    "def strat_kfold_dataframe(df, target_col_name, num_folds=5):\n",
    "    # we create a new column called kfold and fill it with -1\n",
    "    df[\"kfold\"] = -1\n",
    "    # randomize of shuffle the rows of dataframe before splitting is done\n",
    "    df = df.sample(frac=1, random_state=Config.RANDOM_SEED).reset_index(drop=True)\n",
    "    # get the target data\n",
    "    y = df[target_col_name].values\n",
    "    skf = model_selection.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=Config.RANDOM_SEED)\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X=df, y=y)):\n",
    "        df.loc[val_index, \"kfold\"] = fold    \n",
    "    return df     \n",
    "\n",
    "df_train = strat_kfold_dataframe(df_train, target_col_name=Config.TARGET_COL_NAME, num_folds=Config.NUM_FOLDS)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     17\n",
       "float64     7\n",
       "int64       6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the count of each column type\n",
    "df_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_float = df_train.select_dtypes(include=[\"float\"]).columns.to_list()\n",
    "cols_int = df_train.select_dtypes(include=[\"int64\"]).columns.to_list()\n",
    "cols_str = df_train.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "# remove target \"outcome\" from the list cols_str\n",
    "cols_str.remove(Config.TARGET_COL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rectal_temp', 'pulse', 'respiratory_rate', 'nasogastric_reflux_ph', 'packed_cell_volume', 'total_protein', 'abdomo_protein']\n"
     ]
    }
   ],
   "source": [
    "print(cols_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['surgery', 'age', 'temp_of_extremities', 'peripheral_pulse', 'mucous_membrane']\n",
      "['capillary_refill_time', 'pain', 'peristalsis', 'abdominal_distention', 'nasogastric_tube']\n",
      "['nasogastric_reflux', 'rectal_exam_feces', 'abdomen', 'abdomo_appearance', 'surgical_lesion']\n",
      "['cp_data']\n"
     ]
    }
   ],
   "source": [
    "# print the list cols_str with 5 words per line\n",
    "def print_list_cols(cols_str):\n",
    "    for i in range(0, len(cols_str), 5):\n",
    "        print(cols_str[i:i+5])\n",
    "\n",
    "print_list_cols(cols_str)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each categorical feature, calculate distinct categories and their counts\n",
    "def get_category_summary(df):\n",
    "    # Initialize an empty DataFrame to store the results\n",
    "    category_summary = pd.DataFrame(columns=['Feature', 'Distinct_Categories', 'Category_Count'])\n",
    "    # Loop through columns to identify categorical features\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            # For categorical features, calculate distinct categories and their counts        \n",
    "            cat_val_cnt = df[column].value_counts()        \n",
    "            # create a dataframe for this specific categorical feature, distinct categories and their count\n",
    "            cat_feature_df = pd.DataFrame(data={\n",
    "                'Feature': [column] * len(cat_val_cnt),\n",
    "                'Distinct_Categories': cat_val_cnt.index.values.tolist(), \n",
    "                'Category_Count': cat_val_cnt.values.tolist()\n",
    "            })\n",
    "            # Append the results to the categorsummary DataFrame\n",
    "            category_summary= category_summary.append(cat_feature_df)\n",
    "    \n",
    "    category_summary = category_summary.reset_index(drop=True)\n",
    "    return category_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories_train = get_category_summary(df_train)\n",
    "df_categories_test = get_category_summary(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat_notin_test = df_categories_train[[\"Feature\", \"Distinct_Categories\"]].merge(\n",
    "                            df_categories_test[[\"Feature\", \"Distinct_Categories\"]], \n",
    "                            on=['Feature', 'Distinct_Categories'], \n",
    "                            how='left', \n",
    "                            indicator=True\n",
    "                        ).query('_merge == \"left_only\"')\n",
    "\n",
    "train_cat_notin_test = df_categories_train.merge(\n",
    "                            df_categories_test, \n",
    "                            on=['Feature', 'Distinct_Categories'], \n",
    "                            how='left', \n",
    "                            indicator=True\n",
    "                        ).query('_merge == \"left_only\"')\n",
    "\n",
    "# Find rows present in df2 but missing in df1\n",
    "test_cat_notin_train = df_categories_test[[\"Feature\", \"Distinct_Categories\"]].merge(\n",
    "                            df_categories_train[[\"Feature\", \"Distinct_Categories\"]], \n",
    "                            on=['Feature', 'Distinct_Categories'], \n",
    "                            how='left', \n",
    "                            indicator=True\n",
    "                        ).query('_merge == \"left_only\"')\n",
    "\n",
    "# # Drop the '_merge' column and reset the index\n",
    "train_cat_notin_test = train_cat_notin_test.drop(columns=['_merge']).reset_index(drop=True)\n",
    "test_cat_notin_train = test_cat_notin_train.drop(columns=['_merge']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Distinct_Categories</th>\n",
       "      <th>Category_Count_x</th>\n",
       "      <th>Category_Count_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pain</td>\n",
       "      <td>slight</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peristalsis</td>\n",
       "      <td>distend_small</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nasogastric_reflux</td>\n",
       "      <td>slight</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rectal_exam_feces</td>\n",
       "      <td>serosanguious</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outcome</td>\n",
       "      <td>lived</td>\n",
       "      <td>574</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>outcome</td>\n",
       "      <td>died</td>\n",
       "      <td>410</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>outcome</td>\n",
       "      <td>euthanized</td>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature Distinct_Categories Category_Count_x Category_Count_y\n",
       "0                pain              slight                1              NaN\n",
       "1         peristalsis       distend_small                1              NaN\n",
       "2  nasogastric_reflux              slight                1              NaN\n",
       "3   rectal_exam_feces       serosanguious                1              NaN\n",
       "4             outcome               lived              574              NaN\n",
       "5             outcome                died              410              NaN\n",
       "6             outcome          euthanized              251              NaN"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cat_notin_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Distinct_Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pain</td>\n",
       "      <td>moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature Distinct_Categories\n",
       "0    pain            moderate"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cat_notin_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the row from test which has category not present in train\n",
    "# df_test = df_test.drop(df_test[df_test.pain == \"moderate\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(col_names)=27\n",
      "len(cont_col_names)=7, len(cat_col_names)=16, len(noncont_col_names)=20\n"
     ]
    }
   ],
   "source": [
    "cols_to_leave = [\"id\", \"kfold\", Config.TARGET_COL_NAME, Config.TARGET_COL_NAME + \"_encoded\"]\n",
    "col_names = [item for item in df_train.columns.values.tolist() if item not in cols_to_leave]\n",
    "print(f\"len(col_names)={len(col_names)}\")        \n",
    "# get all columns from df_train that are not of type float\n",
    "noncont_col_names = [item for item in col_names if item not in cols_float]\n",
    "cont_col_names = [item for item in cols_float if item not in cols_to_leave]\n",
    "cat_col_names = [item for item in cols_str if item not in cols_to_leave]\n",
    "print(f\"len(cont_col_names)={len(cont_col_names)}, len(cat_col_names)={len(cat_col_names)}, len(noncont_col_names)={len(noncont_col_names)}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Categorical Columns using different strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use one hot encoding for categorical columns using pandas get_dummies\n",
    "# # since some of the categories are missing for some categorical features in test data we combine both test and train befor\n",
    "# # doing one hot encoding\n",
    "# df_combined = pd.concat([df_train, df_test])\n",
    "# df_combined = pd.get_dummies(df_combined, prefix=cols_str, columns=cols_str)\n",
    "# df_train = df_combined[:len(df_train)]\n",
    "# df_test = df_combined[len(df_train):]\n",
    "# print(f\"len(df_combined.columns)={len(df_combined.columns)}\")\n",
    "# print(f\"len(df_train.columns)={len(df_train.columns)}\")\n",
    "# print(f\"len(df_test.columns)={len(df_train.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding of categorical columns using sklearn OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_train.shape = (1235, 72)\n",
      "encoded_test.shape = (824, 72)\n"
     ]
    }
   ],
   "source": [
    "one_hot_enc = OneHotEncoder(handle_unknown=\"infrequent_if_exist\", sparse=False, min_frequency=5)\n",
    "one_hot_enc = one_hot_enc.fit(df_train[cat_col_names])\n",
    "encoded_train = one_hot_enc.transform(df_train[cat_col_names])\n",
    "encoded_test = one_hot_enc.transform(df_test[cat_col_names])\n",
    "print(f\"encoded_train.shape = {encoded_train.shape}\")\n",
    "print(f\"encoded_test.shape = {encoded_test.shape}\")\n",
    "df_train.drop(columns=cat_col_names, inplace=True)\n",
    "df_test.drop(columns=cat_col_names, inplace=True)\n",
    "# drop the categorical columns from df_train\n",
    "df_train_oh = pd.DataFrame(encoded_train, columns=one_hot_enc.get_feature_names_out())\n",
    "df_test_oh = pd.DataFrame(encoded_test, columns=one_hot_enc.get_feature_names_out())\n",
    "# append the one hot encoded data to df_train\n",
    "df_train_processed = pd.concat([df_train, df_train_oh], axis=1)\n",
    "df_test_processed = pd.concat([df_test, df_test_oh], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_train.columns) = 14\n",
      "len(df_test.columns) = 12\n",
      "len(df_test_processed.columns) = 84\n",
      "len(df_train_processed.columns) = 86\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(df_train.columns) = {len(df_train.columns)}\")\n",
    "print(f\"len(df_test.columns) = {len(df_test.columns)}\")\n",
    "print(f\"len(df_test_processed.columns) = {len(df_test_processed.columns)}\")\n",
    "print(f\"len(df_train_processed.columns) = {len(df_train_processed.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Encoding of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target\n",
    "label_encoder = LabelEncoder()\n",
    "target_encoded = label_encoder.fit_transform(df_train[Config.TARGET_COL_NAME])\n",
    "# add the target_encoded as a new column to the dataframe\n",
    "# df_train[Config.TARGET_COL_NAME + \"_encoded\"] = target_encoded\n",
    "df_train_processed[Config.TARGET_COL_NAME + \"_encoded\"] = target_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Target encoding of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from category_encoders import TargetEncoder\n",
    "# from category_encoders.wrapper import PolynomialWrapper\n",
    "\n",
    "# # This target encoder acts on either binary or a continuous target\n",
    "# base_target_encoder = TargetEncoder(cols=cat_col_names, handle_unknown=\"return_nan\", handle_missing=\"return_nan\")\n",
    "# # This is a wrapper to be used for target encoding in case of multiclass target\n",
    "# target_encoder = PolynomialWrapper(base_target_encoder)\n",
    "# encoded = target_encoder.fit_transform(df_train.loc[:, cat_col_names], df_train.loc[:, Config.TARGET_COL_NAME+\"_encoded\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outcome_proba_died', 'outcome_proba_euthanized', 'outcome_proba_lived']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_proba_cols = [Config.TARGET_COL_NAME + \"_proba_\" + tgt_cls for tgt_cls in label_encoder.classes_]\n",
    "tgt_proba_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df, cont_col_names, cols_to_leave):\n",
    "    # normalize continuous features\n",
    "    scaler = StandardScaler()\n",
    "    X_cont = df[cont_col_names]    \n",
    "    X_cont_scaled = scaler.fit_transform(X_cont)     \n",
    "    # get the columns other than continuous features\n",
    "    other_col_names = [item for item in df.columns.values.tolist() if item not in cont_col_names + cols_to_leave]\n",
    "    # combine the normalized continuous features with others\n",
    "    X_processed = np.concatenate([X_cont_scaled, df[other_col_names]], axis=1)    \n",
    "    return X_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_data(fold, df, cont_col_names, cols_to_leave, target_col_name):\n",
    "    df_train = df[df.kfold != fold]\n",
    "    df_val = df[df.kfold == fold]\n",
    "    # normalize the data\n",
    "    X_train = normalize_data(df_train, cont_col_names, cols_to_leave)\n",
    "    X_val = normalize_data(df_val, cont_col_names, cols_to_leave)\n",
    "    y_train = df_train[target_col_name]\n",
    "    y_val = df_val[target_col_name]\n",
    "    return X_train, y_train, X_val, y_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_params, model_type):\n",
    "    model = None\n",
    "    if model_type == ModelType.LR:\n",
    "        model = LogisticRegression(\n",
    "            random_state=Config.RANDOM_SEED,\n",
    "            n_jobs=-1, \n",
    "            solver=model_params[\"solver\"],         \n",
    "            max_iter=model_params[\"max_iter\"], \n",
    "            multi_class=model_params[\"multi_class\"],\n",
    "            C=model_params[\"C\"],\n",
    "            penalty=model_params[\"penalty\"]\n",
    "        )\n",
    "    elif model_type == ModelType.RF:\n",
    "        model = RandomForestClassifier(\n",
    "                    n_estimators=model_params[\"n_estimators\"],                 \n",
    "                    max_depth=model_params[\"max_depth\"],\n",
    "                    min_samples_leaf=model_params[\"min_samples_leaf\"],\n",
    "                    min_samples_split=model_params[\"min_samples_split\"],\n",
    "                    max_features=model_params[\"max_features\"],\n",
    "                    random_state=Config.RANDOM_SEED,\n",
    "                    n_jobs=-1\n",
    "                )     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, train_X, train_y, val_X, val_y):    \n",
    "    model.fit(train_X, train_y.ravel())\n",
    "    val_y_pred = model.predict(val_X)\n",
    "    val_y_proba = model.predict_proba(val_X)\n",
    "    f1 = f1_score(val_y, val_y_pred, average=\"micro\")\n",
    "    return f1, model, val_y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_tuning_params(trial, model_type):\n",
    "    if model_type == ModelType.LR:\n",
    "        return {\n",
    "            \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"saga\"]),\n",
    "            \"C\": trial.suggest_loguniform(\"C\", low=0.001, high=1000.0),\n",
    "            \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]),\n",
    "            \"max_iter\": trial.suggest_categorical(\"max_iter\", [100, 200, 500, 1000]),\n",
    "            \"multi_class\": trial.suggest_categorical(\"multi_class\", [\"auto\", \"ovr\"])\n",
    "        }\n",
    "    elif model_type == ModelType.RF:\n",
    "        return {        \n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 4, 32),\n",
    "            \"min_samples_leaf\": trial.suggest_categorical(\"min_samples_leaf\", [1, 2, 4]),\n",
    "            \"min_samples_split\": trial.suggest_categorical(\"min_samples_split\", [2, 4, 8]),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import statistics\n",
    "\n",
    "def rf_objective(trial):       \n",
    "    params = get_model_tuning_params(trial, ModelType.LR)\n",
    "    model = create_model(params, ModelType.LR)\n",
    "    fold_f1 = []\n",
    "    for fold in range(Config.NUM_FOLDS):\n",
    "        train_X, train_y, val_X, val_y = get_fold_data(\n",
    "                                            fold=fold, \n",
    "                                            df=df_train_processed, \n",
    "                                            cont_col_names=cont_col_names, \n",
    "                                            cols_to_leave=cols_to_leave,\n",
    "                                            target_col_name=Config.TARGET_COL_NAME+\"_encoded\"\n",
    "                                        )\n",
    "        f1, _, _ = run_training(model, train_X, train_y, val_X, val_y)\n",
    "        fold_f1.append(f1)\n",
    "    mean_f1 = statistics.mean(fold_f1)                \n",
    "    return mean_f1\n",
    "\n",
    "# study = optuna.create_study(direction=\"maximize\", study_name=\"RFModelTuning\")    \n",
    "# study.optimize(rf_objective, n_trials=20)\n",
    "# print(\"Best trial:\")\n",
    "# print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RandomizedSearchCV trials reveal that l1 penalty gives the best f1 score, \n",
    "# # but l1 penalty works with liblinear solver\n",
    "\n",
    "# lr_model_params = {\n",
    "#     \"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 500.0, 1000.0],\n",
    "#     \"penalty\": [\"l1\", \"l2\"],\n",
    "#     \"max_iter\": [100, 200, 500, 1000],\n",
    "#     \"multi_class\": [\"auto\", \"ovr\", \"multinomial\"]\n",
    "# }\n",
    "# # Create the Logistic Regression model\n",
    "# lr_model = LogisticRegression(    \n",
    "#     n_jobs=-1, \n",
    "#     random_state=Config.RANDOM_SEED,\n",
    "#     solver=\"liblinear\",\n",
    "# )\n",
    "# random_search_cv = model_selection.RandomizedSearchCV(\n",
    "#     estimator=lr_model,\n",
    "#     param_distributions=lr_model_params,\n",
    "#     scoring=\"f1_micro\",\n",
    "#     n_jobs=-1    \n",
    "# )    \n",
    "# X_train = normalize_data(df_train_processed, cont_col_names, cols_to_leave)\n",
    "# y_train = df_train_processed[Config.TARGET_COL_NAME+\"_encoded\"]\n",
    "# random_search_cv.fit(X_train, y_train)\n",
    "# print(f\"best params = {random_search_cv.best_params_}\")\n",
    "# print(f\"best score = {random_search_cv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 f1 score = 0.708502024291498\n",
      "fold 1 f1 score = 0.757085020242915\n",
      "fold 2 f1 score = 0.7246963562753036\n",
      "fold 3 f1 score = 0.6963562753036437\n",
      "fold 4 f1 score = 0.7004048582995951\n"
     ]
    }
   ],
   "source": [
    "fold_metrics_model = []\n",
    "test_preds = {}\n",
    "lr_params = {'C': 1.0, 'penalty': 'l1', 'max_iter': 200, 'multi_class': 'ovr', 'solver': 'liblinear'}\n",
    "rf_params = {'n_estimators': 299, 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 4, 'max_features': 'log2'}\n",
    "model = create_model(rf_params, ModelType.RF)\n",
    "\n",
    "for fold in range(Config.NUM_FOLDS):\n",
    "    X_train, y_train, X_val, y_val = get_fold_data(\n",
    "        fold=fold, \n",
    "        df=df_train_processed, \n",
    "        cont_col_names=cont_col_names, \n",
    "        cols_to_leave=cols_to_leave,\n",
    "        target_col_name=Config.TARGET_COL_NAME+\"_encoded\"\n",
    "    )\n",
    "    fold_f1_score, model, fold_val_pred_proba = run_training(model, X_train, y_train, X_val, y_val)\n",
    "    print(f\"fold {fold } f1 score = {fold_f1_score}\")    \n",
    "    # add the validation probability predictions for the fold to a new column in train data\n",
    "    df_train.loc[df_train.kfold == fold, tgt_proba_cols] = fold_val_pred_proba    \n",
    "    X_test = normalize_data(df_test_processed, cont_col_names, cols_to_leave)\n",
    "    fold_test_preds = model.predict(X_test)\n",
    "    pred_col_name = f\"fold_{fold}_test_preds\"\n",
    "    test_preds[pred_col_name] = fold_test_preds    \n",
    "    fold_metrics_model.append((round(fold_f1_score, 4), model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rf_clf.feature_importances_) = 83\n",
      "len(df_train_processed.columns) = 87\n",
      "len(feature_names) = 83\n"
     ]
    }
   ],
   "source": [
    "rf_clf = fold_metrics_model[0][1]\n",
    "# get the columns other than continuous features\n",
    "other_col_names = [item for item in df_train_processed.columns.values.tolist() if item not in cont_col_names + cols_to_leave]\n",
    "feature_names = cont_col_names + other_col_names\n",
    "print(f\"len(rf_clf.feature_importances_) = {len(rf_clf.feature_importances_)}\")\n",
    "print(f\"len(df_train_processed.columns) = {len(df_train_processed.columns)}\")\n",
    "print(f\"len(feature_names) = {len(feature_names)}\")\n",
    "feature_importances = pd.Series(rf_clf.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "#feature_importances.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_protein                               0.069035\n",
      "pulse                                       0.066725\n",
      "abdomo_protein                              0.064298\n",
      "hospital_number                             0.058183\n",
      "packed_cell_volume                          0.056347\n",
      "nasogastric_reflux_ph                       0.054488\n",
      "lesion_1                                    0.042332\n",
      "respiratory_rate                            0.035764\n",
      "rectal_temp                                 0.034385\n",
      "pain_mild_pain                              0.024885\n",
      "abdomo_appearance_serosanguious             0.021804\n",
      "surgical_lesion_no                          0.017346\n",
      "peripheral_pulse_normal                     0.017052\n",
      "pain_severe_pain                            0.016649\n",
      "mucous_membrane_normal_pink                 0.015959\n",
      "peripheral_pulse_reduced                    0.015197\n",
      "surgical_lesion_yes                         0.015142\n",
      "capillary_refill_time_more_3_sec            0.014961\n",
      "rectal_exam_feces_absent                    0.013529\n",
      "capillary_refill_time_less_3_sec            0.013502\n",
      "abdomo_appearance_clear                     0.012808\n",
      "cp_data_yes                                 0.012791\n",
      "temp_of_extremities_normal                  0.012096\n",
      "rectal_exam_feces_None                      0.011743\n",
      "cp_data_no                                  0.011471\n",
      "abdominal_distention_moderate               0.011313\n",
      "nasogastric_reflux_more_1_liter             0.011263\n",
      "surgery_yes                                 0.011138\n",
      "surgery_no                                  0.010951\n",
      "pain_extreme_pain                           0.010742\n",
      "temp_of_extremities_cool                    0.010645\n",
      "nasogastric_tube_slight                     0.010604\n",
      "peristalsis_absent                          0.010494\n",
      "pain_depressed                              0.009376\n",
      "abdomen_distend_small                       0.009183\n",
      "peristalsis_hypomotile                      0.009044\n",
      "abdomen_distend_large                       0.008896\n",
      "mucous_membrane_pale_pink                   0.008850\n",
      "abdominal_distention_slight                 0.008649\n",
      "mucous_membrane_bright_red                  0.008452\n",
      "mucous_membrane_pale_cyanotic               0.008342\n",
      "nasogastric_reflux_none                     0.007989\n",
      "pain_alert                                  0.007672\n",
      "abdomen_None                                0.006879\n",
      "abdomo_appearance_cloudy                    0.006851\n",
      "rectal_exam_feces_decreased                 0.006657\n",
      "nasogastric_reflux_less_1_liter             0.006134\n",
      "abdominal_distention_severe                 0.006076\n",
      "nasogastric_tube_none                       0.005800\n",
      "abdominal_distention_none                   0.005795\n",
      "rectal_exam_feces_normal                    0.005534\n",
      "mucous_membrane_dark_cyanotic               0.004594\n",
      "age_adult                                   0.004457\n",
      "age_young                                   0.004272\n",
      "temp_of_extremities_cold                    0.004151\n",
      "nasogastric_tube_None                       0.004028\n",
      "nasogastric_tube_significant                0.003700\n",
      "peripheral_pulse_None                       0.002723\n",
      "mucous_membrane_bright_pink                 0.002444\n",
      "abdomen_normal                              0.001915\n",
      "abdomo_appearance_None                      0.001863\n",
      "abdomen_firm                                0.001836\n",
      "pain_None                                   0.001706\n",
      "peristalsis_normal                          0.001686\n",
      "temp_of_extremities_None                    0.001589\n",
      "abdominal_distention_None                   0.001438\n",
      "temp_of_extremities_warm                    0.001276\n",
      "rectal_exam_feces_increased                 0.001219\n",
      "abdomen_other                               0.000848\n",
      "peristalsis_hypermotile                     0.000606\n",
      "peripheral_pulse_absent                     0.000603\n",
      "mucous_membrane_None                        0.000540\n",
      "peristalsis_None                            0.000423\n",
      "nasogastric_reflux_None                     0.000152\n",
      "lesion_2                                    0.000060\n",
      "capillary_refill_time_None                  0.000047\n",
      "capillary_refill_time_infrequent_sklearn    0.000003\n",
      "lesion_3                                    0.000000\n",
      "rectal_exam_feces_infrequent_sklearn        0.000000\n",
      "peripheral_pulse_infrequent_sklearn         0.000000\n",
      "pain_infrequent_sklearn                     0.000000\n",
      "nasogastric_reflux_infrequent_sklearn       0.000000\n",
      "peristalsis_infrequent_sklearn              0.000000\n"
     ]
    }
   ],
   "source": [
    "print(feature_importances.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With OneHotEncoder\n",
    "\n",
    "model_params = {'C': 1.0, 'penalty': 'l1', 'max_iter': 200, 'multi_class': 'ovr', 'solver': 'liblinear'} \\\n",
    "fold 0 f1 score = 0.6518218623481782 \\\n",
    "fold 1 f1 score = 0.7206477732793523 \\\n",
    "fold 2 f1 score = 0.6923076923076923 \\\n",
    "fold 3 f1 score = 0.6761133603238867 \\\n",
    "fold 4 f1 score = 0.6842105263157895 \n",
    "\n",
    "Best trial:\n",
    "{'solver': 'liblinear', 'C': 0.3344158923659617, 'penalty': 'l1', 'max_iter': 200, 'multi_class': 'ovr'}\n",
    "best score = 0.6939271255060728\n",
    "\n",
    "Random Forest \\\n",
    "Best trial:\n",
    "{'n_estimators': 299, 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 4, 'max_features': 'log2'} \\\n",
    "best score = 0.7174089068825911"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
