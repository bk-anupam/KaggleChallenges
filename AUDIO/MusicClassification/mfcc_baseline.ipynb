{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display as ipd\n",
    "from glob import glob\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import librosa.display\n",
    "import skimage.io\n",
    "import os\n",
    "import torch\n",
    "from sklearn import model_selection\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(\n",
    "    filename=\"./logs/info.log\", \n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s: %(levelname)s: %(message)s', \n",
    "    datefmt='%m/%d/%Y %I:%M:%S %p'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    NUM_CLASSES = 5\n",
    "    NUM_MFCC = 40\n",
    "    BATCH_SIZE = 256\n",
    "    NUM_FOLDS = 5\n",
    "    UNFREEZE_EPOCH_NO = 1\n",
    "    NUM_EPOCHS = 10\n",
    "    NUM_WORKERS = 8    \n",
    "    FAST_DEV_RUN = False\n",
    "    PRECISION = 16\n",
    "    DATA_ROOT_FOLDER = \"./data/\"\n",
    "    PATIENCE = 10    \n",
    "    RANDOM_SEED = 42\n",
    "    # model hyperparameters\n",
    "    MODEL_PARAMS = {    \n",
    "        \"drop_out\": 0.25,\n",
    "        \"lr\": 0.00036\n",
    "    }\n",
    "\n",
    "class AudioConfig:\n",
    "    # settings\n",
    "    # number of samples per time-step in spectrogram. Defaults to win_length / 4\n",
    "    hop_length = 512 \n",
    "    # number of bins in spectrogram. Height of image\n",
    "    n_mels = 224 \n",
    "    # number of time-steps. Width of image\n",
    "    time_steps = 223 \n",
    "    # number of samples per second\n",
    "    sampling_rate = 22050\n",
    "    # sec\n",
    "    duration = 10 \n",
    "    fmin = 20\n",
    "    fmax = sampling_rate // 2\n",
    "    # length of the windowed signal after padding with zeros. Default value = 2048 ( for music signals)    \n",
    "    n_fft = hop_length * 4\n",
    "    # Each frame of audio is windowed by window of length win_length and then padded with zeros to match n_fft. Defaults to n_fft\n",
    "    win_length = hop_length * 4    \n",
    "    padmode = 'constant'\n",
    "    samples = sampling_rate * duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_exists(mfcc):\n",
    "    if mfcc is not None:\n",
    "        if len(mfcc) > 0:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from functools import wraps\n",
    "\n",
    "def timeit(func):\n",
    "    @wraps(func)\n",
    "    def wrap(*args, **kwargs):\n",
    "        start = time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time()\n",
    "        exec_time = end - start\n",
    "        logger.info(f\"Executing {func} with args {str(args)} and {str(kwargs)} took {exec_time} seconds\")\n",
    "        return result, exec_time\n",
    "    return wrap        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>file_exists</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>mfcc_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10150</td>\n",
       "      <td>010150.ogg</td>\n",
       "      <td>train/010150.ogg</td>\n",
       "      <td>7</td>\n",
       "      <td>Instrumental</td>\n",
       "      <td>True</td>\n",
       "      <td>[-256.21112, 125.60442, -0.42895874, 85.35346,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7358</td>\n",
       "      <td>007358.ogg</td>\n",
       "      <td>train/007358.ogg</td>\n",
       "      <td>2</td>\n",
       "      <td>Punk</td>\n",
       "      <td>True</td>\n",
       "      <td>[-37.284946, 120.587944, -26.513258, 50.83251,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20573</td>\n",
       "      <td>020573.ogg</td>\n",
       "      <td>train/020573.ogg</td>\n",
       "      <td>5</td>\n",
       "      <td>Folk</td>\n",
       "      <td>True</td>\n",
       "      <td>[-364.31793, 154.59741, -48.284782, 15.837085,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11170</td>\n",
       "      <td>011170.ogg</td>\n",
       "      <td>train/011170.ogg</td>\n",
       "      <td>12</td>\n",
       "      <td>Old-Time / Historic</td>\n",
       "      <td>True</td>\n",
       "      <td>[-346.21207, 202.10587, -74.181465, -60.517387...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16662</td>\n",
       "      <td>016662.ogg</td>\n",
       "      <td>train/016662.ogg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rock</td>\n",
       "      <td>True</td>\n",
       "      <td>[-48.237347, 141.68365, -49.396336, 69.53004, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id    filename          filepath  genre_id                genre  \\\n",
       "0    10150  010150.ogg  train/010150.ogg         7         Instrumental   \n",
       "1     7358  007358.ogg  train/007358.ogg         2                 Punk   \n",
       "2    20573  020573.ogg  train/020573.ogg         5                 Folk   \n",
       "3    11170  011170.ogg  train/011170.ogg        12  Old-Time / Historic   \n",
       "4    16662  016662.ogg  train/016662.ogg         1                 Rock   \n",
       "\n",
       "   file_exists                                               mfcc  mfcc_exists  \n",
       "0         True  [-256.21112, 125.60442, -0.42895874, 85.35346,...         True  \n",
       "1         True  [-37.284946, 120.587944, -26.513258, 50.83251,...         True  \n",
       "2         True  [-364.31793, 154.59741, -48.284782, 15.837085,...         True  \n",
       "3         True  [-346.21207, 202.10587, -74.181465, -60.517387...         True  \n",
       "4         True  [-48.237347, 141.68365, -49.396336, 69.53004, ...         True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@timeit\n",
    "def load_train_data(check_mfcc_exists=True):\n",
    "    df_train = pd.read_pickle(Config.DATA_ROOT_FOLDER + \"df_train_mfcc.pkl\")\n",
    "    logger.info(\"loaded train data\")\n",
    "    if check_mfcc_exists:\n",
    "        df_train[\"mfcc_exists\"] = df_train.mfcc.map(lambda mfcc: mfcc_exists(mfcc))\n",
    "    return (df_train, True)\n",
    "\n",
    "result, exec_time = load_train_data(check_mfcc_exists=True)\n",
    "df_train = result[0]\n",
    "logger.info(f\"Executing load_train_data took {exec_time} seconds\")\n",
    "result[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>file_exists</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>mfcc_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>3137</td>\n",
       "      <td>003137.ogg</td>\n",
       "      <td>train/003137.ogg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rock</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4668</th>\n",
       "      <td>11088</td>\n",
       "      <td>011088.ogg</td>\n",
       "      <td>train/011088.ogg</td>\n",
       "      <td>2</td>\n",
       "      <td>Punk</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>16312</td>\n",
       "      <td>016312.ogg</td>\n",
       "      <td>train/016312.ogg</td>\n",
       "      <td>7</td>\n",
       "      <td>Instrumental</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8764</th>\n",
       "      <td>24899</td>\n",
       "      <td>024899.ogg</td>\n",
       "      <td>train/024899.ogg</td>\n",
       "      <td>0</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10155</th>\n",
       "      <td>4040</td>\n",
       "      <td>004040.ogg</td>\n",
       "      <td>train/004040.ogg</td>\n",
       "      <td>4</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10873</th>\n",
       "      <td>9963</td>\n",
       "      <td>009963.ogg</td>\n",
       "      <td>train/009963.ogg</td>\n",
       "      <td>3</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11386</th>\n",
       "      <td>15980</td>\n",
       "      <td>015980.ogg</td>\n",
       "      <td>train/015980.ogg</td>\n",
       "      <td>4</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11497</th>\n",
       "      <td>22698</td>\n",
       "      <td>022698.ogg</td>\n",
       "      <td>train/022698.ogg</td>\n",
       "      <td>4</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14377</th>\n",
       "      <td>23078</td>\n",
       "      <td>023078.ogg</td>\n",
       "      <td>train/023078.ogg</td>\n",
       "      <td>5</td>\n",
       "      <td>Folk</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14827</th>\n",
       "      <td>17940</td>\n",
       "      <td>017940.ogg</td>\n",
       "      <td>train/017940.ogg</td>\n",
       "      <td>0</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15145</th>\n",
       "      <td>22295</td>\n",
       "      <td>022295.ogg</td>\n",
       "      <td>train/022295.ogg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rock</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18537</th>\n",
       "      <td>3071</td>\n",
       "      <td>003071.ogg</td>\n",
       "      <td>train/003071.ogg</td>\n",
       "      <td>2</td>\n",
       "      <td>Punk</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18796</th>\n",
       "      <td>13954</td>\n",
       "      <td>013954.ogg</td>\n",
       "      <td>train/013954.ogg</td>\n",
       "      <td>4</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       song_id    filename          filepath  genre_id         genre  \\\n",
       "1359      3137  003137.ogg  train/003137.ogg         1          Rock   \n",
       "4668     11088  011088.ogg  train/011088.ogg         2          Punk   \n",
       "5150     16312  016312.ogg  train/016312.ogg         7  Instrumental   \n",
       "8764     24899  024899.ogg  train/024899.ogg         0    Electronic   \n",
       "10155     4040  004040.ogg  train/004040.ogg         4       Hip-Hop   \n",
       "10873     9963  009963.ogg  train/009963.ogg         3  Experimental   \n",
       "11386    15980  015980.ogg  train/015980.ogg         4       Hip-Hop   \n",
       "11497    22698  022698.ogg  train/022698.ogg         4       Hip-Hop   \n",
       "14377    23078  023078.ogg  train/023078.ogg         5          Folk   \n",
       "14827    17940  017940.ogg  train/017940.ogg         0    Electronic   \n",
       "15145    22295  022295.ogg  train/022295.ogg         1          Rock   \n",
       "18537     3071  003071.ogg  train/003071.ogg         2          Punk   \n",
       "18796    13954  013954.ogg  train/013954.ogg         4       Hip-Hop   \n",
       "\n",
       "       file_exists  mfcc  mfcc_exists  \n",
       "1359         False  None        False  \n",
       "4668         False  None        False  \n",
       "5150         False  None        False  \n",
       "8764         False  None        False  \n",
       "10155        False  None        False  \n",
       "10873        False  None        False  \n",
       "11386        False  None        False  \n",
       "11497        False  None        False  \n",
       "14377        False  None        False  \n",
       "14827        False  None        False  \n",
       "15145        False  None        False  \n",
       "18537        False  None        False  \n",
       "18796        False  None        False  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[~df_train.mfcc_exists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>file_exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7072</td>\n",
       "      <td>007072.ogg</td>\n",
       "      <td>test/007072.ogg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10207</td>\n",
       "      <td>010207.ogg</td>\n",
       "      <td>test/010207.ogg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20008</td>\n",
       "      <td>020008.ogg</td>\n",
       "      <td>test/020008.ogg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10924</td>\n",
       "      <td>010924.ogg</td>\n",
       "      <td>test/010924.ogg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21896</td>\n",
       "      <td>021896.ogg</td>\n",
       "      <td>test/021896.ogg</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id    filename         filepath  file_exists\n",
       "0     7072  007072.ogg  test/007072.ogg         True\n",
       "1    10207  010207.ogg  test/010207.ogg         True\n",
       "2    20008  020008.ogg  test/020008.ogg         True\n",
       "3    10924  010924.ogg  test/010924.ogg         True\n",
       "4    21896  021896.ogg  test/021896.ogg         True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(Config.DATA_ROOT_FOLDER + \"test.csv\")\n",
    "df_test[\"file_exists\"] = df_test.filepath.map(lambda fp: os.path.exists(Config.DATA_ROOT_FOLDER + fp))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config.NUM_CLASSES = len(df_train.genre_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>file_exists</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>mfcc_exists</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2296</td>\n",
       "      <td>002296.ogg</td>\n",
       "      <td>train/002296.ogg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rock</td>\n",
       "      <td>True</td>\n",
       "      <td>[-51.503376, 90.0839, -29.26633, 51.95741, -1....</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8198</td>\n",
       "      <td>008198.ogg</td>\n",
       "      <td>train/008198.ogg</td>\n",
       "      <td>17</td>\n",
       "      <td>Blues</td>\n",
       "      <td>True</td>\n",
       "      <td>[-219.78317, 179.04573, -47.457195, 30.100721,...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17663</td>\n",
       "      <td>017663.ogg</td>\n",
       "      <td>train/017663.ogg</td>\n",
       "      <td>12</td>\n",
       "      <td>Old-Time / Historic</td>\n",
       "      <td>True</td>\n",
       "      <td>[-308.57285, 210.7832, -61.69949, -59.704113, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7167</td>\n",
       "      <td>007167.ogg</td>\n",
       "      <td>train/007167.ogg</td>\n",
       "      <td>9</td>\n",
       "      <td>International</td>\n",
       "      <td>True</td>\n",
       "      <td>[-204.00072, 187.04646, -35.93575, 29.989346, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11242</td>\n",
       "      <td>011242.ogg</td>\n",
       "      <td>train/011242.ogg</td>\n",
       "      <td>6</td>\n",
       "      <td>Chiptune / Glitch</td>\n",
       "      <td>True</td>\n",
       "      <td>[-75.96725, 91.53988, -38.52349, 64.71302, -28...</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   song_id    filename          filepath  genre_id                genre  \\\n",
       "0     2296  002296.ogg  train/002296.ogg         1                 Rock   \n",
       "1     8198  008198.ogg  train/008198.ogg        17                Blues   \n",
       "2    17663  017663.ogg  train/017663.ogg        12  Old-Time / Historic   \n",
       "3     7167  007167.ogg  train/007167.ogg         9        International   \n",
       "4    11242  011242.ogg  train/011242.ogg         6    Chiptune / Glitch   \n",
       "\n",
       "   file_exists                                               mfcc  \\\n",
       "0         True  [-51.503376, 90.0839, -29.26633, 51.95741, -1....   \n",
       "1         True  [-219.78317, 179.04573, -47.457195, 30.100721,...   \n",
       "2         True  [-308.57285, 210.7832, -61.69949, -59.704113, ...   \n",
       "3         True  [-204.00072, 187.04646, -35.93575, 29.989346, ...   \n",
       "4         True  [-75.96725, 91.53988, -38.52349, 64.71302, -28...   \n",
       "\n",
       "   mfcc_exists  kfold  \n",
       "0         True      3  \n",
       "1         True      2  \n",
       "2         True      2  \n",
       "3         True      3  \n",
       "4         True      3  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the training dataframe into kfolds for cross validation. We do this before any processing is done\n",
    "# on the data. We use stratified kfold if the target distribution is unbalanced\n",
    "def strat_kfold_dataframe(df, target_col_name, num_folds=Config.NUM_FOLDS):\n",
    "    # we create a new column called kfold and fill it with -1\n",
    "    df[\"kfold\"] = -1\n",
    "    # randomize of shuffle the rows of dataframe before splitting is done\n",
    "    df = df.sample(frac=1, random_state=Config.RANDOM_SEED).reset_index(drop=True)\n",
    "    # get the target data\n",
    "    y = df[target_col_name].values\n",
    "    skf = model_selection.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=Config.RANDOM_SEED)\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X=df, y=y)):\n",
    "        df.loc[val_index, \"kfold\"] = fold    \n",
    "    return df     \n",
    "\n",
    "df_train = df_train[df_train.mfcc_exists]\n",
    "df_train = strat_kfold_dataframe(df_train, target_col_name=\"genre_id\")\n",
    "df_train.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(conf, pathname, trim_long_data):\n",
    "    y, sr = librosa.load(pathname, sr=None, res_type=\"kaiser_fast\")\n",
    "    # trim silence\n",
    "    if 0 < len(y): # workaround: 0 length causes error\n",
    "        y, _ = librosa.effects.trim(y) # trim, top_db=default(60)\n",
    "    # extract a fixed length window\n",
    "    start_sample = 0 # starting at beginning\n",
    "    length_samples = conf.time_steps * conf.hop_length    \n",
    "    # make it unified length to conf.samples\n",
    "    if len(y) > conf.samples: # long enough\n",
    "        if trim_long_data:\n",
    "            y = y[start_sample : start_sample+length_samples]        \n",
    "    else: # pad blank\n",
    "        padding = length_samples - len(y)    # add padding at both ends\n",
    "        offset = padding // 2\n",
    "        y = np.pad(y, (offset, conf.samples - len(y) - offset), conf.padmode)\n",
    "    return y, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc_features(filename):\n",
    "    mfccs_processed = None\n",
    "    audio_path = Config.DATA_ROOT_FOLDER + \"train/\" + filename\n",
    "    if os.path.exists(audio_path):\n",
    "        audio, sample_rate = read_audio(AudioConfig, audio_path, True)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=Config.NUM_MFCC)\n",
    "        mfccs_processed = np.mean(mfccs.T,axis=0)     \n",
    "    return mfccs_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"mfcc\"] = df_train.filename.apply(lambda filename: extract_mfcc_features(DATA_PATH + \"train/\" + filename))\n",
    "# df_train.to_pickle(\"df_train_mfcc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import delayed, Parallel\n",
    "\n",
    "# df_train = df_train.head(100)\n",
    "# delayed_funcs_train = [delayed(extract_mfcc_features)(row[\"filename\"]) for i, row in df_train.iterrows()]\n",
    "# results_train = Parallel(n_jobs=-1, verbose=5)(delayed_funcs_train)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataset contains the logic to fetch, load and if required transform data to bring it to a format\n",
    "# that can be used by dataloaders for training. \n",
    "class AudioMfccDataset(Dataset):\n",
    "    def __init__(self, df, mfcc_col, target_col, id_col, transform=None, target_transform=None):\n",
    "        self.df = df\n",
    "        self.id_col = id_col\n",
    "        self.mfcc_col = mfcc_col\n",
    "        self.target_col = target_col        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):                \n",
    "        mfcc = self.df.loc[index, self.mfcc_col]\n",
    "        target = self.df.loc[index, self.target_col]\n",
    "        song_id = self.df.loc[index, self.id_col]\n",
    "        if self.transform is not None:\n",
    "            mfcc_tfmd = self.transform(mfcc)            \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        song_id = torch.as_tensor(song_id)\n",
    "        return song_id, mfcc_tfmd, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold_dls(fold, df_imgs):\n",
    "    df_train = df_imgs[df_imgs[\"kfold\"] != fold].reset_index(drop=True)\n",
    "    df_val = df_imgs[df_imgs[\"kfold\"] == fold].reset_index(drop=True)    \n",
    "    ds_train = AudioMfccDataset(\n",
    "        df_train, \n",
    "        mfcc_col=\"mfcc\",\n",
    "        target_col=\"genre_id\", \n",
    "        id_col=\"song_id\",\n",
    "        transform=torch.as_tensor,\n",
    "        target_transform=torch.as_tensor\n",
    "    )\n",
    "    ds_val = AudioMfccDataset(\n",
    "        df_val, \n",
    "        mfcc_col=\"mfcc\",\n",
    "        target_col=\"genre_id\",\n",
    "        id_col=\"song_id\",\n",
    "        transform=torch.as_tensor,\n",
    "        target_transform=torch.as_tensor\n",
    "    )        \n",
    "    dl_train = DataLoader(ds_train, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=Config.NUM_WORKERS)    \n",
    "    dl_val = DataLoader(ds_val, batch_size=Config.BATCH_SIZE, num_workers=Config.NUM_WORKERS)\n",
    "    return dl_train, dl_val, ds_train, ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train, dl_val, ds_train, ds_val = get_fold_dls(0, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(20570),\n",
       " tensor([ 77.1201,  74.4379, -41.6419,  43.3034, -36.6637,  51.3666, -30.3715,\n",
       "          33.0450, -20.6842,  34.3427, -23.1814,  27.6178, -15.7877,  20.3962,\n",
       "         -10.9349,  12.6420,  -5.7834,  11.1199,  -3.6817,   0.7359,  -0.5042,\n",
       "           1.7668,   9.0716,  -2.0096,   3.4431,  -7.1916,   8.2092,  -7.3172,\n",
       "           9.1665,  -6.9760,   8.0860,  -6.1567,   7.5181,  -6.5443,   6.9241,\n",
       "          -4.6341,   3.5342,  -2.2990,   3.0409,  -1.7411]),\n",
       " tensor(3))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MfccAudioClfNet(nn.Module):\n",
    "    def __init__(self, num_mfcc, num_classes): \n",
    "        super().__init__()       \n",
    "        self.fc1 = nn.Linear(in_features=num_mfcc, out_features=256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout()\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout()\n",
    "        self.classifier = nn.Linear(in_features=128, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "import torchmetrics\n",
    "\n",
    "class AudioClfMfccLitModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes, num_mfcc, hparams):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = hparams[\"lr\"]\n",
    "        self.num_classes = num_classes              \n",
    "        self.net = MfccAudioClfNet(num_mfcc=num_mfcc, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        return self.net(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        model_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.parameters()), lr=self.lr)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(model_optimizer, \"min\")        \n",
    "        return {\n",
    "            \"optimizer\": model_optimizer, \n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": lr_scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"frequency\": 1\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        id, X, y = batch\n",
    "        y_pred = self(X)\n",
    "        loss = cross_entropy(y_pred, y)\n",
    "        train_f1 = torchmetrics.functional.f1(preds=y_pred, target=y, num_classes=self.num_classes, average=\"micro\")\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        self.log(\"train_f1\", train_f1, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        return loss        \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        id, X, y = batch\n",
    "        y_pred = self(X)\n",
    "        val_loss = cross_entropy(y_pred, y)\n",
    "        val_f1 = torchmetrics.functional.f1(preds=y_pred, target=y, num_classes=self.num_classes, average=\"micro\")\n",
    "        self.log(\"val_loss\", val_loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        self.log(\"val_f1\", val_f1, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n",
    "        return {\"loss\": val_loss, \"val_f1\": val_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, BackboneFinetuning, EarlyStopping\n",
    "\n",
    "# For results reproducibility \n",
    "# sets seeds for numpy, torch, python.random and PYTHONHASHSEED.\n",
    "pl.seed_everything(Config.RANDOM_SEED, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "class MetricsAggCallback(Callback):\n",
    "    def __init__(self, metric_to_monitor, mode):\n",
    "        self.metric_to_monitor = metric_to_monitor\n",
    "        self.metrics = []\n",
    "        self.best_metric = None\n",
    "        self.mode = mode\n",
    "        self.best_metric_epoch = None\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer: Trainer, pl_module: LightningModule):\n",
    "        metric_value = trainer.callback_metrics[self.metric_to_monitor].cpu().detach().item()\n",
    "        val_loss = trainer.callback_metrics[\"val_loss\"].cpu().detach().item()\n",
    "        print(f\"metric {self.metric_to_monitor} = {metric_value}, val_loss={val_loss}\")        \n",
    "        self.metrics.append(metric_value)\n",
    "        if self.mode == \"max\":\n",
    "            self.best_metric = max(self.metrics)\n",
    "            self.best_metric_epoch = self.metrics.index(self.best_metric)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "def run_training(fold, dl_train, dl_val, fold_loss, fold_f1, find_lr=True):\n",
    "        fold_str = f\"fold{fold}\"\n",
    "        print(f\"Running training for {fold_str}\")\n",
    "        logger = None\n",
    "        val_loss_chkpt = \"best_model_{epoch}_{val_loss:.4f}\"\n",
    "        val_f1_chkpt = \"best_model_{epoch}_{val_f1:.4f}\"\n",
    "        early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience=Config.PATIENCE, mode=\"min\", verbose=True)        \n",
    "        if fold is not None:       \n",
    "            val_loss_chkpt = fold_str + \"_\" + val_loss_chkpt\n",
    "            val_f1_chkpt = fold_str + \"_\" + val_f1_chkpt\n",
    "        logger = WandbLogger(name=\"mfcc_baseline\", project=\"Pog_Music_Clf\")                    \n",
    "        audio_model = AudioClfMfccLitModel(\n",
    "            num_classes=Config.NUM_CLASSES, \n",
    "            num_mfcc=Config.NUM_MFCC,\n",
    "            hparams=Config.MODEL_PARAMS\n",
    "        )    \n",
    "        val_loss_chkpt_callback = ModelCheckpoint(dirpath=\"./model\", verbose=True, monitor=\"val_loss\", mode=\"min\", filename=val_loss_chkpt)\n",
    "        val_f1_chkpt_callback = ModelCheckpoint(dirpath=\"./model\", verbose=True, monitor=\"val_f1\", mode=\"max\", filename=val_f1_chkpt)\n",
    "        acc_chkpt_callback = MetricsAggCallback(metric_to_monitor=\"val_f1\", mode=\"max\")\n",
    "        trainer = pl.Trainer(\n",
    "            gpus=1,\n",
    "            # For results reproducibility \n",
    "            deterministic=True,\n",
    "            auto_select_gpus=True,\n",
    "            progress_bar_refresh_rate=20,\n",
    "            max_epochs=Config.NUM_EPOCHS,\n",
    "            logger=None,\n",
    "            auto_lr_find=True,    \n",
    "            precision=Config.PRECISION,            \n",
    "            weights_summary=\"full\", \n",
    "            fast_dev_run=Config.FAST_DEV_RUN,                   \n",
    "            callbacks=[val_loss_chkpt_callback, val_f1_chkpt_callback, acc_chkpt_callback, early_stopping_callback]\n",
    "        )\n",
    "        if find_lr:\n",
    "            trainer.tune(model=audio_model, train_dataloaders=dl_train)\n",
    "            print(audio_model.lr)\n",
    "        trainer.fit(audio_model, train_dataloaders=dl_train, val_dataloaders=dl_val)                \n",
    "        if not Config.FAST_DEV_RUN:\n",
    "            fold_loss.append((val_loss_chkpt_callback.best_model_score.cpu().detach().item(), val_loss_chkpt_callback.best_model_path))\n",
    "            fold_f1.append((acc_chkpt_callback.best_metric, val_f1_chkpt_callback.best_model_path))\n",
    "            print(f\"Loss for {fold_str} = {fold_loss[fold]}, f1 = {fold_f1[fold]}\")\n",
    "        del trainer, audio_model, early_stopping_callback, acc_chkpt_callback, val_loss_chkpt_callback, val_f1_chkpt_callback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# For a specific fold get the predictions on oof (validation) data. We do this for each fold\n",
    "# We then use these oof predictions to calculate the cross validation score (using the evaluation metric)\n",
    "def get_oof_preds(fold, fold_loss, dl_val):\n",
    "    # get the best model (having lowest val loss) for the fold\n",
    "    best_model_path_val_loss = fold_loss[fold][1]\n",
    "    print(f\"Using best model = {best_model_path_val_loss} for oof prediction on fold {fold} validation set\")\n",
    "    best_model = AudioClfMfccLitModel.load_from_checkpoint(\n",
    "        checkpoint_path=best_model_path_val_loss,\n",
    "        num_classes=Config.NUM_CLASSES, \n",
    "        num_mfcc=Config.NUM_MFCC, \n",
    "        hparams=Config.MODEL_PARAMS\n",
    "    )\n",
    "    if \"val_preds\" not in df_train.columns:\n",
    "        df_train[\"val_preds\"] = len(df_train) * [-100]\n",
    "    with torch.no_grad():        \n",
    "        for id, X, y in tqdm(dl_val):\n",
    "            id = id.cpu().detach().numpy()            \n",
    "            y_preds = torch.argmax(best_model(X), dim=1)\n",
    "            y_preds = y_preds.cpu().detach().numpy().astype(int)            \n",
    "            df_train.loc[df_train.song_id.isin(id), \"val_preds\"] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_score(targets, oof_preds):\n",
    "    cv_f1 = torchmetrics.functional.f1(preds=oof_preds, target=targets, num_classes=Config.NUM_CLASSES, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def print_exp_statistics(fold_loss, fold_acc):\n",
    "    print(\"val loss across folds\")\n",
    "    print(fold_loss)\n",
    "    print(\"val f1 across folds\")\n",
    "    print(fold_acc)\n",
    "    #mean_loss = statistics.mean(fold_loss)\n",
    "    #mean_acc = statistics.mean(fold_acc)\n",
    "    #std_loss = statistics.stdev(fold_loss)\n",
    "    #std_acc = statistics.stdev(fold_acc)\n",
    "    #print(f\"mean loss across folds = {mean_loss}, loss stdev across fold = {std_loss}\")\n",
    "    #print(f\"mean accuracy across folds = {mean_acc}, accuracy stdev across fold = {std_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for fold0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using native 16bit precision.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type            | Params\n",
      "---------------------------------------------------\n",
      "0 | net            | MfccAudioClfNet | 45.8 K\n",
      "1 | net.fc1        | Linear          | 10.5 K\n",
      "2 | net.relu1      | ReLU            | 0     \n",
      "3 | net.dropout1   | Dropout         | 0     \n",
      "4 | net.fc2        | Linear          | 32.9 K\n",
      "5 | net.relu2      | ReLU            | 0     \n",
      "6 | net.dropout2   | Dropout         | 0     \n",
      "7 | net.classifier | Linear          | 2.5 K \n",
      "---------------------------------------------------\n",
      "45.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "45.8 K    Total params\n",
      "0.183     Total estimated model params size (MB)\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df90922f0884f9386a110e4868b23e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint file at /home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/lr_find_temp_model.ckpt\n",
      "Restored all states from the checkpoint file at /home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/lr_find_temp_model.ckpt\n",
      "Learning rate set to 0.003981071705534969\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type            | Params\n",
      "---------------------------------------------------\n",
      "0 | net            | MfccAudioClfNet | 45.8 K\n",
      "1 | net.fc1        | Linear          | 10.5 K\n",
      "2 | net.relu1      | ReLU            | 0     \n",
      "3 | net.dropout1   | Dropout         | 0     \n",
      "4 | net.fc2        | Linear          | 32.9 K\n",
      "5 | net.relu2      | ReLU            | 0     \n",
      "6 | net.dropout2   | Dropout         | 0     \n",
      "7 | net.classifier | Linear          | 2.5 K \n",
      "---------------------------------------------------\n",
      "45.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "45.8 K    Total params\n",
      "0.183     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003981071705534969\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f62304442f4d0a953422cd9979d4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric val_f1 = 0.0703125, val_loss=7.652549743652344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4d227ca18640d9ba95b6aea51f7ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 36it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8693953d333e4a0dbefd955714822eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 2.265\n",
      "Epoch 0, global step 62: val_loss reached 2.26545 (best 2.26545), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=0_val_loss=2.2655.ckpt\" as top 1\n",
      "Epoch 0, global step 62: val_f1 reached 0.25063 (best 0.25063), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=0_val_f1=0.2506.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric val_f1 = 0.2506278157234192, val_loss=2.265454053878784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45615f01ecbd4c9998f5b6b0a10b68e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.143 >= min_delta = 0.0. New best score: 2.123\n",
      "Epoch 1, global step 125: val_loss reached 2.12265 (best 2.12265), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=1_val_loss=2.1227.ckpt\" as top 1\n",
      "Epoch 1, global step 125: val_f1 reached 0.30010 (best 0.30010), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=1_val_f1=0.3001.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric val_f1 = 0.3001004457473755, val_loss=2.1226511001586914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e7dc552f86430f9e4f65fbffd5efbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.033 >= min_delta = 0.0. New best score: 2.090\n",
      "Epoch 2, global step 188: val_loss reached 2.08991 (best 2.08991), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=2_val_loss=2.0899.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric val_f1 = 0.30813661217689514, val_loss=2.0899057388305664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 188: val_f1 reached 0.30814 (best 0.30814), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=2_val_f1=0.3081.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f6706f6bc149c28bb003bb4d956558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.010 >= min_delta = 0.0. New best score: 2.080\n",
      "Epoch 3, global step 251: val_loss reached 2.07959 (best 2.07959), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=3_val_loss=2.0796.ckpt\" as top 1\n",
      "Epoch 3, global step 251: val_f1 was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric val_f1 = 0.2950778603553772, val_loss=2.0795934200286865\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4dc8990c824025bd26e7db466c73af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 2.076\n",
      "Epoch 4, global step 314: val_loss reached 2.07638 (best 2.07638), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=4_val_loss=2.0764.ckpt\" as top 1\n",
      "Epoch 4, global step 314: val_f1 was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric val_f1 = 0.29432445764541626, val_loss=2.0763773918151855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932eaceef96940598ff98b086a08193f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0. New best score: 2.065\n",
      "Epoch 5, global step 377: val_loss reached 2.06539 (best 2.06539), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=5_val_loss=2.0654.ckpt\" as top 1\n",
      "Epoch 5, global step 377: val_f1 reached 0.31215 (best 0.31215), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=5_val_f1=0.3122.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric val_f1 = 0.31215471029281616, val_loss=2.065389633178711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68abba40e3948d099ae36f453035536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.041 >= min_delta = 0.0. New best score: 2.024\n",
      "Epoch 6, global step 440: val_loss reached 2.02431 (best 2.02431), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=6_val_loss=2.0243.ckpt\" as top 1\n",
      "Epoch 6, global step 440: val_f1 reached 0.32195 (best 0.32195), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=6_val_f1=0.3219-v3.ckpt\" as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric val_f1 = 0.321948766708374, val_loss=2.0243079662323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f27060f8eae48c1a574dcd76ee7026f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 503: val_loss was not in top 1\n",
      "Epoch 7, global step 503: val_f1 was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric val_f1 = 0.31567052006721497, val_loss=2.040850877761841\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b12fb07201048d6ab8fc99ae787b311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 566: val_loss was not in top 1\n",
      "Epoch 8, global step 566: val_f1 was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric val_f1 = 0.321948766708374, val_loss=2.0314948558807373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90878b02415d4335bc9b0c496a08a276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 2.020\n",
      "Epoch 9, global step 629: val_loss reached 2.02006 (best 2.02006), saving model to \"/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=9_val_loss=2.0201-v3.ckpt\" as top 1\n",
      "Epoch 9, global step 629: val_f1 was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric val_f1 = 0.31491711735725403, val_loss=2.020061492919922\n",
      "Loss for fold0 = (2.020061492919922, '/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=9_val_loss=2.0201-v3.ckpt'), f1 = (0.321948766708374, '/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=6_val_f1=0.3219-v3.ckpt')\n",
      "Using best model = /home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=9_val_loss=2.0201-v3.ckpt for oof prediction on fold 0 validation set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b01bade7e84bd7bab1e838b1c3bef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>file_exists</th>\n",
       "      <th>mfcc</th>\n",
       "      <th>mfcc_exists</th>\n",
       "      <th>kfold</th>\n",
       "      <th>val_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20570</td>\n",
       "      <td>020570.ogg</td>\n",
       "      <td>train/020570.ogg</td>\n",
       "      <td>3</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>True</td>\n",
       "      <td>[77.12008, 74.43785, -41.64192, 43.303394, -36...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14294</td>\n",
       "      <td>014294.ogg</td>\n",
       "      <td>train/014294.ogg</td>\n",
       "      <td>3</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>True</td>\n",
       "      <td>[-411.85922, 186.5546, 38.15256, 1.7032989, -1...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2557</td>\n",
       "      <td>002557.ogg</td>\n",
       "      <td>train/002557.ogg</td>\n",
       "      <td>13</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>True</td>\n",
       "      <td>[-185.49287, 156.26584, -4.746399, 47.099525, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11205</td>\n",
       "      <td>011205.ogg</td>\n",
       "      <td>train/011205.ogg</td>\n",
       "      <td>9</td>\n",
       "      <td>International</td>\n",
       "      <td>True</td>\n",
       "      <td>[-199.2589, 100.37568, -16.693697, 51.71922, 2...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>24813</td>\n",
       "      <td>024813.ogg</td>\n",
       "      <td>train/024813.ogg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rock</td>\n",
       "      <td>True</td>\n",
       "      <td>[-139.90079, 156.55542, -81.60364, 83.02814, 2...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    song_id    filename          filepath  genre_id          genre  \\\n",
       "9     20570  020570.ogg  train/020570.ogg         3   Experimental   \n",
       "11    14294  014294.ogg  train/014294.ogg         3   Experimental   \n",
       "19     2557  002557.ogg  train/002557.ogg        13           Jazz   \n",
       "24    11205  011205.ogg  train/011205.ogg         9  International   \n",
       "44    24813  024813.ogg  train/024813.ogg         1           Rock   \n",
       "\n",
       "    file_exists                                               mfcc  \\\n",
       "9          True  [77.12008, 74.43785, -41.64192, 43.303394, -36...   \n",
       "11         True  [-411.85922, 186.5546, 38.15256, 1.7032989, -1...   \n",
       "19         True  [-185.49287, 156.26584, -4.746399, 47.099525, ...   \n",
       "24         True  [-199.2589, 100.37568, -16.693697, 51.71922, 2...   \n",
       "44         True  [-139.90079, 156.55542, -81.60364, 83.02814, 2...   \n",
       "\n",
       "    mfcc_exists  kfold  val_preds  \n",
       "9          True      0          0  \n",
       "11         True      0         11  \n",
       "19         True      0          1  \n",
       "24         True      0          0  \n",
       "44         True      0          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss across folds\n",
      "[(2.020061492919922, '/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=9_val_loss=2.0201-v3.ckpt')]\n",
      "val f1 across folds\n",
      "[(0.321948766708374, '/home/bk_anupam/code/ML/KaggleChallenges/AUDIO/MusicClassification/model/fold0_best_model_epoch=6_val_f1=0.3219-v3.ckpt')]\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "find_lr = True\n",
    "fold_loss = []\n",
    "fold_f1 = []\n",
    "for fold in range(Config.NUM_FOLDS):\n",
    "    dl_train, dl_val, ds_train, ds_val = get_fold_dls(fold, df_train)\n",
    "    run_training(fold, dl_train, dl_val, fold_loss, fold_f1, find_lr)        \n",
    "    get_oof_preds(fold, fold_loss, dl_val)\n",
    "    display(df_train[df_train.kfold == fold].head())\n",
    "    break  \n",
    "\n",
    "print_exp_statistics(fold_loss, fold_f1)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation F1 score across 1 folds = 0.29306880964339527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# export the oof predictions to csv for later use in stacking\n",
    "df_train.to_csv(Config.DATA_ROOT_FOLDER + \"df_train_oof_preds.csv\")\n",
    "df_oof = df_train[df_train.val_preds != -100]\n",
    "cv_f1 = f1_score(y_pred=df_oof.val_preds, y_true=df_oof.genre_id, average=\"micro\")\n",
    "print(f\"Cross validation F1 score across {len(fold_loss)} folds = {cv_f1}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0197751694b00855cd01780d565fa2e16f7945f624c4146f8d6aac863c2ba178"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('fastai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
